<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>期望最大化（洪亮劼的专栏）</title>
    <description>LinkedIn工程总监、前Etsy工程总监、雅虎研究院高级研发经理，长期从事机器学习、大数据分析、个性化系统架构的研究；这是一个分享技术、管理、团队和业界思考的专栏。</description>
    <link>http://column.hongliangjie.com/</link>
    <atom:link href="http://column.hongliangjie.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 13 Dec 2020 10:48:40 -0800</pubDate>
    <lastBuildDate>Sun, 13 Dec 2020 10:48:40 -0800</lastBuildDate>
    <generator>Jekyll v3.8.7</generator>
    
      <item>
        <title>浅谈工业级推荐系统</title>
        <description>&lt;p&gt;我于2020年8月受&lt;a href=&quot;https://irsworkshop.github.io/2020/index.html&quot;&gt;“第一届工业级推荐系统研讨会”&lt;/a&gt;的邀请，做了题为&lt;a href=&quot;https://www.hongliangjie.com/talks/IRS_KDD2020.pdf&quot;&gt;“工业级推荐系统最新的挑战和发展”&lt;/a&gt;的主题演讲。我们就依据这个演讲的内容作为一个起点，来聊一聊工业级推荐系统的一些特点，尤其是和推荐系统的学术研究有着哪些不同的侧重点。本文会关注那些学术研究中容易忽视的，但却是在工业级推荐系统研发的日常中需要思考的问题。&lt;/p&gt;

&lt;h2 id=&quot;工业级推荐系统及其生态系统&quot;&gt;工业级推荐系统及其生态系统&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/in-recsys-1.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;工业级推荐系统和学术研究中的推荐系统最大的一个区别，也是最容易忽视的一个区别在于，前者往往是某个产品中的一个环节，甚至有时候是一个很小的环节。一个产品往往有很多环节，而这些环节构成了一个复杂的生态系统。更进一步来说，某个公司之间的多个产品可以进一步构成更加高级的复杂生态系统。所以，理解工业级推荐系统就必须把推荐系统放回其所在的整体生态系统来进行审视和研究。&lt;/p&gt;

&lt;p&gt;传统学术研究中的推荐系统往往基于一个虚构的理想环境。那就是有一个物品的候选池（可以是新闻、电影、或者是商品等），而用户针对这个侯选池中的物品进行逐一评分，分数由低到高，可以是五分制，也可以是两分制，表达喜好程度。推荐系统的任务被抽象成为对用户评分（Rating）信息的预测或者是估计。一个完美的推荐系统就是毫无偏差得对所有的用户评分进行还原和预测。熟悉的读者可以发现，这个理想环境其实就是对推荐系统研究有着巨大推动作用的——&lt;a href=&quot;https://en.wikipedia.org/wiki/Netflix_Prize&quot;&gt;Netflix大奖赛&lt;/a&gt;中任务场景更加抽象的一个版本。的确，把推荐系统抽象成用户评分信息预估极大得简化了推荐系统在实际产品中的作用，为十多年来推荐系统研究的蓬勃发展带来了有力的支持。一个更加抽象的任务描述则把评分预估看成是不完全信息的&lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_completion&quot;&gt;“矩阵完成”（Matrix Completion）&lt;/a&gt;。也就是说评分预估可以看做是一个以用户为行物品为列的矩阵中有一些信息不完整。我们只有某一些单元中有数值，代表已经打过分的用户与物品的的交互。剩下有大量的单元需要来补全信息。这种“矩阵完成”的任务描述则更进一步得把推荐系统的任务变成了数学中的代数问题。&lt;/p&gt;

&lt;p&gt;实际上，研究人员和实践工作者很快意识到了把推荐系统研究如此简化带来的一个直接问题，那就是推荐系统性能的提高，或者说是对用户评分预测的精准与否，与我们期望推荐系统所承载的功能有不小的偏差。早在Netflix大奖赛之后，&lt;a href=&quot;https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429&quot;&gt;Netflix官方工程博客&lt;/a&gt;就阐述了为什么团队最终没有采纳获奖的算法在产品中，并且因为种种原因，包括隐私和法律风险，Netflix最终放弃了举行第二届大奖赛的想法。对于Netflix这个产品群来说，真正的产品需求是希望用户能够喜欢其服务所带来的电影电视以及广泛的节目，从而让用户能够选择订阅Netflix服务，或者持续订阅。也就是说，Netflix所有产品，包括上面林林种种的搜索推荐功能都是为这同一目的而服务的。单一模块的好坏甚至是某个模块上面用户对于某一个节目的评分可能与这个用户是否选择继续订阅Netflix没有明显的联系。&lt;/p&gt;

&lt;p&gt;这种推荐模块仅仅是一个更大产品中的一个环节，并且更大产品的目标和推荐系统的目标完全不一样的情况不仅仅局限于Netflix。例如电商Amazon，虽然网站上有各种不同的页面和模块，但归结起来，总的目的还是希望能够吸引用户购买商品。例如专注构建职业社交圈的LinkedIn，网站上有丰富的各种模块和服务，但归根结底，LinkedIn是希望用户最终能够订阅其中的一些服务或者是成为其广告的点击者，为其服务产生商业价值。例如在线音乐和广播节目服务商Spotify的最终目的是吸引用户持续订阅其服务。因此，Spotify上的种种栏目和推荐模块都是为这一共同的目标而服务的。&lt;/p&gt;

&lt;p&gt;把单一推荐模块，和其他的模块页面放一起，都看做是达成产品最终目标的统一生态系统中的一个元素，是理解和开发工业级推荐系统的重要前提。&lt;/p&gt;

&lt;p&gt;对于多页面多模块的生态系统而言，有这么两个重要的挑战。第一，产品的最终目的往往和某一个模块的成功有着复杂的关系，并没有完全线性的相互联系。换句话说，即便衡量大多数甚至每一个模块的指标有了正向或者负向的变化，整个产品的最终目标并不一定会有相同方向的变化。例如，对于Netflix来说，某一个模块的点击率的变化，可能对每一个月的订阅人数的变化并不起决定性的作用。第二，理解多个模块之间的关系变得很困难。例如，Amazon商品页面上的多个模块，按理说，其目的是为了吸引用户更加了解当前产品并且进行购买，但是如果一个模块展示了其他更加有吸引力的产品，用户可能会从当前页面跳转到其他页面去。更加复杂的场景包括用户可能因为看了过多的产品后举棋不定，从而不准备在当下进行购买。于是，商品页面上的某一个模块虽然可能有了更多的点击，但是其他模块可能会受到影响，点击下降，达到某种“此消彼长”的态势。&lt;/p&gt;

&lt;p&gt;总而言之，把推荐系统放到整个生态系统中进行思考并且理解多个模块之间的关系是工业级推荐系统的重要挑战。&lt;/p&gt;

&lt;h2 id=&quot;工业级推荐系统和产品长期目标的关系&quot;&gt;工业级推荐系统和产品长期目标的关系&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/in-recsys-2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们前面提到了工业级的推荐系统往往是庞大产品体系中的一个环节。而整个产品体系又是为公司的产品以及商业策略服务而最终获得商业和社会价值。大多数互联网公司都对如何衡量产品和商业策略有一些标准的做法，比如利用&lt;a href=&quot;https://en.wikipedia.org/wiki/Active_users&quot;&gt;“月活跃用户数”&lt;/a&gt;（Monthly Active Users）、&lt;a href=&quot;https://en.wikipedia.org/wiki/Gross_merchandise_volume&quot;&gt;“商品毛利润”&lt;/a&gt;（Gross Merchandise Value）来对一个公司的业务好坏进行最基本的判断。&lt;/p&gt;

&lt;p&gt;然而我们可以看到，公司对于产品衡量好坏的标准往往都是对于产品的一个相对长时间状态的描述。例如，如果我们要观测“月活跃用户数”的变化，则需要对产品进行好几个月的观察，仅仅观察一两个月就自然无法得到这种本身就需要多个月进行观测的指标的变化。同理，“商品毛利润”的变化有时候也需要少则数周多则数月才能观测出来，如有一些产品的计费方式是每一个月针对用户进行计费甚至有的是每一年才计费（例如有一些订阅服务）。LinkedIn的企业级招聘的重要指标是看有多少用户利用LinkedIn找到心仪的工作。而要衡量一个用户是否换了工作，这里面的数据信息的滞后性可能有几周到几个月不等。因此观察这个指标的变化也是需要长期衡量的。&lt;/p&gt;

&lt;p&gt;产品的业务指标需要长期观测这一特性为优化这些指标，特别是利用机器学习系统来优化这些指标，带来了巨大的困难。&lt;/p&gt;

&lt;p&gt;现代互联网产品迭代往往利用在线可控实验，或者简称的&lt;a href=&quot;https://en.wikipedia.org/wiki/A/B_testing&quot;&gt;A/B测试&lt;/a&gt;，来对产品特性进行实验。具体说来，我们常常把当前版本的特性当做“控制组”，并把新版本的特性当做“参照组”，然后把用户流量各50%得导给“控制组”和“参照组”。一般来说，A/B测试运行一两周，有时候会有两三周，然后根据一些容易观测的指标，例如“点击率”来判断特性的新版本是不是比当前版本要有明显的优势（包括我们说的统计意义上的要更好）。然而，我们可以看到，在几周的在线测试的设置下，我们是很难去直接观测刚才我们提到的产品指标（如“月活跃用户数”、“商品毛利润”）的变化。大多数在线测试的时长都远远小于观测产品长期指标变化需要的时长。&lt;/p&gt;

&lt;p&gt;如果我们希望利用A/B测试来对产品的特性进行迭代，那势必就需要观测的指标能够在测试的时长中被有效得观测到其大小的变化。从更加专业的角度来说，这样的指标需要有足够的“敏感度”（Sensitivity）能够在测试的时长中很容易发现其变化。遗憾的是，大多数的产品长期指标的“敏感度”都比较小。例如“月活用户数”的变化往往需要我们对很大的流量数据进行观测一段时间。而“点击率”的变化则相对容易看到。&lt;/p&gt;

&lt;p&gt;于是，我们这里就有一个很大的障碍，那就是A/B测试指标和产品长期指标之间往往非常不一样，而建立两者之间的关系可能有不可逾越的鸿沟。&lt;/p&gt;

&lt;p&gt;推荐系统作为一种机器学习系统，往往采用我们熟知的指标来衡量其好坏。比如我们前面提到的Netflix大奖赛其实是看我们对评分预测的准确性。很多机器学习问题采用的&lt;a href=&quot;https://en.wikipedia.org/wiki/Precision_and_recall&quot;&gt;“精度”&lt;/a&gt;或者一些排序问题采用的&lt;a href=&quot;https://en.wikipedia.org/wiki/Discounted_cumulative_gain&quot;&gt;NDCG&lt;/a&gt;等，也是研发人员往往使用的指标。然而，我们可以看到，这些指标和A/B测试指标以及产品的长期指标有着本质的不同。一个例子是我们也可以推断，Netflix大奖赛的获胜算法虽然能够带来评分预测准确性大幅度的提升，但对于产品的重要指标，也就是用户的订阅数，并没有明显的影响。&lt;/p&gt;

&lt;p&gt;工业级推荐系统的一个重要发展方向就是建立有效的通过推荐系统性能的提高来达到产品的长期指标得以提高的方法论。&lt;/p&gt;

&lt;h2 id=&quot;工业级推荐系统作为复杂的软件系统&quot;&gt;工业级推荐系统作为复杂的软件系统&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/in-recsys-3.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这里要提到的最后一个工业级推荐系统的特性，也是推荐系统的学术研究往往会完全忽视的，那就是工业级推荐系统往往是一个复杂的软件系统。&lt;/p&gt;

&lt;p&gt;这里面的复杂性来自于两方面。第一，工业级的推荐系统作为一个复杂的软件系统，是由不同的软件模块和服务构建而成。而这些软件模块还需要利用很多的基础设置，例如数据平台，以及各种工具。这些不同的软件模块之间如何能够设计最优，会不会有复杂的依赖关系从而很难调优，都是需要思考的重要问题。第二，工业级的推荐系统作为一个复杂的软件系统，是多人甚至是多团队的研发结果。每一个团队往往维护着不同的软件模块。这些团队之间的协作往往并没有很多人想象的那样非常紧密。实际上，不同的团队通常有不同的开发周期，因此如何能够保证不同的团队协调一致是一个复杂软件工程问题。&lt;/p&gt;

&lt;p&gt;我们通常在推荐系统的研究论文中，看到所谓的“端到端”（End-to-End）的优化模式，也就是说，我们希望能够对模型的方方面面的所有参数以及各种输入信号一起都拿到一个统一的模型中去调优。这种思路在近年来的以深度学习为基础的论文中常常遇到。而通过论文，我们也看到，这样的“端到端”的学习方法往往有最优的效果。遗憾的是，针对多模块多团队的推荐系统，我们是很难做到真的“端到端”优化的。通常情况下，某一个团队的模块可以进行“端到端”优化。而各个模块之间则往往是“黑盒”交流（也就是说并不清楚互相模块的内部信息）。从软件系统的角度来看，工业级推荐系统和推荐系统研究有着比较大的差别。&lt;/p&gt;

&lt;p&gt;多模块和多团队的推荐系统还会遇到在研究中完全不需要考虑的问题，比如，如果不同的模块都在进行进度不同的研发，那么如何能够保证多个模块之间能够协调好，特别是在进行在线测试的时候，能够得到有效的结论，有时候是相当有挑战的。例如，某个推荐系统的新旧版本可能依赖不同的数据，或者一些不同的内部服务，这时候就可能并不是严格意义上的A/B测试，而可能有很多因素可以影响测试结果。&lt;/p&gt;

&lt;p&gt;从软件系统和软件工程的角度来看到工业级推荐系统，或者说一般的机器学习系统，是一个很值得探讨的课题。从推荐系统的学术研究中，我们很难看到这一类的讨论。&lt;/p&gt;

&lt;h2 id=&quot;总结点评&quot;&gt;总结点评&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;我们在这一篇文章中为大家阐述了三个工业级推荐系统的重要特征。这三个特征都有别于推荐系统的主流学术研究，但都是推荐系统应用到工业界产品中所需要思考的问题。我希望这三个特性所涵盖的三方面问题可以指导对工业级推荐系统产生更加有高度的认识，从而能够让我们对今后的研究工作有新的启发，起到抛砖引玉的作用。&lt;/p&gt;
</description>
        <pubDate>Sun, 04 Oct 2020 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2020/10/04/industrial-recsys/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2020/10/04/industrial-recsys/</guid>
        
        
        <category>推荐系统</category>
        
      </item>
    
      <item>
        <title>《韧性管理》总结</title>
        <description>&lt;p&gt;今天我们要来总结技术管理书籍&lt;a href=&quot;https://resilient-management.com/&quot;&gt;Resilient Management&lt;/a&gt;。作者&lt;a href=&quot;https://www.linkedin.com/in/larachogan/&quot;&gt;Lara Hogan&lt;/a&gt;是资深的科技公司领导人。她先后于Etsy和Kickstarter担任重要的技术领导人职务，其长期在发表关于技术管理的博客文章以及提供相应的咨询和培训服务。书中有不少可以直接拿来用的技巧、模板和方法。同时，书中的一些案例也是来源于实际工作。本书非常适合需要对技术管理快速入门的初级技术管理人员。&lt;/p&gt;

&lt;h2 id=&quot;作者简介&quot;&gt;作者简介&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/lara.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;作者&lt;a href=&quot;https://www.linkedin.com/in/larachogan/&quot;&gt;Lara Hogan&lt;/a&gt;是资深的科技公司领导人。她先后于Etsy和Kickstarter担任重要的技术领导人职务，其长期在发表关于技术管理的博客文章以及提供相应的咨询和培训服务。&lt;/p&gt;

&lt;h2 id=&quot;全书结构&quot;&gt;全书结构&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;全书非常短小精悍，分为以下这么五章内容：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一章，主要是讲如何认识你的团队，也就是书中讲的结识你的团队（Meet Your Team）。&lt;/li&gt;
  &lt;li&gt;第二章，主要是讲如何是你的团队成员得以成长（Grow Your Teammates）。&lt;/li&gt;
  &lt;li&gt;第三章，主要是讲如何设置明确清晰的期望（Set Clear Expectations）。&lt;/li&gt;
  &lt;li&gt;第四章，主要是讲如何有效的进行沟通（Communicate Effectively）。&lt;/li&gt;
  &lt;li&gt;第五章，主要是讲如何构建韧性管理（Build Resiliency）。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;内容剖析&quot;&gt;内容剖析&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;在对全书的五个章节进行剖析之前，有必要说一说作者在序章中提及的团队发展的四个阶段，分别是“组建”（Forming）、“风暴”（Storming）、“成规”（Norming）和“高效”（Performing）。&lt;/p&gt;

&lt;p&gt;简而言之，“组建”阶段可以认为是当一个团队的成员初次集合到一起的时候，团队需要的各种协作和流程都还没有建立。一切方兴未艾。“风暴”阶段是团队的成员之间开始产生“摩擦”（Friction）。作者认为，这个阶段是团队成长的必要阶段，需要有这个阶段的“疑惑”（Confusion）和“冲突”（Clashing）来达到下一个阶段。“成规”阶段是事情慢慢得到了解决，团队成员之间的差别得到了调和。最后，“高效”阶段是整个团队有序得运行，你们开始“交付”（Ship）产品。&lt;/p&gt;

&lt;p&gt;需要指出的是，这四个阶段并不是一次性的，而是循环往复的团队生存周期。这是因为团队永远处于持续地变化中，例如有新成员加入、团队的宗旨发生了变化等。全书也算是围绕着这四个阶段来进行展开讨论的。&lt;/p&gt;

&lt;p&gt;接下来，我们针对书中的五个章节为大家进行剖析。&lt;/p&gt;

&lt;h3 id=&quot;结识你的团队&quot;&gt;结识你的团队&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/lara_1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这一章主要是讲在团队“组建”阶段，我们如何去了解团队成员的“核心需求”（Core Needs）以及他们的工作模式（Work Styles）。同时，这个阶段也需要让团队成员了解你。&lt;/p&gt;

&lt;p&gt;书中提到了六个和工作相关的“核心需求”：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一个是“归属感”（Belonging），也就是团队成员对一个社群（Community）或者团队的一种认同度，是否觉得自己是其中一员。当你觉得被团队“遗漏”（Left Out）的时候，这个“核心需求”就受到了伤害，例如团队某一个重要的会议，你没有被邀请参加，或是一个重要的产品发布没有通知你。&lt;/li&gt;
  &lt;li&gt;第二个是“进步感”（Improvement/Progress），也就是说你希望在团队中体会到某种程度上的进步或者是进展。这种进展可以是来自个人的，也可以是整个团队的。有时候，这种“进步感”可能会很难体会到，特别是在比较大的公司中。&lt;/li&gt;
  &lt;li&gt;第三个是“选择感”（Choice），也就是你是否感到对自己的生活和工作进行决策。也许你原本对自己的工作有很大的自主权，但突然公司新加入的一个负责产品的副总裁开始对你的之前计划开始发表意见。这时你可能开始感到“选择感”的失去。另一方面，如果有太多的决策需要做，也可能会造成你不知所措的情况。因此，对于“选择感”而言，我们需要注意“平衡”（Balance）。&lt;/li&gt;
  &lt;li&gt;第四个是“平等感”（Equality/Fairness），也就是你是否收到了平等的对待。当有决策通过的时候，所有参与决策的各个方面是否都有平等地接收到信息，是否平等地接收到了资源。&lt;/li&gt;
  &lt;li&gt;第五个是“预测感”（Predictability），也就是你是否能够对可预见的未来有一个初步的感知，而不是充满了“惊奇”（Surprise）。在日常工作中，大家度希望对未来有一定的把握程度。&lt;/li&gt;
  &lt;li&gt;第六个是“重要感”（Significance），也就是你个人的“地位”（Status），或者说是在团队中扮演什么样的角色，是否能够体现你的价值。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;值得注意的是，这六个核心需求对于每个人而言，并不是有同样的效果。面对一些事情，或者书中提到了“刺激物”（Stimulus），每个人可能会有非常不一样的反应。文中提到了让员工换座位这个例子来说明，这么一件看似简单的事情，有可能会“刺激”到不同人关于上述六个核心需求的反应，值得仔细阅读。&lt;/p&gt;

&lt;p&gt;这一章的第二部分，作者则是在讨论不同人的工作模式，具体说来就是遇到一些问题的时候，不同的人可能会有不尽相同的偏好。作者总结了下面五个方面的模式问题值得每一个经理逐一了解自己的员工：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;“不高兴”（Grumpiness）：什么样的事情可以可以导致员工不高兴，例如缺少咖啡因、没有睡好、不喜欢被“微观管理”（Micromanage）等。&lt;/li&gt;
  &lt;li&gt;“反馈和认可”（Feedback and Recognition）：当需要探讨反馈和认可的时候，每个人可能希望利用不同的媒介来达到目的，例如面对面、电子邮件还是即时聊天工具。特别是一些比较艰难的反馈，媒介的选择就显得尤为重要。&lt;/li&gt;
  &lt;li&gt;“目标和支持”（Goals and Support）：如何支持一个员工的成长以及如何知道员工需要怎样的支持都是作为经理和员工沟通的一个重要话题。&lt;/li&gt;
  &lt;li&gt;“员工成长”（Grow and Learn）：员工成长是一个很难以衡量的事情。然而，帮助员工成长又是经理们责无旁贷的职责。至少每一个季度都花一些时间来确定员工具体的，可以有行动的成长目标。&lt;/li&gt;
  &lt;li&gt;“款待自己”（Treat Yourself）：花时间去了解每一个员工如何款待自己的喜好，也许在未来某个时候需要奖励和表彰员工的时候能够用得上。这里面的偏好差异可能会非常大。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这一章最后的内容是帮助你的团队认识你，或者反过来说，你希望如何呈现在你的团队面前。&lt;/p&gt;

&lt;p&gt;有两个方面的话题是需要你去思考的。第一，就是你优化的目标是什么？作者认为，这一个问题直接决定了一个经理的“风格”（Style）和“管理哲学”（Philosophy）。当然，优化一个目标往往会伴随着其他目标的缺失，这是需要注意的。第二，一旦你有了优化目标之后，和团队成员交流你这些目标有助于整个团队统一思想，同时也能够帮助你的团队成员设置有效的预期。&lt;/p&gt;

&lt;h3 id=&quot;扩展你的团队&quot;&gt;扩展你的团队&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/lara_2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们之前提到的团队发展的四个阶段，这一章主要在讲“风暴”阶段团队的成长。&lt;/p&gt;

&lt;p&gt;为什么会有“风暴”阶段呢？团队在之前每一个个体的运作阶段可能并没有太多的问题。因为从本质上来说，团队并不是一个有机的整体，而是个体的集合，因此，一旦我们开始整合团队的所有人，开始设立一些流程，团队在协作、沟通等方面就都会出现广泛的“摩擦”。这几乎是可以预期的。&lt;/p&gt;

&lt;p&gt;书中说，在这个阶段，作为经理的你，需要做好下面四件事情。&lt;/p&gt;

&lt;p&gt;第一件事情，就是扮演好“导师”的角色（Mentoring），也就是直接给出建议并且帮助员工解决问题。这里，我们依靠的更多的是自己的经验。作为一名“导师”，我们需要注意的是对提供建议的人与环境有一定敏感程度。对一个人有意义的建议可能会对另一个人有伤害。另外，“导师”这个角色往往对初入角色（Role）的新人更有帮助，而对于已经有了一些成长的员工而言，更需要另外的指导手段。&lt;/p&gt;

&lt;p&gt;第二件事情，就是扮演好“教练”的角色（Coaching），也就是通过和指导对象进行对话，问“开放式”问题（Open Questions）来达到引导员工自省并且找到解决问题的方案。这个角色和“导师”是很不一样的。“导师”需要对问题以及解决方案都有所关注，而“教练”的角色则更加注重在分析问题上。两个重要的技巧是问“开放式问题”和“反思”（Reflection）。“开放式问题”必须让人觉得真诚，是你带有真正的好奇心来问的问题。这些问题有助于指导对象来进行更深层次的思考。“反思”是希望你能作为对方的一面“镜子”。把对方已经表达过的观点进行二次“翻译”，看是否能够抓住问题的核心。在这样的反复对话中，我们可以帮助指导对象来达到对当前问题的更深层次的理解和提出更好的解决方案。&lt;/p&gt;

&lt;p&gt;第三件事情，就是扮演好“支持者”（Sponsoring）的角色。如果说“导师”和“教练”是你和员工在面对面情况下互动的角色，那么“支持者”这个角色则是你在其他场合所要扮演的角色。这里的“支持”指的是你为指导对象提供并且争取机会，从而能够有力地进入到他职场的下一个层级。&lt;/p&gt;

&lt;p&gt;第四件事情，就是提供“反馈”（Delivering Feedback）。这一部分可能是最难以做好的角色。作者在这里讲了一个“反馈”公式。也就是，我们提供反馈需要首先来自某种行为的“观察”（Observation），然后我们需要描述这个行为的“影响”（Impact），接着，我们需要直接说出需要改变的事情或者是进入“教练”的角色，开始问一些开放式问题，最后，我们需要达到非常具体的，能够执行的反馈。&lt;/p&gt;

&lt;p&gt;在日常的工作中，我们经常需要对这四种角色进行有机得结合，并且在这些角色之间频繁互换。当然，书中也讲了，并不是这些手段都能够永远有效，总有员工可能并不理会你和他互动的好意，因此书中也讲了讲其他的渠道。&lt;/p&gt;

&lt;h3 id=&quot;设置明确的期望&quot;&gt;设置明确的期望&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/lara_3.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这一章主要在讲“成规”阶段的团队发展话题。&lt;/p&gt;

&lt;p&gt;顾名思义，无规矩不成方圆，当团队发展到一定程度，就需要设置一些规则和流程来保证团队运行的顺畅和解决分歧。&lt;/p&gt;

&lt;p&gt;这一章一开始主要讲了如何定义团队中的“角色和职责”（Roles and Responsibilities）。在团队发展的早期，都没有真正定义不同角色和职责的实际需要，一是因为人比较少，二是因为很多时候需要有人能够兼顾多种不同的角色从而能够达到某种情况下的灵活度。然而，随着团队的发展，每个人在日常运行中究竟是什么角色，不同人之间怎么协作，就需要我们开始思考这方面的问题。&lt;/p&gt;

&lt;p&gt;书中介绍了RACI角色定义方法和“维恩图表”（Venn Diagram）来定义“角色和职责”并且用了“工程经理”（Engineering Manager）、“产品经理”（Product Manager）以及“工程负责人”（Engineering Lead）如何建立清晰的职责界限来解释了这些方法的实际使用方法，建议读者精读这部分内容。&lt;/p&gt;

&lt;p&gt;这一章的第二部分讲了如何设置一个团队的“视野”（Vision）以及“优先级”（Priorities）。“视野”是回答你们这个团队为什么存在，究竟是要解决什么终极问题，这样的疑问。这里细分的话，有“视野”（Vision）、“使命”（Mission）、“策略”（Strategy）以及“目标”（Objective）的区别。简单来说，这几类定义是从最宏观到最微观的逐层表述。书中有详细的解释，建议大家读一读。有读者可能会问，对于一个团队来说，设置这些空洞的宏大的主题是否有实际的意义。这里的目的是让一个团队有章可循，特别是团队有任何分歧、有疑虑的时候都随时能够根据团队的“视野”和“优先级”来排除这些纷扰。&lt;/p&gt;

&lt;p&gt;这一章的第三部分讲的是团队的“实践”（Practice）。这一部分主要是指一个团队日常运作的模式，包括有什么样的会议以及交流的渠道（邮件或者即时通讯工具），和这些运作模式都是处理哪些问题。作者认为，即便每一个团队在具体的实践中可能都有了约定俗成的一套流程，最好能够利用文档工具（例如“维基”Wiki）来把这些实践记录下来。同时，作者认为，需要把团队的协作和交互给融合到日常的运作中去。&lt;/p&gt;

&lt;h2 id=&quot;有效的沟通&quot;&gt;有效的沟通&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/lara_4.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在现代团队发展和运作过程中会遇到大大小小的很多事情，例如公司的目标发生了变化、公司开始经历裁员、新的产品线、公司上市等等。所有这些事情，作为一个经理，你都需要和员工保持良好有效的沟通。有不小挑战性的是，很多这些事情，你并不是直接的决策者，甚至也没有参与其中，但作为当前团队的负责人，你需要有很清晰的头脑如何和团队进行交互和沟通。&lt;/p&gt;

&lt;p&gt;书中首先介绍了如何来规划沟通一些重要的信息。很明显，你需要一个计划。作者介绍了一些沟通计划的模板。总而言之，这些模板的目的是帮助你能够为一些相对复杂的情况有一个更加全面的沟通有所准备。书中作者用一个虚拟的经理离职作为例子，展示了如何为这样一个可能会比较棘手的事件进行沟通准备。&lt;/p&gt;

&lt;p&gt;在这一章的第二部分，作者讲了讲对敏感信息沟通的技巧。敏感信息的挑战来自于可能会触及一些员工的核心需求。比如，我们要沟通一次组织架构的调整，团队的工作方向也许会有调整，那么一些员工的“选择感”和“预测感”都会受到不小的影响。一些员工可能会觉得自己的意见或者声音没有得到抒发的机会。作者认为，敏感信息沟通的核心来自于“迅速”（Swift）而不是拖延好几天甚至是更长时间。有很多事情有可能在更长的等待中发生变化，也就是我们经常说的“夜长梦多”。同时，如何有效得分享一些机密信息，也是需要特别注意拿捏分寸的事情。在一个较大的公司和团队中，任何机密的信息都有可能被泄露出去，作者认为在这种时候，首要任务是沟通并且阐明一些事情的事实，而事后对有可能把机密信息泄露这样的事情进行反思。&lt;/p&gt;

&lt;p&gt;本章的第三个部分，作者探讨了一下，作为经理的你，如何沟通你并不十分认可的决定。在一个比较大的公司中，这样的情况其实比比皆是。公司有很多决策或者变化无法邀请所有人参与。这一方面是不现实一方面也没必要。因此，在公司的运作中，我们就需要学会传达和沟通我们自己并不认同的决定。这里的核心是做到“不认同但负责”（Disagree and Commit）这样一种职业态度。也就是说，虽然你对于某一些决策的内容并不能完全认可，但是你需要去完全执行这些决策的内容并且利用沟通的技巧和团队进行沟通。不过，作者也提出，这种时刻，也是你重新审视自己和当前的团队以及公司还是否能够契合到一起，如果有重大的分歧，离开这样的团队和公司可能是更好的选择。&lt;/p&gt;

&lt;p&gt;本章的第四部分作者讲了讲不同媒介的区别，例如会议、邮件以及即时通讯工具，都具有自身不同的特点，适用于沟通不同的内容。比如，一些重大的决定或者是变化，最好能够通过面对面的会议，甚至是“全公司会议”（All Hands Meeting）来首先传达。而另一方面，邮件沟通可以传达一些没有太多歧义内容的信息，并且能够起到提醒人的作用。&lt;/p&gt;

&lt;p&gt;最后，作者强调，沟通不是一次性的工作，而是本身就需要反复迭代和演化的工作。也就是说，我们需要反复重复重要的信息，在很多场合，和很多媒介。同时，每个公司可能对于如何沟通有不同的企业文化的偏好。&lt;/p&gt;

&lt;h2 id=&quot;构建韧性管理&quot;&gt;构建韧性管理&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/lara_5.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;作者把最后一章的内容献给了如何让当经理的人自身更加富有“韧性”。也许你的团队已经到达了“高效运行”的阶段，但是一个突然的变化，使得你做的很多工作回归原点。千万不要以为变化是一时的，作者认为，处在高速发展的科技公司中，变化是随时随地都在发生的。因此，如何让经理变得更有“韧性”，也就是如何处置随时的变化，以及一一种不变应万变的心态就成为了很重要的议题。&lt;/p&gt;

&lt;p&gt;这一章一开始，作者讨论了如何管理危机时刻（Times of Crisis）。这里的关键是了解你有什么样的资源和工具。每一个公司对待很多情况都有相应的流程。对这些流程有所了解，是你需要处理危机的必备信息。另一方面，是和员工有良性的和真挚的沟通，让他们觉得你是可以依赖的伙伴。&lt;/p&gt;

&lt;p&gt;这一章的第二部分，则在讨论如何管理你自己的“能量”。简而言之，那就是如何能够使自己保持一个正能量的心态。作者的一个建议是时刻关注我们被什么样的事情所消耗时间和精力。也就是看看自己的日历，平时都参加什么样的会议。这里，需要你对自己的时间有一个深层次的了解以及有一些如何应对这些事物的想法。然后，书中介绍了不少的技巧，可以用于管理自己的时间使自己更高效，例如重新安排自己的任务，把一部分任务给代理出去、对一些事情说“不”等等。读者可以好好阅读一下这部分内容。&lt;/p&gt;

&lt;p&gt;本章的最后是探讨如何构建自己的“支持网络”（Support Network）。作为一个经理而言，“你不是一个人在战斗”，但往往，我们可能觉得自己是“孤家寡人”。作者提出了“支持网络”这个概念，也就是说，我们需要去构建自己的网络来获取更多的信息，学习更多的技能，以及扩宽自己的社交网络。同时，作者也提到了“第一团队”（The First Team）的概念，也就是当发生任何变化以及需要做一些复杂决策的时候，你最先寻求帮助和信息的人都是什么人，而这些人都能够提供哪一些不同的视角。这一部分内容可以算是经理职业发展的高级话题。&lt;/p&gt;

&lt;h2 id=&quot;总结点评&quot;&gt;总结点评&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这本书可以说是作为技术管理人的经典入门的参考书。作者Lara Hogan作为在工业界有丰富经验的技术经理人写作的次数可以说是有非常强的实战指导价值。书中有不少可以直接拿来用的技巧、模板和方法。同时，书中的一些案例也是来源于实际工作。与同类型的&lt;a href=&quot;http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2019/12/25/the-manager-path/&quot;&gt;《经理人之路——技术领袖启航成长与变化的参考书》&lt;/a&gt;相比，本书更加短小精悍，并且非常适合需要对技术管理快速入门的初级技术管理人员。从结构上看，全书的五个章节都相对独立但又和在序章中讲到的团队的发展历程的几个阶段有着紧密的联系。建议对技术管理有兴趣的读者精读。&lt;/p&gt;
</description>
        <pubDate>Thu, 09 Jul 2020 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2020/07/09/resilient-management/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2020/07/09/resilient-management/</guid>
        
        
        <category>读书笔记,管理</category>
        
      </item>
    
      <item>
        <title>《从数据中学习》总结</title>
        <description>&lt;p&gt;今天我们要来总结技术书籍&lt;a href=&quot;https://www.amazon.com/Learning-Data-Yaser-S-Abu-Mostafa/dp/1600490069&quot;&gt;《从数据中学习》&lt;/a&gt;。这本书是一本浅显易懂的机器学习理论知识的入门教材。对于机器学习感兴趣的工程师和希望在理论知识上更进一步的数据科学家可以通过本书来快速了解机器学习的核心思想，也就是“学习理论”（Learning Theory）的重要结论。本书的三位作者都来自学术界。全书书写通畅，公式和理论推导也很基础，适合自学的初学者。&lt;/p&gt;

&lt;h2 id=&quot;作者简介&quot;&gt;作者简介&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/learningfromdata.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本书有三位作者。&lt;/p&gt;

&lt;p&gt;第一作者&lt;a href=&quot;https://work.caltech.edu/&quot;&gt;Yaser Abu-Mostafa&lt;/a&gt;是加州理工学院&lt;a href=&quot;https://www.caltech.edu/&quot;&gt;（California Institute of Technology）&lt;/a&gt;电子工程与计算机系的教授。Yaser于1979年从开罗大学学士毕业之后于1981年从佐治亚理工学院获得硕士学位，然后于1983年从加州理工学院获得博士学位。Yaser和他人于1987年筹办了第一届此后享有盛誉的神经信息处理系统大会（NeurIPS）。&lt;/p&gt;

&lt;p&gt;第二作者&lt;a href=&quot;https://www.cs.rpi.edu/~magdon/&quot;&gt;Malik Magdon-Ismail&lt;/a&gt;是伦斯勒理工学院&lt;a href=&quot;https://www.rpi.edu/&quot;&gt;（Rensselaer Polytechnic Institute）&lt;/a&gt;计算机科学系的教授。Malik于1993年从耶鲁获得物理学士学位，然后分别于1995年和1998年从加州理工学院获得物理硕士和计算机博士学位。&lt;/p&gt;

&lt;p&gt;最后一个作者&lt;a href=&quot;https://www.csie.ntu.edu.tw/~htlin/&quot;&gt;Hsuan-Tien Lin&lt;/a&gt;是国立台湾大学计算机和信息工程系教授。Hsuan-Tien于2001年从国立台湾大学获得计算机和信息工程系学士然后于2008年从加州理工学院获得计算机博士学位。&lt;/p&gt;

&lt;h2 id=&quot;全书结构&quot;&gt;全书结构&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;全书大体有下面五个章节&lt;/p&gt;

&lt;p&gt;第一章，是对于“学习问题”（The Learning Problem）的一个总体的设置和介绍。这部分介绍了不同类型的“学习场景”，例如“监督学习”（Supervised Learning）、“强化学习”（Reinforcement Learning）以及“无监督学习”（Unsupervised Learning），以及最重要的内容“学习”的“可行性”（Feasibility）。&lt;/p&gt;

&lt;p&gt;第二章，是进一步展开“学习”的“可行性”方面的内容，详细来探讨“泛化理论”（Theory of Generalization），也就是我们常说的为什么我们能够通过“训练集”（Training）上的一些结论来扩展到“测试集”（Testing）甚至是未知的数据上。在这一章，作者们介绍了重要的“VC维度”（The VC Dimension）以及如何理解“泛化界限”（Generalization Bound）。&lt;/p&gt;

&lt;p&gt;第三章，作者们详细介绍了最简单的模型“线性模型”（The Linear Model）。这其中包括了针对回归问题的“线性回归”（Linear Regression）以及分类问题的“对数几率回归”（Logistic Regression）。&lt;/p&gt;

&lt;p&gt;第四章，作者们详细的阐述了关于“过拟合”（Overfitting）的观点。在其他教材中，“过拟合”的内容往往是简单带过，和“线性模型”类似，这本书对于“过拟合”的讲解可以说是非常有阅读价值。&lt;/p&gt;

&lt;p&gt;第五章，作者们讲解了三个重要的“学习”原理（Learning Principles）：“奥卡姆剃刀”（Occam’s Razor）、“采样偏差”（Sampling Bias）和“数据窥探”（Data Snooping）。如果在实践中不注意这些问题，那之前讲的“泛化保证”则不能提供有效的理论支持。&lt;/p&gt;

&lt;p&gt;整本书可以说是把“学习理论”（Learning Theory）中的重要概念以及机器学习的核心思想深入浅出得进行了讲解，非常适合机器学习的初学者。&lt;/p&gt;

&lt;h2 id=&quot;内容剖析&quot;&gt;内容剖析&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;我们接下来就针对书中的一些重点内容为大家进行剖析。&lt;/p&gt;

&lt;h3 id=&quot;从训练集到未知数据的泛化历程&quot;&gt;从训练集到未知数据的泛化历程&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/lt.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;经典的“监督学习”设置可以简化为如何通过一组数据输入$ \mathbf{x} $来学习一个未知函数$ f $。这里面有两个难点，一是我们对$ f $一无所知，二是数据有限。如何能够构造出一套理论来对于这样一个问题进行描述成为了机器学习需要解决的核心问题，也就是“学习”的“可行性”问题。&lt;/p&gt;

&lt;p&gt;书中在第1.3节解决了“学习可行性”的第一个障碍，也就是把“概率化”的语言引入关于“可行性”的讨论中。直观得说，希望能够“确定性”得学习一个未知的$ f $是很难的，我们没有数学工具来对这样的场景提供有效的结论。但如果我们用概率的眼光来看，则可以针对学习$ f $的精准度进行严格地描述。这个根本性的思路来自于对于随机事件的理解。例如有一个瓶子里放着一定数量的红球和一定数量的白球。如果我们的任务是根据已经从瓶子里拿出的一些球是否是红色或者白色来确定性得估计红球和白球的比例，这是没有保证的。但如果我们以一定正确的概率去估计红球和白球的比例则有定量的结论。&lt;/p&gt;

&lt;p&gt;这个定量的结论来自于概率论中的“霍夫丁不等式”（Hoeffding Inequality）:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(|\bar{X} - \mathbb{E}[X] | &gt; \epsilon ) \leq 2e^{-2\epsilon^{2}N}&lt;/script&gt;

&lt;p&gt;这里，$ X $是一个随机变量，$ \bar{X} $是这个随机变量的均值，然后$ \epsilon $是一个误差项。简单说来，“霍夫丁不等式”对于样本均值作为参数的估计值和参数真值之间的差距给出了一个“界限”（Bound）。这个“界限”和样本数据量$ N $有关，并且随着数据的增多，参数的估计值和真值的差距大于一个事先约定的范围的可能性会以指数方式降低。这个结论的魅力来自于我们并不需要知道参数真值，我们只需要进行操作的是作为参数估计值的样本均值。另外，这个结论的优势在于它是概率意义上的。也就是说，我们并不能100%确保估计准确，但是准确性的保证来源于随着数据增多而减小的可能性。这个可能性虽然很小但一直存在。&lt;/p&gt;

&lt;p&gt;把“霍夫丁不等式”应用到机器学习的场景我们需要两个概念。一个是根据样本数据集得来的“样本内误差”（In-Sample Error）:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{in}[h] = \frac{1}{N} \sum_{n=1}^{N} \mathbb{I}(h(\mathbf{x}_{n}) \neq f(\mathbf{x}_{n}))&lt;/script&gt;

&lt;p&gt;这里的$ h $是对于$ f $的一个估计，然后$ \mathbb{I}(x) $在$ x $的时候等于$ 0 $另一个则是在全数据集上的“样本外误差”（Out-of-Sample Error）：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{out}[h] = P(h(\mathbf{x}) \neq f(\mathbf{x}))&lt;/script&gt;

&lt;p&gt;我们无法衡量“样本外误差”，但是根据“霍夫丁不等式”，我们可以对其利用“样本内误差”进行估计，并且估计的错误率是一个随着样本数据量N增大而指数式减小的数值:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(|\mathbb{E}_{in}[h] - \mathbb{E}_{out}[h] | &gt; \epsilon ) \leq 2e^{-2\epsilon^{2}N}&lt;/script&gt;

&lt;p&gt;这可以说是“学习理论”的第一大步。我们可以利用样本数据集上的估计来针对参数的真值进行描述。接下来遇到的困难来自于，刚才所说的“样本内误差”和“样本外误差”都依赖于我们选择的某一个特定的“假设”（Hypothesis）$ h $。也就是说，我们如果要估计$ f $，我们只要选择一个$ h $，就能利用“霍夫丁不等式”来对$ h $和$ f $的“样本外误差”进行评估。但是，很明显，我们需要评价具有可能性的$ h $的总数目也许是无限多，这就造成了一个重大难题。在我们讨论无限数目的假设空间之前，作者们展示了“霍夫丁不等式”可以被推广到有限数目$ M $的情况，也就是参数的估计值和真值之间误差的“界限”是一个同时和$ N $以及$ M $有关的数量:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(|\mathbb{E}_{in}[g] - \mathbb{E}_{out}[g] | &gt; \epsilon ) \leq 2Me^{-2\epsilon^{2}N}&lt;/script&gt;

&lt;p&gt;注意，这里的$ g $和$ h $有所不同，书中详细讲了两者的关系，我们这里的讨论可以忽略这个差别。下面的进展需要我们拿掉对于$ M $的依赖。&lt;/p&gt;

&lt;p&gt;第一个观察来源于我们对于所有M甚至是无限数目的假设空间的一个洞察，那就是这些假设往往很类似。在第2章里，作者们开始阐述我们需要真正在意的是有效的假设数目（Effective Number of Hypotheses）而不是所有的甚至是无限多个假设数目。这里一个巧妙的构造来自于我们理解一个假设h的视角并不专注于这个假设本身而在于这个假设在一个数据集上的表现。也就是说，我们通过数据来观察一个假设的表现。对于一个二分问题（Binary Classification），无论假设本身如何，我们都可以在一个给定的数据集上获得一个假设在这个数据集上作用所得到的一些“正例”和“负例”的判别结果。而两个不同的假设很可能在一个数据集上产生的“正负例”判别结果是一样的。我们把一组“正负例”结果叫做一个“二分”（Dichotomy）。那么，一个包含很多假设的“假设集合”就对应一个包含众多“二分”的“二分集合”。我们把一个数据集N上能够通过某个假设集合H所产生的最多的二分集合数目定义为“增长函数”（Growth Function）在这个数据集和假设集合上的取值。换句话说，“增长函数”是一个依赖于数据集和假设集合的函数。如果一个假设集合H可以产生一个数据集上所有可能的“二分”，我们就说这个假设集合H“散开”（Shatter）了这个数据集。回到之前提到的问题，那就是我们希望替换掉“霍夫丁不等式”中对于$ M $的依赖。整个这个部分的讲述就是要引出“增长函数”这个重要的工具。&lt;/p&gt;

&lt;p&gt;有了“增长函数”的概念之后，我们肯定希望“增长函数”是有一个上界的，而这个上界最好和假设集合的总数目没有关系。这样，我们就可以达到目的从而让参数的估计值和真值之间的误差和我们需要评价的假设数目最好没有关系。&lt;/p&gt;

&lt;p&gt;为了解决这个问题，我们就要引入最后一个重要定义。那就是“VC维度”。一个假设集合H的“VC维度”（VC Dimension）是这个假设集合所对应的“增长函数”等于$ 2^{N} $所能对应到的最大的$ N $值。形象地说，也就是我们不断增大$ N $，看假设集合H能否“散开”当前$ N $所对应的数据集，如果是，那就继续增大，直到最后一个可以“散开”的$ N $值。如果我们对于所有的$ N $值，我们总能“散开”当前N所对应的数据集，我们就定义“VC维度”为无限。&lt;/p&gt;

&lt;p&gt;对于初学者来说，这一部分的内容概念比较密集而且抽象。作者们很快举了几个例子来说明“增长函数”以及“VC维度”在某一些特定的数据集上的存在以及给出了它们的表达式。&lt;/p&gt;

&lt;p&gt;下面的一个难点就在于如何把“增长函数”给“界限”住。书中有不少的细节。我们这里直接引述结论，那就是如果对于某个假设集合$ H $我们可以找到“VC维度”，“增长函数”就有一个上限。这个上限是一个和N以及“VC维度”有关的多项式加和公式。简而言之，那就是“增长函数”在这样的情况下是被“VC维度”所“界限”住的。有了这些基石之后，作者们就推出了书中最重要的结论（公式2.21），我们在这里重复出来：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbb{E}_{out}[g] \leq \mathbb{E}_{in}[g] + \sqrt{\frac{8}{N}\ln \frac{4m_{N}(2N)}{\delta}}&lt;/script&gt;

&lt;p&gt;公式的证明并没有在正文中，而是放到了附录里。但是公式的核心思想就是我们之前提到的“样本中误差”和“样本外误差”的关系被一个带有“增长函数”的不等式所“界限”。这个不等式和我们之前所说的“霍夫丁不等式”非常类似，只是其中没有了对于$ M $的依赖，而变成了对于“增长函数”的依赖。有了这个重要的工具之后，再加上上面所说的我们利用“VC维度”对于“增长函数”进行“界限”。我们就更进一步得到了一个“样本中误差”和“样本外误差”的关系被“VC维度”所“界限”的结论。而这个结论就具备可操作性了，因为很多情况下，我们可以直接计算“VC维度”。&lt;/p&gt;

&lt;p&gt;这部分的讲解（整个第2章）可以说深入浅出得介绍了“学习理论”中最重要的一组结论。&lt;/p&gt;

&lt;h3 id=&quot;机器学习的噩梦过拟合&quot;&gt;机器学习的噩梦——“过拟合”&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/overfit.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本书在第4章详细探讨了机器学习中“过拟合”（Overfitting）的现象以及一些解决方案。&lt;/p&gt;

&lt;p&gt;首先，书中利用一些例子来展示了“过拟合”现象的存在性，那就是有的模型可以在训练集上获得非常小甚至是零的“样本内误差”但在训练集之外有着非常惊人的“样本外误差”。换句话说，这些模型只有很弱的甚至是没有“泛化”能力。这种“过拟合”的现象在对于一个相对简单的模型和一个相对复杂的模型进行比较的时候会显得尤为明显。比如书中利用一个10阶多项式函数来产生一组有噪声的数据，然后利用一个2阶多项式和另一个10阶多项式来拟合产生的数据。如果我们来比较两个模型的“样本内误差”则可以发现10阶多项式好像能够更好得拟合10阶多项式所产生的训练数据。然而令人吃惊的是，如果我们来比较两个模型的“样本外误差”，则会发现2阶多项式相比于10阶多项式有更好的“泛化”能力。这里面可能会让人疑惑的就是，按理说，我们利用10阶多项式来拟合10阶多项式产生的数据应该会比2阶多项式有更好的“泛化”能力，因为这里相当于是利用了“真模型”（Ground Truth）的信息。书中提供的一种解释是虽然10阶多项式作为“真模型”这个信息有价值之处，但是总体而言，10阶多项式相比于2阶多项式需要更多的数据来拟合，同时对于有噪声的数据，复杂模型更容易去拟合数据中的噪声，从而导致了弱化的“泛化”能力。&lt;/p&gt;

&lt;p&gt;机器学习中，一个经常使用的来减弱“过拟合”现象的工具叫做“正则化”（Regularization）。书中提醒，绝大多数“正则化”的方法都是“启发法”（Heuristics）。也就是说，这些方法可能并没有太多的理论基础，而是在实际使用中有比较好的效果。书中介绍了“权重衰减”（Weight Decay）这种“正则化”方法。简单来说，“权重衰减”就是指，我们把模型中学习到的参数，或者叫系数，或者叫权重，人为得进行数值上的“衰减”，也就是使其变小，甚至是归零。这种做法的初衷是让学习算法不因为一些数据中的异常值，通常是噪声，来误导模型学习到过大的权重。“权重衰减”往往会通过更改目标函数（Objective Function）的方式来达到同时拟合数据以及让参数变小这两个目的。&lt;/p&gt;

&lt;p&gt;针对“过拟合”的另外一个工具是构造一个“验证集”（Validation）。“验证集”和“测试集”非常类似，也就是这部分数据不能用作模型的训练。“验证集”和“测试集”的区别在于，这部分数据可以用于对于模型的一些决策，例如帮助选择模型的参数。在日常的机器学习实践中，我们经常利用K个“验证集”来进行模型选择或者参数选择的流程，从而达到减小“过拟合”的效果。&lt;/p&gt;

&lt;h3 id=&quot;三大学习原理&quot;&gt;三大学习原理&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/or.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在本书的第5章，也就是全书的最后，作者们总结了三个重要的机器学习原理。&lt;/p&gt;

&lt;p&gt;第一个原理是“奥卡姆剃刀”。简单说来“奥卡姆剃刀”讲的是，能够拟合数据中的最简单的模型往往是最有道理的。这个原理还可以被说成，在能够拟合数据的众多模型中，我们往往更偏向于简单的那个。需要说明的是，如何衡量模型的简单与否，或者说如何衡量模型的复杂度，是一个值得探讨的问题。例如书中讲过的VC维度以及“正则化”所代表的误差项等都是某种衡量模型复杂度的方法。另外，“奥卡姆剃刀”也提供了一种在实践中经常使用的方法，那就是对于一组数据，我们往往先开始尝试使用简单模型进行拟合，然后逐渐把模型复杂化，看是否能够增强拟合，同时注意“验证集”的错误率。&lt;/p&gt;

&lt;p&gt;第二个原理是“样本偏差”，指的是如果数据是通过有偏差的采样所获得的，那么学习也会产生类似的有偏差的结果。“样本偏差”有时候非常难以发现。例如，书中举了一个例子，那就是我们利用华尔街的股票数据进行建模，可能会找到模型能够很好得拟合过去的股票高低起伏信息。然而这样的模型是带有很大的偏差的，原因就是，华尔街这十几年表现不好的股票有可能已经退市，而如果我们选择数据中仅仅包含一直存在的股票，这本身就是一种选择性“偏差”。&lt;/p&gt;

&lt;p&gt;最后一个原理叫“数据窥探”。简而言之，“数据窥探”是说如果一个数据集影响了学习算法的任何一个流程，那么这个数据集对于结论的有效性就已经也受到了影响。这是在机器学习实践中经常遇到的陷阱。换句话说，我们要杜绝“测试集”的信息“泄露”并且影响到我们学习算法的任何一个流程。例如，我们首先看了数据貌似符合线性规律以后，然后采用线性模型进行拟合；再例如，我们利用了“测试集”数据和“训练集”数据一起对整个数据集进行一些数据预处理。更普遍的陷阱来源于，对同一个数据集反复使用，也就是说，在不同数据集上反复测试不同的算法，直到找到测试数据集上表现好的模型位置。书中重点解释了这样做的结果就是理论上我们推导的VC维度无法来对结论进行“泛化”保证。&lt;/p&gt;

&lt;h2 id=&quot;总结点评&quot;&gt;总结点评&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这本书可以说是作为机器学习入门的一个参考教材。和大多数希望涵盖众多内容的机器学习通用教材相比，本书可以说是短小精悍，而且专注在机器学习、特别是学习理论（Learning Theory）方面最基本的介绍。整本书的行文非常通顺而且理论证明部分也毫不晦涩，非常适合有了一定机器学习基础，又希望能够在理论上有所了解的工程师和数据科学家。&lt;/p&gt;
</description>
        <pubDate>Thu, 25 Jun 2020 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0,%E6%95%99%E6%9D%90/2020/06/25/learning-from-data/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0,%E6%95%99%E6%9D%90/2020/06/25/learning-from-data/</guid>
        
        
        <category>读书笔记,机器学习,教材</category>
        
      </item>
    
      <item>
        <title>《值得信赖的在线可控实验——A/B实验实用向导》总结</title>
        <description>&lt;p&gt;今天我们要来总结技术书籍&lt;a href=&quot;https://doi.org/10.1017/9781108653985&quot;&gt;Trustworthy Online Controlled Experiments: A Practical Guide to A/B Testing&lt;/a&gt;。这本书的三位作者在业界享有盛誉，他们在在线可控实验、实验平台的搭建和运维以及如何构建数据驱动化的公司企业文化有着丰富的经验。全书是数据科学家、机器学习工程师、产品经理以及一切对在线可控实验有兴趣的研发人员的必读参考书，是技术书籍领域的经典。&lt;/p&gt;

&lt;h2 id=&quot;作者简介&quot;&gt;作者简介&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/onlinetests.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;本书有三位作者，都是来自互联网公司从事在线实验运行、管理和研究工作多年的专业人员。&lt;/p&gt;

&lt;p&gt;第一作者&lt;a href=&quot;https://www.linkedin.com/in/ronnyk/&quot;&gt;Ron Kohavi&lt;/a&gt;在成书时担任Airbnb的副总裁和技术院士（Technical Fellow）。之前Ron长期担任Microsoft的集团副总裁和技术院士，负责在线实验平台的工作。在加入Microsoft之前，Ron担任Amazon数据挖掘和个性化方面的总监。Ron于斯坦福大学获得计算机博士学位，他有非常丰富的学术论文发表经历，有很多关于在线可控实验方面的经典之作以及帮助扩大这方面研究影响力的课程和演讲。&lt;/p&gt;

&lt;p&gt;第二作者&lt;a href=&quot;https://www.linkedin.com/in/diane-tang-2a2477/&quot;&gt;Diane Tang&lt;/a&gt;在成书时是Google的技术院士（Technical Fellow），专注于大规模数据分析以及基础设施、在线可控实验和广告系统的研发。她于斯坦福大学获得博士学位。下文要提到的“并发实验”的架构就是Diane（和其他合作者）于2010年的KDD上首次提出。&lt;/p&gt;

&lt;p&gt;第三作者&lt;a href=&quot;https://www.linkedin.com/in/ya-xu-59346919/&quot;&gt;Ya Xu&lt;/a&gt;在成书时是负责LinkedIn的数据科学和实验平台系统的资深总监，之前在Microsoft任职。Ya于斯坦福大学获得统计博士学位，其发表过诸多关于在线可控实验的论文并且经常在诸多顶级学术与工业界的会议中发表演讲。&lt;/p&gt;

&lt;h2 id=&quot;全书结构&quot;&gt;全书结构&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;全书大体上可以分为以下五部分内容。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一部分，是对于“可控实验”（Controlled Experiments）基础知识和信息的介绍。作者们讲解了什么是可控实验和为什么要做可控实验等基础问题后，利用一个虚构的电商网站测试界面的例子完整得展示了如何设置和分析一个在线可控实验的全流程。同时，作者们开始介绍一些理解实验结果的“陷阱”和“谬误”，为后面章节详细介绍针对这些问题的解决方案打下基础。最后，作者们讨论了“实验平台”（Experimentation Platform）和公司文化对于如何利用实验来建立“数据驱动”（Data Driven）文化的必要关系。&lt;/li&gt;
  &lt;li&gt;第二部分，是几个有针对性的专题，主要探讨了速度对于网站运行的重要性、“指标”（Metric）的选取以及如何建立“机构记忆”（Institutional Memory）等。&lt;/li&gt;
  &lt;li&gt;第三部分，是探讨了当可控实验变得不可能的时候，如何使用现有的数据进行&lt;a href=&quot;https://en.wikipedia.org/wiki/Observational_study&quot;&gt;“观察研究”（Observational Studies）&lt;/a&gt;。这部分技术是对可控实验的有效补充。&lt;/li&gt;
  &lt;li&gt;第四部分，是针对实验平台的高级内容，包括如何运行“客户端”（如手机）的实验、如何进行“检测设置”（Instrumentation）、如何选择“随机化单元”（Randomization Unit）、如何“发布实验”（Ramping Experiment）以及如何规模化实验分析。&lt;/li&gt;
  &lt;li&gt;第五部分，是针对实验分析的高级内容，包括如何进行统计统计假设检验、“方差缩减”（Variance Reduction）、A/A实验、如何处理“样本比率偏差”（Sample Ratio Mismatch）以及衡量“长期效果”（Long-Term Treatment Effects）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;整本书可以说是包含了丰富的经验之谈和理论论述。&lt;/p&gt;

&lt;h2 id=&quot;内容剖析&quot;&gt;内容剖析&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;我们接下来就针对书中的一些重点内容为大家进行剖析。&lt;/p&gt;

&lt;h3 id=&quot;数据驱动的企业文化&quot;&gt;数据驱动的企业文化&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/datadriven.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在线A/B实验已经成为了今日互联网和软件工业中必不可少的数据驱动工具。很多公司把是否应用在线实验当做一个公司是否数据驱动的一个试金石。本书用了“爬”（Crawl）、“走”（Walk）、“跑”（Run）以及“飞”（Fly）四个阶段来对公司如何利用在线实验来达到数据驱动的成熟程度进行了分类（第4章）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;“爬”这个阶段主要是公司对最基本的检测设置和数据科学能力进行搭建。在这个阶段的实验平台主要是解决能够进行实验的设计、执行和分析。团队可以并且已经运行了一些实验。这些成功的案例有助于进行到下一个阶段。&lt;/li&gt;
  &lt;li&gt;“走”这个阶段主要是从可以运行少量的实验到定义一系列标准指标并且开始运行更多的实验。在这个阶段，团队开始运行更加复杂的一些检测来持续验证“检测设置”并且能够通过运行A/A实验来验证平台潜在的问题，同时能够进行“样本比率偏差”检测。&lt;/li&gt;
  &lt;li&gt;“跑”这个阶段对于团队来说，已经可以运行大量的实验，并且各种指标也都相对成熟。公司能够利用“综合评测指标”OEC（Overall Evaluation Criterion）来进行多个指标之前的权衡。整个组织利用实验来对绝大多数的新功能和改动进行测试。&lt;/li&gt;
  &lt;li&gt;“飞”这个阶段则是团队的几乎所有改动都需要经过在线实验的验证。“功能团队”（Feature Teams）已经可以在没有数据科学家的辅助下对大多数的实验进行独立的分析和运作。整个平台的专注点转移到了大规模自动化以及建立“机构记忆”上。同时通过对过去实验的分析，整个平台的有效性和针对实验运行的最佳实践也能够得到不断得更新。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;书中强调团队不管在哪个阶段，领导在多个层面的支持（Buy in）是团队能够成功的重要因素。同时，在建立真正的数据驱动团队的过程中，领导的意见（也就是所谓的Highest Paid Person’s Opinion）和完全依靠直觉的产品开发都是需要逐渐被大规模实验和数据驱动所替代的。因此，在这个过程中，领导需要建立起机制来帮助团队慢慢过渡到“飞”这个阶段。除了领导的支持，书中强调了机制和“机构记忆”的重要作用。也就是说，平台和分析本身只是有效的数据驱动团队的重要组成部分，但团队说到底还是人与人协作的平台。因此，书中（第四章）提到了很多有效的机制来帮助团队拥抱实验文化，例如在团队内部开发关于实验平台和实验分析的课程让更多的人能够接触到这样的知识和技能；再例如在实验平台发展的早期举行例行的会议来针对实验的假设、不同“指标”之间的取舍等进行讨论从而加强这部分企业文化的建设。&lt;/p&gt;

&lt;p&gt;作者们也给出了作为企业希望利用在线实验来达到数据驱动的三个重要的条件（第1章）。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一个条件是企业希望利用数据进行决策并且希望能够通过标准化OEC。换句话说，一个企业希望把对于前进目标的讨论和取舍都能够融入一个标准化的OEC并且能够清晰得让整个企业都理解和为之奋斗。&lt;/li&gt;
  &lt;li&gt;第二个条件是企业愿意为实验平台等基础设施以及实验结果的可信性进行投资。我们前面提及了企业在应用实验来进行决策的几个阶段。很明显，每一个阶段都有软件、组织流程和企业文化等方面的持续投入。这里面，作者们专门提到了实验结果的可信性。也就是说，得到数字容易，但是能够得到让人信赖的数字则需要下不小的功夫。&lt;/li&gt;
  &lt;li&gt;第三个条件是企业愿意承认自己对于不同的想法很难确定它们的价值。这一点尤为重要，在书中被反复提及。首先，这个观点的第一层信息是作者们观察到很多企业，即便是运行大量实验的成熟企业例如微软，也只有近30%的实验结果是正向积极的，能够最终发布到整个的网站。其次，这个观点的第二层信息就是对于单个想法，很多时候我们都很难去衡量它的好坏。作者举了好一些例子展示一些积极有价值的想法在早期都得到了不小的忽视。&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;实验平台的架设&quot;&gt;实验平台的架设&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/exps.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A/B在线实验的思想非常直观，但这并不代表实验平台的搭建和演化是一件容易的事情。实验平台有诸多方面需要很细致的关注，而一些微小的决策错误往往可能带来完全不可信的实验数据。可以说是细节决定成败。&lt;/p&gt;

&lt;p&gt;书中谈到的一个可以说是非常有意思的有关实验平台的“陷阱”（第3章）那就是利用“页面跳转”（Page Redirect）来实现针对“控制组”和“对照组”之间的分流。如果“控制组”不经过“页面跳转”而“对照组”经过“页面跳转”，这样的设计往往会带来两部分流量之间产生细微的但可以被检测出来的差别。从这个例子可以看出实验平台实现细节的重要性。&lt;/p&gt;

&lt;p&gt;早期的实验平台都只支持“单层”（Single Layer）架构，意思就是100%的流量被分配到几个“流量桶”（Bucket）中。这些“流量桶”互相独立互不干涉。这样每个“流量桶”对应一个“对照组”（Treatment）。我们可以针对一系列“对照组”同时进行实验。然而，我们很容易发现，在这样的设置下单位时间内可以测试的“对照组”数目是有限的。因而，我们可能需要面临“流量”不够的情况。书中（第4章）介绍了“并发实验”（Concurrent Experiments）的概念，也就是“多层”（Multiple Layer）架构，可以允许多个实验同时在某一块流量上运行。当然，这虽然带来了理论上可以有无限流量的好处，但也为实验的分析提出了更高的要求。一般来说，我们需要能够分析两两实验之间的“交互”（Interaction）效果。成熟的实验平台需要能够支持“并发”实验以及能够检测实验之间的“交互”效果。&lt;/p&gt;

&lt;p&gt;实验平台另外一个需要注意的技术点，那就是如何选取“随机单元”（Randomization Unit）的问题（第15章）。什么是“随机单元”呢？简单来说，“随机单元”就是实验平台选取的达到随机化的最小“单元”。一个通常的网站，我们可以选择“页面级别”、“会话级别”以及“用户级别”的“随机单元”。例如，如果我们选择“页面级别”的“随机单元”，实验平台就可以针对某一个页面，用户每一次打开页面的时候来决定把用户导向某个“对照组”。这几种选择自然意味着不同的取舍，并没有一定的优劣之分。第一，我们需要考虑的是“随机单元”和“分析单元”（Analysis Unit）之间的关系。最简单的情况那就是“随机单元”和“分析单元”一致。比如，一个经常采用的策略就是“随机单元”和“分析单元”都采用“用户级别”。两种单元之间的不一致性往往使得实验分析更加复杂。&lt;/p&gt;

&lt;p&gt;最后，书中提及了“实验发布“（Ramp）是一个往往容易忽视但又非常重要的步骤。从比较小的流量慢慢发布到相对比较大的流量知道最后全站发布，整个过程需要的是自动化和风险控制的结合。通常情况下，实验平台在“实验发布”之后还可以预留一些流量来衡量实验的长期效果。另外一个可以降低错误的步骤则是重复“发布”某个实验，看实验的结果是否能够保持。&lt;/p&gt;

&lt;h3 id=&quot;实验指标的构建和选取&quot;&gt;实验指标的构建和选取&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/metrics.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;架设好实验平台并且能够平稳运行实验之后，我们需要选择什么指标来进行检测，从而来帮助我们进行数据驱动决策。&lt;/p&gt;

&lt;p&gt;选取实验指标的第一要素，就是选择“综合评测指标”OEC。书中在第1章、第2章和第7章都对OEC有详细的讲述。简单说来，我们希望能够用OEC，这一个唯一的衡量指标，来指导我们如何对实验结果进行取舍。在现实场景中，我们往往希望检测多种指标。这对于我们了解实验对于系统所带来的改变固然有好处，使得我们可以关注不同方面的变化，然而实验的最终的目的是进行决策，面对多个指标的决策往往是困难的。因此，作者们认为，与其对于每一个实验对要面对不同指标的决策，还不如直接把所有的权衡都包含在唯一的指标OEC里面，这样可以把决策的困难前移到定义阶段，而在后面的实验阶段可以根据OEC来进行快速的判断。第7章专门了讨论了如何构建OEC的一些细节经验。&lt;/p&gt;

&lt;p&gt;书中第6章则对指标进行了一些更加深入的讨论。虽然针对一款产品或者一个团队来说，可能会有很多指标的选择，然而不同的指标有着不同的作用。第一类指标是“目标指标”（Goal Metrics）。这一类指标是产品和团队发展的最终发展方向。通常来说，“目标指标”是一个或者非常少数的指标。这一类指标的设立往往需要产品或者团队的领导层来进行决策。有了“目标指标”之后，在现实的操作中，这些指标往往难以在短期内被改变。这里的短期通常指的是在线实验的几周时间。也就是说，虽然我们希望能够直接优化“目标指标”，但经常并不具备可操作性。因此，我们需要更有可操作性的第二类指标“驱动指标”（Driver Metrics）。这一类的指标和“目标指标”应该是有相关性（Correlation）甚至是有因果相关（Causality）的，但同时又要比“目标指标”更容易检测变化以及进行操作。第三类指标是“护栏指标”（Guardrail Metrics）。这类指标的作用是确保产品或者团队的一些最基本的运行平稳。一般来说，“护栏指标”有一个范围来保护产品的运行底线，这样即便“目标指标”或者“驱动指标”有所增长也需要不大幅度影响“护栏指标”。&lt;/p&gt;

&lt;p&gt;书中在第6章和第7章中有不少对于在线产品指标选择的意见和建议，还包括了针对“指标”的博弈的讨论。&lt;/p&gt;

&lt;h3 id=&quot;实验数据分析&quot;&gt;实验数据分析&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/dataanalysis.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;有了实验平台和我们需要检测的指标之后，实验结果的分析就成为了一件重要而且有挑战的工作。产生一组数据往往比较容易，但能够从数据中分析得出对实验的“洞察”（Insight），则并不简单。&lt;/p&gt;

&lt;p&gt;A/B在线实验数据分析的基础来自于统计的假设检验。基于&lt;a href=&quot;https://en.wikipedia.org/wiki/Student%27s_t-test&quot;&gt;“双样本”（Two-Sample）的t检测（t-Test）&lt;/a&gt;是来进行假设检验的重要工具。同时，我们也需要理解&lt;a href=&quot;https://en.wikipedia.org/wiki/P-value&quot;&gt;p值（p-value)&lt;/a&gt;以及置信区间的含义。这些概念在现实应用中常常被误解。在书中第17章有比较详细的简介。然而对于实验数据分析，仅仅知道t检测和p值是远远不够的。书中介绍了不少相对不经常被讨论到，但又很普遍的一些问题。&lt;/p&gt;

&lt;p&gt;第一个重要主题就是&lt;a href=&quot;https://en.wikipedia.org/wiki/Multiple_comparisons_problem&quot;&gt;“多次测试”（Multiple Testing）&lt;/a&gt;。简单来说，传统的假设检验的设置是对需要检测的“假设”（Hypothesis）进行唯一的测试，然后计算p值。在这样的情况下，我们有5%的概率观测到某一个并没有实际变化的“指标”显得有统计意义上的显著变化。然而在现实中，对于同一个实验，我们常常通过实验平台反复观测结果，或者反复针对同一个想法进行迭代。更加严重的是，我们针对同一个实验， 常常同时观测几十个有时候上百个“指标”。这些行为都会导致“多次测试”的问题，也就是大大增加观测到并不该显得有变化的“指标”有统计意义变化的概率。书中第17章讲了一些处理“多次测试”问题的实用判断方法。在现实运作中，“多次测试”问题会在长期运行平台和有实验数据分析后让很多结果有“水分”。&lt;/p&gt;

&lt;p&gt;第二个问题就是针对“方差”的计算。t检测中我们需要对数据的方法进行计算。书中的第18章指出，有时候我们的“方差”计算是有问题的，例如前文提到的“随机单元”和“分析单元”不一致的情况下，尤其是我们需要计算一些比率如点击率。一个经常遇到的场景就是，我们的“随机单元”是“用户级别”，然而我们希望计算一些页面级别的点击率，看是否在“控制组”和“对照组”之间有差别。这时候，就存在“随机单元”和“分析单元”不一致的问题，传统的计算点击率的“方差”公式有可能是错误的。那么，第18章针对这样的问题进行了分析。&lt;/p&gt;

&lt;p&gt;书中还提到的一个重要的数据分析手段是看“样本比率偏差”（Sample Ratio Mismatch）。在理想状态下，“控制组”和“对照组”的流量是五五开的，也就是50%的用户会到“控制组”另外50%的用户会到“对照组”。那么，如果在现实中，是50.43%的用户到了“控制组”另外49.57%的用户到了“对照组”，这样的情况还是正常的吗？我们还能信任这样的实验结果吗？书中第21章讲解了如何针对这样的情况进行排查和分析。简单来讲，我们需要把这样的分流结果当做是假设检验，看这样的结果是否异常。&lt;/p&gt;

&lt;p&gt;类似的看似简单实际需要认真对待的还有针对A/A实验的结果。在第19章里专门讲了A/A实验的一些经验和数据处理。A/A实验往往作为检测平台稳定性和实验设置是否正确的重要手段。&lt;/p&gt;

&lt;p&gt;除了这些非常实用的场景外，书中还在第22章介绍了更加高阶的话题，那就是如果“控制组”和“对照组”之间有“干涉”（Interference）怎么办。也就是说，传统的实验我们的一个重要的假设就是“控制组”和“对照组”的完全隔绝。然而在现实中的一些设置中，完全的隔绝是不可能的。例如，在社交网络中，因为朋友与朋友的关系，于是如果我们按照传统的随机划分流量的方法，则有可能一个用户在“控制组”，而其朋友在“对照组”，这样就使得这个用户可以接触到“对照组”的一些信息，从而违反了假设检验的一系列基本假设。在这一章，作者们给出了一些参考的解决方案。&lt;/p&gt;

&lt;p&gt;除了针对衡量“指标”在实验内的数据分析之外，作者们还在第23章讨论了一个非常重要的话题，那就是如何衡量“指标”的长期效果。一个经常发现的现象就是，有一些“指标”的效果在A/B实验之后，可能会出现一些“恶化”，也就是说，效果可能没有之前那么明显了，甚至会出现效果完全消失。作者们在这一章详细分析了“指标”长期效果出现变化的一些可能性，以及如何去做一些针对性的分析来看“指标”是否有长期效果不佳的问题。这一部分算是高阶内容，建议感兴趣的读者阅读。&lt;/p&gt;

&lt;h3 id=&quot;观察研究和因果推论&quot;&gt;观察研究和因果推论&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/abtests.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在有不少的情况下，我们无法对需要研究的问题进行实验。这一方面有可能是实验是现实中不可操作的，另一方面也可能是做实验会有伦理、道德等挑战，因此“观察研究”和“因果推论”（Causal Inference）就成为了在这种情况下我们依然希望进行数据驱动决策的唯一选择。本书的作者们在第11章简要介绍了“观察研究”的一些基本技术。不过，对于“观察研究”的可靠度，作者们持有谨慎的态度。原因是一般的基于“观察研究”的“因果推论”方法因为有很强的假设有不小的局限性。作者们甚至指出了一些研究的结果因为后期发现的一些问题而导致结论发生很大的变化而不可信。尽管如此，我们还是建议读者们对第11章的内容进行普遍的了解。&lt;/p&gt;

&lt;h2 id=&quot;总结点评&quot;&gt;总结点评&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这本书可以说是作为数据科学家、机器学习工程师、产品经理以及一切对于在线可控实验有兴趣的研发人员“宝典”级别的参考书。全书包含了丰富的理论基础、实践指导以及案例分析，是一本难能可贵的集科普与进阶为一体的技术书籍。三位作者，特别是第一作者Ron在微软多年从事在线可控实验研发和领导工作的经历，使得这本书从某种意义上成为了他对这些年工作的一种总结之作。本书高阶部分的内容可以直接连接到当前研究和实践的热点内容，可以使程度较高的读者也能有比较享受的阅读体验。总体而言，本书可以作为可以反复阅读的业界经典之作。&lt;/p&gt;
</description>
        <pubDate>Fri, 08 May 2020 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E5%9C%A8%E7%BA%BF%E5%AE%9E%E9%AA%8C/2020/05/08/online-tests/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E5%9C%A8%E7%BA%BF%E5%AE%9E%E9%AA%8C/2020/05/08/online-tests/</guid>
        
        
        <category>读书笔记,在线实验</category>
        
      </item>
    
      <item>
        <title>《经理人之路——技术领袖启航成长与变化的参考书》总结</title>
        <description>&lt;p&gt;今天我们要来总结技术管理书籍&lt;a href=&quot;https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth/dp/1491973897&quot;&gt;The Manager’s Path – A Guide for Tech Leaders Navigating Growth &amp;amp; Change&lt;/a&gt;。这本书的作者是&lt;a href=&quot;https://en.wikipedia.org/wiki/Camille_Fournier&quot;&gt;卡米尔福尔聂尔（Camille Fournier）&lt;/a&gt;，其在技术管理领域有丰富的经验。全书是针对技术管理人在职场发展不同阶段所需技能以及面对诸多管理场景的经验总结，是技术管理领域不可多得的参考书籍。&lt;/p&gt;

&lt;h2 id=&quot;作者简介&quot;&gt;作者简介&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/cf.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Camille_Fournier&quot;&gt;卡米尔福尔聂尔（Camille Fournier）&lt;/a&gt;从2017年起在对冲基金&lt;a href=&quot;https://en.wikipedia.org/wiki/Two_Sigma&quot;&gt;Two Sigma&lt;/a&gt;担任“董事总经理”（Managing Director）。之前在&lt;a href=&quot;https://en.wikipedia.org/wiki/Rent_the_Runway&quot;&gt;Rent The Runway&lt;/a&gt;历任总监、高级副总裁以及首席科技官等职务。其早年从卡内基梅隆大学毕业或计算机科学学士，毕业后在微软以及高盛任职。&lt;/p&gt;

&lt;h2 id=&quot;全书结构&quot;&gt;全书结构&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;全书大体上可以分为以下这么四部分内容:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一部分，是对从“个人岗位”（Individual Contributor）向“管理岗位”（Managerial Contributor）转换过程的经验总结，面向的对象主要是有一定经验的技术人员，内容涵盖了“导师”（Mentor）和“技术负责人”（Tech Lead）。这部分内容是“技术管理”（Technical Management）的重要准备。在书中大体对应第二章、第三章和一部分第四章的内容。&lt;/li&gt;
  &lt;li&gt;第二部分，是对“初级经理人”（Entry-Level Manager）的经验总结，面向的对象主要是“经理”（Manager）这一级别的职务。这一部分是“技术管理”的奠基石。在书中大体对应一部分第四章的内容和第五章的内容。&lt;/li&gt;
  &lt;li&gt;第三部分，是对“中层经理人”（Manager of Managers）的经验总结。面向的对象主要是“资深经理”和“总监”这一级别的职务。这一部分是技术管理的重要进阶。在书中大体对应第六章和第七章的内容。&lt;/li&gt;
  &lt;li&gt;第四部分，是对“高级经理人”（Senior Leaders）的经验总结，面向的对象主要是“首席科技官”（CTO）和“高级副总裁”（SVP）这一级别的职务。这一部分是技术管理的高级阶段。在书中大体对应第八章的内容。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了这四部分的主要内容以外，这本书的第一章主要是从“被管理”的角度讲如何和自己的经理打交道，可以说是非常有用的经验总结。而第九章，也就是最后一章，则讲了讲对于塑造团队和企业技术文化的一些经验之谈。&lt;/p&gt;

&lt;h2 id=&quot;内容剖析&quot;&gt;内容剖析&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;我们接下来就针对书中的四个重点内容为大家进行剖析。&lt;/p&gt;

&lt;h3 id=&quot;技术管理的准备&quot;&gt;技术管理的准备&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/mentor.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;要想胜任技术管理的岗位往往不是一蹴而就。从个人岗位到管理岗位有时候有着不可逾越的鸿沟。现实中的技术人员，特别是资深技术人员，通常情况下都在自身技术水平不断得到提升的基础上，希望能够对自己的管理能力也进行扩展，从而来试探自己是否有朝一日能够走上管理岗位。于是，在非管理岗位进行技术管理的技能培养和训练就显得尤其重要。&lt;/p&gt;

&lt;p&gt;本书对于技术管理的准备阶段着重从“导师”和“技术负责人”这两个重要“角色”（Role）入手，来引导资深技术人员来理解“人员管理”（People Management）的入门技能。&lt;/p&gt;

&lt;p&gt;另一方面，从中层经理人的角度来说，“导师”和“技术负责人”这两个角色也是考察资深技术人员是否具备转换为潜在“初级经理人”（所谓的内部提拔）的重要过度性角色。也就是说，把有一定资质的技术人员放在这样的角色上是相对风险较低得考察一个技术人员是否能够适应管理工作的重要方法。&lt;/p&gt;

&lt;p&gt;“导师”这个角色往往比较简单。书中涵盖了两种“导师”关系：实习生导师和新员工导师。在这些初级的技术管理角色中，技术人员需要开始学习和掌握三种重要的管理技能（Skill）：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;聆听&lt;/strong&gt;（Listen）：“聆听”可以说是从简单技术岗位到管理岗位转换中非常难以驾驭的一个技能。同时，聆听是建立“共情”（Empathy），也就是另一个重要的管理技能，的重要步骤，或者说是第一步。培养“聆听”技能的核心在于“专注”。也就是说，“聆听”需要你专注于你所聆听对象目前在表达的事情。“聆听”的目的是了解对方所希望表达的内容和观点，而不是迅速切换到你自己的回应。另外，“聆听”的难点在于很多人并不善于表达自己的观点。于是，在“聆听”的过程中去真正理解对方的意图就变得尤为重要。这种时候，通过反复问问题的方式来调整对于意图和内容的理解是一种有效的手段。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;沟通&lt;/strong&gt;（Communication）：“沟通”是指对于沟通对象明确表达或者明确传达某种信息。沟通最忌讳预设立场。也就是说，不要预期沟通对象在没有沟通的情况下依然知道或者能够猜测到你所希望表达的信息。“沟通”的目的是明确表达出你对于对方的期待。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;调整&lt;/strong&gt;（Calibration）：“调整”是指通过“聆听”和“沟通”来针对目前的状况调整计划。有很多情况是你实现意料不到的：你的指导对象也许比你想象得要慢；或许项目的进行不如你的预期；或许你的指导对象完全依靠自己完成了任务，等等。在这些意料之外的情况发生的时候，都需要你针对这些情况进行调整，并且能够和你的指导对象进行沟通。这种调整往往有一定周期性，比如每天或者每周。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;相较于“导师”，“技术负责人”则更像一个完整的“初级经理人”。在很多公司，“技术负责人”往往承担起很多经理的职责。值得注意的是，很多“技术负责人”也为团队中的年轻技术人员提供指导工作，起到“导师”的作用。&lt;/p&gt;

&lt;p&gt;然而，“技术负责人”往往需要具备一些相较于“导师”而言更加高阶的技能：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;平衡&lt;/strong&gt;（Balance）：“技术负责人”要开始学会在诸多完全不同的任务之间平衡自己的精力和时间。在最开始的一些时间里，人们往往倾向于做自己熟悉的任务（例如编写代码）。然而要想能够在技术管理的路上前行，“技术负责人”要开始学习新的技能并且在自己并不是那么熟悉的领域（例如组织会议、指导更多的年轻技术人员）多花时间。于是，“平衡”就成为了一种重要的技能。另外一个通常需要平衡的关系就是自己写代码解决复杂问题和如何调动团队来合作解决问题。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;项目管理&lt;/strong&gt;（Project Management）：理解和掌握项目管理的精髓并不需要你成为“项目经理”（Project Manager）。这里所说的项目管理指的是如何把一个复杂的技术问题转换成为细致的多种任务同时能够对这些任务进行简单的分配和管理。更加高阶一些的项目管理技能需要“技术负责人”能够收集项目需求（Requirements）同时能够对项目的长度进行有效的估计。一个好的“技术负责人”更是能够发现目前项目进度的主要挑战（Challenge），并且能够带领团队进行技术攻坚。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不管是“导师”还是“技术负责人”，作为一个资深技术人员，这两种角色都是让你能够开始学习和锻炼管理技能的重要过度角色。你可以审视自己是否喜欢这样的角色，是否真正愿意在技术管理的道路上继续前行。&lt;/p&gt;

&lt;h3 id=&quot;初级经理人&quot;&gt;初级经理人&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/junior.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在绝大多数科技公司，“初级经理人”一般指的是管理单一团队的技术经理人。单一团队的人数通常在三到十人不等。&lt;/p&gt;

&lt;p&gt;从“初级经理人”开始，技术管理的一些重要技能开始把个人岗位和管理岗位完全地区分开：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;开始一段新的汇报关系：在之后的技术管理工作中，经常会产生新的汇报关系。如何对待这些新出现的汇报关系则成为了技术管理中的重要技能。书中提到了一系列重要手段。例如和新的汇报对象逐渐建立&lt;strong&gt;互信&lt;/strong&gt;。说到底好的管理还是建立在人与人的关系上的，而在西方管理学中一个核心的内容就是人与人的互信。再例如就是建立一个30天60天90天的计划从而为新的汇报关系之间提供一个清晰的预期。同时，在确立新的汇报关系的过程中，“聆听”和“沟通”技能也起着至关重要的作用。这些技能是为了和新的汇报关系慢慢建立一个反馈机制。&lt;/li&gt;
  &lt;li&gt;一对一会议（1-1）：在这本书中，“一对一会议”的重要性被作者反复强调。“一对一会议”的安排（例如每周）和内容以及如何在这些会议中和汇报对象建立起稳健的反馈机制都是初级经理人需要掌握的重要人事管理的技能。书中还列举了不同类型的“一对一会议”诸如解决问题型、反馈型或者最新进展型。显然，要想在不同的情况下和汇报对象建立长久的关系，在不同类型的“一对一会议”之间熟练切换就成为了重要的手段。&lt;/li&gt;
  &lt;li&gt;绩效反馈评定：对汇报关系进行绩效反馈以及评定是技术管理的核心组成部分。这项技能是之前提及的“初级经理人”有别于之前提及的“技术负责人”的重要标杆。书中提及了一系列实际的技巧，例如“使用实际的事例”、“还需要加强的领域需要专注”等。
“初级经理人”一个非常重要的职责就是关注和协助团队成员的职业发展。很明显，不同公司不同行业的职级（Level）有区别。作为一线的“初级经理人”，你需要对团队中不同成员的晋升负责并且和他们一起提供一个完整的路线图。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另外一个“初级经理人”需要开始学习的职责，就是管理员工的“离职”。“离职”分“主动离职”和“被动离职”（也就是俗称的“解雇”）。对于很多“初级经理人”而言，管理汇报对象的“离职”往往比想象中的要困难。这里关键的步骤是有效得建立起绩效的反馈机制以及比较详细的记录，从而为“离职”进行材料准备。&lt;/p&gt;

&lt;p&gt;“初级经理人”的相对比较高阶的话题还包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;观察和调试（Debug）团队：因为“技术经理人”不再是技术人员，需要利用新的技能和流程来对团队的整体绩效进行有效的评估。这里面包括的场景有团队的产出下降、团队有“人事混乱”（People Drama）、团队有合作问题等等。这里面的每一个场景都需要你建立一整套的机制来获取、筛选和处理信息，从而能够达到调试团队的目的。&lt;/li&gt;
  &lt;li&gt;矛盾和分歧的处理：很快，“初级经理人”就会发现其周围充满了矛盾和分歧。这些矛盾和分歧有来自于团队内部的，有来自其他合作团队的，有来自于上层的，等等。如何在复杂的环境下处理这些矛盾和分歧就成为了“初级经理人”所要学习的技能。这些技能会在“高级经理人”的阶段变得更加关键。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;成为一个有效的“初级经理人”还需要对项目管理有更加高阶的提升，包括你要开始针对团队的短期和长期的任务有一个比较完整的理解以及理解公司的运作周期（每个季度的时间安排），从而使得你对项目的分配以及团队的产出和合作都有一个全新的更高层次的认知。&lt;/p&gt;

&lt;h3 id=&quot;中层经理人&quot;&gt;中层经理人&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/middle.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在绝大多数科技公司，“中层经理人”一般指的是管理多个团队的技术经理人。这个时候，“中层经理人”所管理的多个子团队本身往往有一线的“初级经理人”。而“中层经理人”的职责则转移到如何管理好这些初级经理人以及通过这些“初级经理人”来对所有的多个团队进行间接的管理。管理多个团队是技术管理人从初级阶段向更加复杂的管理场景提升的重要标志。&lt;/p&gt;

&lt;p&gt;书中认为“中层经理人”一项非常的技能是如何更加合理得管理自己的时间。的确，对于一个“中层经理人”来说，在某一个瞬间，都有太多的事情可以聚焦，那么如何专注在最需要的事情上就变得尤为重要。书中介绍了一种经典的时间管理方法，那就是把事情按照重要与否和紧急与否两个维度分为如下的四种类别：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;重要而且紧急：一件事情如果是重要且紧急，那么这明显是当前需要专注的工作。尽管这样的分类方法有一定道理，作者提醒我们要注意在日常工作中把“显然”（Obvious）的工作当做是“紧急”（Urgent）的。例如，一个在日历上的会议邀请并不意味着这个会议就一定是紧急的事件。有时候，分清楚什么事情是否重要或者紧急并不是那么显然的事情。&lt;/li&gt;
  &lt;li&gt;重要但不紧急：很多事情都可以归为这个类别。例如，写一份新的“职位描述”（Job Description），抑或是思考一个新的招聘计划。这类事情的一个特点就是如果一点不花时间去做，那么长期积累下来就会对你的工作产生负面影响。一个“中层经理人”需要利用“平衡”等技能来找到时间花在重要但不紧急的事情上。&lt;/li&gt;
  &lt;li&gt;不重要且不紧急：这是很明显需要避免的一个类别。&lt;/li&gt;
  &lt;li&gt;不重要但紧急：作者认为这个类别的事情都是潜在的“分心”（Distraction）。例如，很多会议都显得很紧急，但作为一个“中层经理人”是否需要参与这些会议是需要仔细拿捏的意见事情。还有类似电子邮件或者聊天工具（Slack）上面的信息，会显得很紧急。但这些事情并不一定需要你现在就去处理。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在管理时间的基础上，作者提到了第二个“中层经理人”的重要技能“决策”（Decision）和“代理”（Delegation）。这个技能是中级经理人需要获取和发展的。类似于时间管理，作者按照经常与否和复杂与否两个维度，把事情的决策和代理分为了以下四个类别：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;简单且不经常：这类事情的典型代表如运行一些每个季度需要的报表，或订会议的票等，一般需要你自己去做。主要的原因是这类事情不具备利用来培养团队“初级经理人”的目的。&lt;/li&gt;
  &lt;li&gt;简单且经常：这类事情的典型代表如团队每日的例会、团队的进度报告等，一般需要你代理别人去做。一般来说，团队中的技术负责人或者一些资深技术人员都可以胜任这样的任务。&lt;/li&gt;
  &lt;li&gt;复杂且经常：这类事情的典型代表如项目计划、系统设计或者是在“事故”（Outage）的处理中担任核心的任务，一般需要你小心得去代理给团队。这些任务可以认为是发展团队中核心成员的重要手段和工具。然而因为这些事情相对都比较复杂，因此在代理的过程中需要注意方式方法和速度。简单来说，就是不能贸然把这类事物都不假思索得代理给团队。&lt;/li&gt;
  &lt;li&gt;复杂且不经常：这类事情的典型代表是写绩效评定、或者是建立一个新的招聘计划，一般来说需要你自己去做，但是也可以慢慢来代理给团队中未来的领袖。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;学会如何平衡所有事物的决策和代理权是一个动态并且需要慢慢体会的技能。&lt;/p&gt;

&lt;p&gt;对于“中层经理人”来说，第三个重要的技能就是需要策略性地说“不”。对于多团队管理来说，有太多的场景需要你来斟酌并且表达否定的决策。然而，这里面的问题是，很多时候，简单说“不”并不能解决问题，尤其是有矛盾和分歧的时候。书中介绍了一系列的“说不”的技巧。总结说来，这些技巧都是要在“说不”的情况下提供更多的“上下文”（Context）以及尝试创造一个“说不”以后的计划，而不是简单的“说不”。&lt;/p&gt;

&lt;p&gt;我们在前面总结“初级经理人”的时候提及了“一对一会议”的重要性。当一个“中层经理人”开始管理多个团队时，与所有团队所有人进行“一对一会议”已经不现实，然而，书中还是强调了在这种新形势下的“一对一会议”，也就是“隔层会议”（Skip-Level Meetings）的必要性。总的来说，“隔层会议”是让你保持和一线员工有稳固联系的重要手段。通过这些“隔层会议”，你可以发现团队运行存在问题的蛛丝马迹。&lt;/p&gt;

&lt;p&gt;最后，“中层经理人”还需要有效管理起各个团队的“初级经理人”。这些“初级经理人”有可能是完全的新手，也有可能是富有经验的技术管理者。对于这些人的管理最重要的有两点，那就是如何建立有效的调试机制来得知他们管理的团队是否是高效运行还是存在不少潜在的问题，另外设置有效的预期以及提供反馈都是非常重要的中层管理手段。&lt;/p&gt;

&lt;p&gt;值得一提的是，“中层经理人”由于隔了一层“初级经理人”，因此对于团队的管控往往都是通过间接的手段，因此书中介绍的种种经验和技能都依赖于能够对初级经理人能够进行有效管理，因此“中层经理人”需要同时具备管理多个团队以及管理多个个人（也就是多个“初级经理人”）的技能和手段。这对经理人的要求明显高于初级经理人。&lt;/p&gt;

&lt;h2 id=&quot;高级经理人&quot;&gt;高级经理人&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/senior.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;书中的“高级经理人”指的是“工程副总裁”（VP of Engineering）或者“首席技术官”（CTO）这样的职位。很显然，“高级经理人”需要相比于“中级经理人”和“初级经理人”而言完全不同的一整套技能。&lt;/p&gt;

&lt;p&gt;书中提及的第一个重要技能就是如何对待“变化的优先级”（Changing Priorities）。这里提及的场景主要是指公司高层，例如CEO突然觉得公司应该专注于新的事情或者目前事情的优先级发生了变化。这些变化有可能并不是深思熟虑的结果。那么，如何带领一个复杂的机构（这时候已经不是单单几个团队了）来应对优先级的变化就是高级经理人往往需要掌握的技能。优先级的改变有可能对团队产生极大负面的效果。每个团队都潜在有一个常常的任务列表。很多项目之间还有依赖关系。因此，转变一个机构的优先级，并且能够有一个匹配的计划就变得尤为关键。另外，“沟通”在这种场景下也是不可缺少的重要技能。&lt;/p&gt;

&lt;p&gt;作为“高级经理人”的第二个重要技能就是如何设置“战略”（Strategy）。向董事会成员、或者是管理高层讲述、汇报部门甚至是公司在某一个方面的战略思想将成为“高级经理人”的一项核心工作。那么，如果能够建立战略的思路以及如何表述这样的战略就成为了高级经理人阶段的新技能。再之前的中层以及初级经理人阶段，主要是强调在执行的层面。&lt;/p&gt;

&lt;p&gt;最后，作为“高级经理人”，一个非常重要也是一个新的技能领域，那就是如何与诸多“跨部门”（Cross-Functional）“高级经理人”协作。尽管在科技公司中，有不少项目是跨部门协作的，例如需要设计、前台、后台、算法的齐心协力，然而在“高级经理人”阶段，你往往代表了一整个职能部门（例如工程副总裁或者是首席科技官代表了整个工程研发团队）与其他职能部门，例如产品、法务、人事，在整个公司的层面上进行合作。这势必是对你沟通表达能力以及协作能力的全新考验。&lt;/p&gt;

&lt;h2 id=&quot;总结点评&quot;&gt;总结点评&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这本书可以说是作为技术管理人的“宝典”级别的职场参考书。因为作者卡米尔相对丰富的职业经理人晋升经历，因此这本书中提供的很多经验之谈都相当接地气并且有极高的参考价值。与更加通用的管理书籍相比，此书专注于科技公司的技术管理场景，因而对于有心于技术管理职场发展的各层级技术人员和技术管理人来说，这本书都能够提供不小的帮助。整本书的结构上来看，主要是相对比较松散组织起的四大块内容，以及穿插的各种技巧，因此可能在宏观上缺乏一定的架构，所以，本书可以作为可以反复阅读的经验总结之作。&lt;/p&gt;
</description>
        <pubDate>Wed, 25 Dec 2019 00:00:00 -0800</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2019/12/25/the-manager-path/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2019/12/25/the-manager-path/</guid>
        
        
        <category>读书笔记,管理</category>
        
      </item>
    
      <item>
        <title>KDD 2019讲座 - “双次序实验”</title>
        <description>&lt;p&gt;今天我们要来分享一个叫&lt;a href=&quot;http://www.stat.cmu.edu/~aramdas/kdd19/&quot;&gt;Foundations of Large-scale “Doubly-Sequential” Experimentation&lt;/a&gt;的KDD 2019讲座（Tutorial)。这个讲座的作者是来自于时任卡内基梅隆大学（Carnegie Mellon University）助理教授的&lt;a href=&quot;http://www.stat.cmu.edu/~aramdas/&quot;&gt;Aaditya Ramdas&lt;/a&gt;。这个讲座清晰得梳理了基于单个实验的“内次序”（Inner Sequential Process）和基于多个实验的“外次序”（Outer Sequential Process），以及他们之间的关系。同时，这个讲座还涵盖了这方面的重要文献历史，是一份不可多的资料。&lt;/p&gt;

&lt;h2 id=&quot;讲座的基本设置&quot;&gt;讲座的基本设置&lt;/h2&gt;

&lt;p&gt;讲座的第一部分是对简单的A/B实验进行了回顾。诚如讲座里面讲的，这部分内容已经在最近几年的各大会议的很多其他类似讲座中已经有所涵盖。因此该讲座并没有再对基础知识进行重复。&lt;/p&gt;

&lt;p&gt;讲座的内容很快转移到核心的两块内容，那就是基于单个实验的“内次序”（Inner Sequential Process）以及基于多个实验的“外次序”（Outer Sequential Process）。简单得来说，不管是“内次序”还是“外次序”，该讲座的目的就是来探讨如何让实验的结论能够成立。也就是说，如果进行简单的“假设检验”（Hypothesis Testing），例如我们经常做的T-Test，或者其他基于“置信区间”（Confidence Interval）的检验有可能得到错误的结论。讲座的核心内容就是来对已有的方法已经扩展。&lt;/p&gt;

&lt;h2 id=&quot;内次序&quot;&gt;内次序&lt;/h2&gt;

&lt;p&gt;“内次序”主要是探究在一个实验里的结论是否正确的问题。当然，这里的“正确”并不是指绝对意义上的“控制组”（Control Group）要比“对照组”（Treatment Group）好，或者反之。而是从统计意义来说，如何来衡量控制组和对照组之间的差别。上面我们提到，这种统计推断的核心是进行“假设检验”。&lt;/p&gt;

&lt;p&gt;Aaditya首先指出，传统的假设检验的一个重大问题就是样本数量必须事先确定好。不管是p-value还是置信区间都依赖于这个&lt;strong&gt;事先确定好的&lt;/strong&gt;样本数量。这种静态的需求和很多平时在A/B实验中进行观测的行为是非常不同的。例如，一种非常普遍（并不是是正确）的观测实验的方式是，对一个实验的结果反复进行检查，看p-value是不是到达并且小于某个阈值$ \alpha $，一旦小于这个值，立马停止实验。利用这样的方法会得到“False Positive Rate”很可能远远大于事先的阈值$ \alpha $。换句话说，很多我们认为有作用的“对照组”其实很有可能并没有作用。&lt;/p&gt;

&lt;p&gt;那么，内次序的核心问题就是如何对这样的监控算法进行扩展和改进，使得我们能够随时监控实验并且还能够得到正确的统计推断结果。&lt;/p&gt;

&lt;p&gt;在该讲座中，Aaditya讲解了“Confidence Sequence”和“Sequential p-value”的概念，并且展示了如何利用这两种手段来进行单个实验的检测。同时，Aaditya还揭示了这两种概念之间的转化关系。&lt;/p&gt;

&lt;h2 id=&quot;外次序&quot;&gt;外次序&lt;/h2&gt;

&lt;p&gt;那么，如果我们能够很好得处理一个实验，是不是我们就可以放心大胆得进行多个实验来进行服务的改进了呢？答案是，对于多个实验，我们依然需要更加小心。&lt;/p&gt;

&lt;p&gt;这部分的内容可能一开始会让人觉得很震惊。但Aaditya在讲座中举了很直观的例子来说明，即便单个实验我们都依靠某个$ \alpha_{i} $来控制“False Positive Rate”，并不代表多个实验的总体的”False Discovery Proportion”(FDP)是小于或等于这些$ \alpha_{i} $。&lt;/p&gt;

&lt;p&gt;外次序的核心内容就是如何对多个实验进行监控，并且能够在“在线”（Online）的情况下进行统计推断。该讲座对几个最新的在线FDP算法进行讲解。细节可以参考讲座内容。&lt;/p&gt;

&lt;h2 id=&quot;双次序实验&quot;&gt;双次序实验&lt;/h2&gt;

&lt;p&gt;该讲座应该算是第一个把内次序和外次序都结合在一起的一个讲座。Aaditya在讲座内容中指出，这两个部分均可以进行“模块化”。意思是说，更好的内次序算法以及更好的外次序算法可以进行搭配使用。&lt;/p&gt;

&lt;h2 id=&quot;高级内容&quot;&gt;高级内容&lt;/h2&gt;

&lt;p&gt;Aaditya在该讲座也进行了部分高级内容的概括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在“内次序”中如何处理多个“对照组”。讲座提到了基于Multi-Armed Bandit（MAB）的算法。&lt;/li&gt;
  &lt;li&gt;如何对Quantile进行估计。&lt;/li&gt;
  &lt;li&gt;在“外次序”中，如何对过去远期的实验进行“忘却”（Forget）。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;历史信息&quot;&gt;历史信息&lt;/h2&gt;

&lt;p&gt;Aaditya在讲座中回顾了内外次序的重要历史文献。&lt;/p&gt;
</description>
        <pubDate>Mon, 02 Sep 2019 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2019/09/02/kdd-sequencial/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2019/09/02/kdd-sequencial/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>CIKM 2018论文精读（一）</title>
        <description>&lt;p&gt;今天我们要来分享一篇题目叫&lt;a href=&quot;https://drive.google.com/open?id=1m7-z2loy5iW-gcrGiT2XJTdr4LjQHf3H&quot;&gt;Collaborative Multi-objective Ranking&lt;/a&gt;的发表在&lt;a href=&quot;https://www.cikm2018.units.it/&quot;&gt;CIKM 2018&lt;/a&gt;上的论文。这篇论文的作者是来自于罗格斯大学（Rutgers University）的&lt;a href=&quot;https://sites.google.com/site/hujun1010/&quot;&gt;Jun Hu&lt;/a&gt;和&lt;a href=&quot;http://www.stat.rutgers.edu/home/pingli/&quot;&gt;Ping Li&lt;/a&gt;。文章的核心内容讲的是，传统的以矩阵分解为基础的“协同排序”（Collaborative Ranking）容易有无法有效学习“用户隐向量”（User Factor）和“物品隐向量”（Item Factor）的问题。这篇论文探究了这种问题的来源以及提出了一种“共同优化”（Joint Optimization）的策略来解决问题。&lt;/p&gt;

&lt;h2 id=&quot;文章的基本设置&quot;&gt;文章的基本设置&lt;/h2&gt;

&lt;p&gt;我们先来看一下文章的基本设置。首先，我们假设有一个评分矩阵$ \mathbf{R} \in \mathbb{R}^{M \times N} $，被一个用户矩阵$ \mathbf{U} \in \mathbb{R}^{M \times K} $和一个物品矩阵$ \mathbf{V} \in \mathbb{R}^{N \times K} $所表达$ \mathbf{R} = \mathbf{U} \times \mathbf{V} $。一个“单点”（Pointwise）目标函数常用来学习模型的参数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{\mathrm{pointwise}} = \sum_{u=1}^{M} \sum_{v=1}^{N} (r_{ui} - \hat{r_{ui}})^{2} + \sum_{u=1}^{M}\lambda_{U,u}|| \mathbf{U}_{u} ||^{2} + \sum_{v=1}^{N}\lambda_{V,v}|| \mathbf{V}_{v} ||^{2}&lt;/script&gt;

&lt;p&gt;这个目标函数的目的是希望能够学习到准确的用户隐向量和物品隐向量来逼近原有的评分矩阵。然而在真实的应用中，很多时候我们并不是在意&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}&lt;/script&gt;的绝对数值的准确性，而是它们之间的相对位置，也就是说“排序”。所以，这也就有了“协同排序”的出现。具体说来，“协同排序”就是希望利用“配对法”（Pairwise）的“排序学习”（Learning to Rank）确保物品的相对顺序得以保证。一个常见的针对顺序的损失目标函数是：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\varepsilon_{\mathrm{zero-one}} = - \sum_{(u, i_{1}, i_{2}) \in \Omega} \sigma \Bigr( \mathbf{U}_{u} \mathbf{V}_{v_{1}}^{T} - \mathbf{U}_{u} \mathbf{V}_{v_{2}}^{T}\Bigl)&lt;/script&gt;

&lt;p&gt;其中&lt;script type=&quot;math/tex&quot;&gt;\Omega = \{ (u, i_{1}, i_{2}) : r_{ui_{1}} &gt; r_{ui_{2}} \}&lt;/script&gt;是一个比较集合，&lt;script type=&quot;math/tex&quot;&gt;\sigma(x)&lt;/script&gt;是一个$0-1$ 损失函数：当$x &amp;gt; 1$的时候&lt;script type=&quot;math/tex&quot;&gt;\sigma(x) =1&lt;/script&gt;，其他时候为$0$。这个损失函数无法微分，因此一个替代的方案则是利用Sigmoid函数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\varepsilon_{\mathrm{zero-one-approximate}} = - \sum_{(u, i_{1}, i_{2}) \in \Omega} \frac{1}{1+\exp\Bigr( -\mathbf{U}_{u} (\mathbf{V}_{v_{1}} - \mathbf{V}_{v_{2}})^{T}\Bigl)}&lt;/script&gt;

&lt;p&gt;我们有了上面的这个损失函数以后，在进行优化的过程中，往往会“保持住”（Fix）所有某个用户$u$所对应的&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}&lt;/script&gt;，然后更新&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;。&lt;/p&gt;

&lt;h2 id=&quot;文章的核心观点&quot;&gt;文章的核心观点&lt;/h2&gt;

&lt;p&gt;文章的作者们发现，在某些情况下在更新用户矩阵&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;的时候，算法不可能保持住所有用户所对应物品的顺序的。举例来说，我们有两组物品的比较顺序&lt;script type=&quot;math/tex&quot;&gt;\{ (u, a, b) : r_{ua} &gt; r_{ub} \} \in \Omega&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\{ (u, c, d) : r_{uc} &gt; r_{ud} \} \in \Omega&lt;/script&gt;。并且当前情况下，我们有这样的关系：&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}_{a} - \mathbf{V}_{b} =[0,-1]&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}_{c} - \mathbf{V}_{d} =[0,1]&lt;/script&gt;。这也就意味着无论如何更新&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;，我们都无法同时满足&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}(\mathbf{V}_{a} - \mathbf{V}_{b})&gt;0&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}(\mathbf{V}_{c} - \mathbf{V}_{d})&gt;0&lt;/script&gt;，因为这两组乘积必定是一正一负，无法调和。也就是说，在更新了&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;之后，我们反而无法保证原有的顺序了。&lt;/p&gt;

&lt;p&gt;第二个作者们的发现来自于对于Sigmoid函数&lt;script type=&quot;math/tex&quot;&gt;\sigma(x) = \frac{1}{1+ \exp(-ax)}&lt;/script&gt;的认识。在这个函数中，&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;控制了曲线多么接近&lt;script type=&quot;math/tex&quot;&gt;0-1&lt;/script&gt;损失函数：值越大，越接近。然而，在矩阵分解中，任何对于&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;的更新（例如把其值增大两倍），都可以利用更改其对应的所有&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}_{i}&lt;/script&gt;来达到恢复其之前的状态（例如把其值除以一半）。这样，更新&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;并不一定逼近&lt;script type=&quot;math/tex&quot;&gt;0-1&lt;/script&gt;损失函数。换句话说，我们必须要对&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}&lt;/script&gt;进行限制，不能无限制得任其发展。&lt;/p&gt;

&lt;h2 id=&quot;文章提出的模型&quot;&gt;文章提出的模型&lt;/h2&gt;

&lt;p&gt;有了上面的铺垫，作者们提出了一种新的损失函数，那就是把单点损失函数，基于物品的配对损失函数以及基于用户的配对损失函数结合起来，形成一个三个损失函数的某种平衡。&lt;/p&gt;

&lt;p&gt;我们已经定义了单点损失函数，那这里就来看看一下基于物品的配对损失函数。作者们使用了一个叫Bradley-Terry模型来针对某个用户的两个物品进行比较的概率进行建模：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(r_{ui_{1}} &gt; r_{ui_{2}}) = \frac{\exp(\mathbf{U}_{u}\mathbf{V}_{i_{1}}^{T})}{\exp(\mathbf{U}_{u}\mathbf{V}_{i_{1}}^{T}) + \exp(\mathbf{U}_{u}\mathbf{V}_{i_{2}}^{T})}&lt;/script&gt;

&lt;p&gt;在有了这个概率之后，我们最小化其“负对数似然”（Negative Log Likelihood）:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{\mathrm{row-wise}} = - \sum_{(u, i_{1}, i_{2}) \in \Omega} \log P(r_{ui_{1}} &gt; r_{ui_{2}}) + \sum_{v} \lambda_{V,v}||\mathbf{V}_{v}||^{2}&lt;/script&gt;

&lt;p&gt;非常类似的，我们还可以定义基于用户的配对损失函数，得到：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{\mathrm{column-wise}} = - \sum_{(u_{1} u_{1}, i) \in \Psi} \log P(r_{u_{1}i} &gt; r_{u_{2}i}) + \sum_{u} \lambda_{U,u}||\mathbf{U}_{u}||^{2}&lt;/script&gt;

&lt;p&gt;于是我们可以定义最终的统一的损失函数为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = \alpha L_{\mathrm{row-wise}} + \beta L_{\mathrm{column-wise}} + (1-\alpha -\beta) L_{\mathrm{pointwise}}&lt;/script&gt;

&lt;p&gt;其中，$\alpha \in [0, 1]$和$\beta \in [0, 1]$，并且&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\alpha + \beta &lt;1 %]]&gt;&lt;/script&gt;。作者们认为，这个新的损失函数可以解决之前提出的问题。针对这个新的目标函数，文章提出了详细的优化算法，这里就不赘述了。作者们提出的模型在MovieLens、Netflix以及Amazon的数据集上都要优于不使用排序的纯矩阵分解模型以及一般的协同排序算法。&lt;/p&gt;
</description>
        <pubDate>Sat, 01 Dec 2018 00:00:00 -0800</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2018/12/01/cikm2018-pr/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2018/12/01/cikm2018-pr/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>AISTATS 2018论文导读</title>
        <description>&lt;p&gt;2018年的第21届人工智能和统计学大会（The 21st International Conference on Artificial Intelligence and Statistics）在加那利群岛（Canary Islands）召开。我们在这篇短文里提供一些论文的快速导读，起到抛砖引玉的作用。&lt;/p&gt;

&lt;h2 id=&quot;论文导读&quot;&gt;论文导读&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;boosting-variational-inference-an-optimization-perspective&quot;&gt;Boosting Variational Inference: an Optimization Perspective&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/locatello18a/locatello18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/locatello18a/locatello18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章主要是说最近提出的Boosting Variational Inference（BVI）是把Boosting的思想和Variational Inference相结合的一个新的研究方向，只不过这个方向目前并没有太多的理论支持。这篇论文通过和Frank-Wolfe算法建立联系从而对BVI的收敛性质进行了证明。本篇文章基本上是一个纯理论工作。&lt;/p&gt;

&lt;p&gt;之前的BVI的主要论文是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fangjian Guo, Xiangyu Wang, Kai Fan, Tamara Broderick, David B. Dunson:
&lt;a href=&quot;https://arxiv.org/abs/1611.05559&quot;&gt;Boosting Variational Inference&lt;/a&gt;. CoRR abs/1611.05559 (2016)&lt;/li&gt;
  &lt;li&gt;Andrew C. Miller, Nicholas J. Foti, Ryan P. Adams:
&lt;a href=&quot;http://proceedings.mlr.press/v70/miller17a.html&quot;&gt;Variational Boosting: Iteratively Refining Posterior Approximations&lt;/a&gt;. ICML 2017: 2420-2429&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;personalized-and-private-peer-to-peer-machine-learning&quot;&gt;Personalized and Private Peer-to-Peer Machine Learning&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/bellet18a/bellet18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/bellet18a/bellet18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章主要是把“隐私”（Privacy）领域和优化领域相结合，寻找一种可以保护每一个“个体”（Agent）的隐私但同时能够进行协作从而让最终的优化算法能够达到最优的情况。这方面的研究其实有很多现实的应用。例如说在手机应用中，传统的模式是让所有的手机把数据都集中到服务器上，然后在服务器端再进行机器学习。这种模式很明显具有最高的数据效率但是有可能对用户的数据隐私有侵害。而另一个极端则是把在每个手机上直接进行学习。然而，因为数据有限，这样往往无法学习到有用的模型。这篇文章就是提出了一种如何在这两个极端之间寻求平衡的“异步”（Asynchronous）分布式算法。&lt;/p&gt;

&lt;h3 id=&quot;fast-threshold-tests-for-detecting-discrimination&quot;&gt;Fast Threshold Tests for Detecting Discrimination&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/pierson18a/pierson18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/pierson18a/pierson18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章说的是“阈值测试”（Threshold Test）在过去被提出来用于检测在一些社会活动（比如租房、招聘、警察活动等）中可能存在的“歧视”或“偏差”（Bias)。这篇文章则是提出了快速计算方法使得这样的测试能够快速进行。文章在270万纽约市警察阻止路人的数据集上进行了评测。这篇文章主要是帮助大家扩宽眼界，对于社会性的偏差，目前在学术界已经出现了专门的方法论。&lt;/p&gt;

&lt;h3 id=&quot;batch-expansion-training-an-efficient-optimization-framework&quot;&gt;Batch-Expansion Training: An Efficient Optimization Framework&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/derezinski18b/derezinski18b.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/derezinski18b/derezinski18b-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章讲的是这样一种优化的场景，那就是一个不断增大的数据集，如何在这样的情况下进行“批量”（Batch）学习。这种场景和传统的“随机”（Stochastic）学习不同，因为可以更加有效得利用资源，减少磁盘的读取。这篇文章提出的方法可以和任意的其他优化算法结合，比如L-BFGS。文章展示了提出的方法的很强的收敛性质和以及在并行化下的效果。&lt;/p&gt;

&lt;h3 id=&quot;topic-compositional-neural-language-model&quot;&gt;Topic Compositional Neural Language Model&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/wang18a/wang18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/wang18a/wang18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;自从Neural Language Model（NLM）流行以来，期望能够把NLM和话题模型（Topic Model）进行结合的想法就屡见不鲜。这篇论文也是这个方向的一次尝试。NLM的主要优势是在句子以下的结构上对字句进行建模，而话题模型则往往能够在真个文档甚至更高的层次上对文本的语义进行建模。把这两者结合起来就是想利用这两方面的优势。在这篇文章里，话题模型通过Variational Autoencoder的框架来捕捉到文档的话题（Topic）隐变量。之后，这个变量成为了对不同的语言模型进行加权的权重，而语言文字的产生则利用了Mixture-of-Experts的框架来对不同的RNN语言模型进行整合。需要注意的是，在这篇文章提出的方法里，话题模型对文字的整体数据和语言模型对单独的字句都进行了建模，也就是说，一个文档分别有两个产生过程，一个针对全局文字，一个针对有顺序的字句。&lt;/p&gt;

&lt;h3 id=&quot;making-tree-ensembles-interpretable-a-bayesian-model-selection-approach&quot;&gt;Making Tree Ensembles Interpretable: A Bayesian Model Selection Approach&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/hara18a/hara18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/hara18a/hara18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;最近几年，机器学习的可解释性是一个新的研究领域，不少工作都围绕在如何能够让已经学习的模型或者在学习过程中产生容易被解释的模型。这篇文章针对的是“树集成”（Tree Ensembles）模型，希望通过贝叶斯模型选择（Bayesian Model Selection）的方法来对树模型进行简化从而达到能够可解释的目的。这篇文章的一个可以借鉴也可以精读的地方在于如何把树模型变为概率模型。传统上树模型的整套建模语言都是非概率的，那么如果要使用贝叶斯统计的方法，就一定需要做概率的转换。&lt;/p&gt;

&lt;h3 id=&quot;can-clustering-scale-sublinearly-with-its-clusters-a-variational-em-acceleration-of-gmms-and-k-means&quot;&gt;Can Clustering Scale Sublinearly with Its Clusters? A Variational EM Acceleration of GMMs and K-means&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/forster18a/forster18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/forster18a/forster18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;高斯混合模型（GMM）和K-means都是我们非常熟悉的聚类算法。然而传统上，这两个模型的解法都是和聚类数目C、数据点数N、以及数据的维度D呈线性关系。能不能在这个基础上再加速成为了很多实践者的疑问和困难。这篇文章是希望利用Variational EM来化简整个算法，使得其不依赖于C，而依赖于一个较小的参数G。这篇文章是典型的老树开新花的尝试。&lt;/p&gt;

&lt;h3 id=&quot;parallelised-bayesian-optimisation-via-thompson-sampling&quot;&gt;Parallelised Bayesian Optimisation via Thompson Sampling&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/kandasamy18a/kandasamy18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/kandasamy18a/kandasamy18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;贝叶斯优化（Bayesian Optimisation），或者简称BO，常常用来针对复杂而且昂贵（Expensive）的函数评价，例如超参数（Hyper-parameter）的调节。针对有一些可以并行化的情况下，这篇论文提出了使用“汤姆森采样”（Thompson Sampling）的方法来应对并行的场景有惊人好的效果，并且这篇文章最终提出了“异步并行化的汤姆森采样”。作者们认为这篇文章的一大亮点是给出了理论的结论，这在过去尝试把BO并行化的工作中并不多见。&lt;/p&gt;

&lt;h3 id=&quot;on-the-challenges-of-learning-with-inference-networks-on-sparse-high-dimensional-data&quot;&gt;On the challenges of learning with inference networks on sparse, high-dimensional data&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/krishnan18a/krishnan18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/krishnan18a/krishnan18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章其实是在针对Variational Autoencoder，或者简称VAE，在训练的时候的一个普遍问题，那就是作者们认为VAE在计算过程中并没有最优化Variational参数，而仅仅是找到了或者说是计算出了一组解。因此，作者们认为VAE存在Underfitting的情况，就是说模型的参数学习得不完全。而在传统的Stochastic Variational Learning的语境中，每一步都是根据当前的参数进行的最优化。于是，这篇文章就是把这种思路给应用到VAE上。&lt;/p&gt;

&lt;h3 id=&quot;scalable-generalized-dynamic-topic-models&quot;&gt;Scalable Generalized Dynamic Topic Models&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/jahnichen18a/jahnichen18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/jahnichen18a/jahnichen18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dynamic Topic Model（DTM）相信作为对话题模型（Topic Model）研究者都会不陌生。这可以说是最有影响力的话题模型的扩展。DTM是把时间序列和话题模型结合在一起最直观的一种模型。这篇文章指出，其实DTM提出的模型仅仅是一种叫Weiner Processes（WP）的一个特殊情况。而把DTM给扩展到WP以后，作者们认为就可以使用各种不同的WP的Kernel来对时序建模，大大增强模型的效果。这篇文章还给出了大规模的Variational Inference的模型解法。&lt;/p&gt;

&lt;h3 id=&quot;direct-learning-to-rank-and-rerank&quot;&gt;Direct Learning to Rank And Rerank&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/rudin18a/rudin18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/rudin18a/rudin18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;“排序学习”（Learning to Rank）是不是一个已经完全被研究过的领域呢？答案当然不是。这篇论文就是尝试在一个似乎已经被反复研究过的领域里找到一些新的知识。这篇论文的看点主要是使用了一种目标函数对已有的排序指标例如AUC、NDCG、MAP、MRR等进行了高度总结。另外，这篇文章提出，传统上，我们在优化这些方法或者这些指标的时候，并不是直接去优化这些指标，而是优化这些指标的一些“代理”（Proxy），而就是这些代理可能出了问题，使得最后的结果有可能会有很大的偏差。于是，这篇文章提出了一种直接优化目标函数的方法。&lt;/p&gt;
</description>
        <pubDate>Fri, 25 May 2018 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2018/05/25/aistats2018/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2018/05/25/aistats2018/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>Facebook的应用机器学习平台</title>
        <description>&lt;p&gt;我们在这里对Facebook应用机器学习（Applied Machine Learning）组发布的文章&lt;a href=&quot;https://research.fb.com/publications/applied-machine-learning-at-facebook-a-datacenter-infrastructure-perspective/&quot;&gt;Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective&lt;/a&gt;进行一个简单的分析解读。这篇文章可以让我们对Facebook里机器学习平台以及各个产品应用这个平台的情况有一个很不错的了解。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://research.fb.com/wp-content/uploads/2017/12/hpca-2018-facebook.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自Facebook的17位工程师和科学家。这些人可能仅仅是整个平台的骨干成员。可以看出整个Facebook的机器学习平台是一个有非常多人协作搭建的复杂环境。&lt;/p&gt;

&lt;p&gt;这篇文章可以说是帮助外界解惑了很多迷思或者说是误解。同时，也给了大家一个学习大型互联网公司构建机器学习平台的机会。文章首先提出了一系列的重要观察：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Facebook有很多机器学习的应用场景。计算机视觉的应用仅仅是一个小部分。&lt;/li&gt;
  &lt;li&gt;Facebook有一个很丰富的机器学习库，包括Support Vector Machines、Logistic Regression、GBDT、MultiLayer Perceptron、CNN和RNN。&lt;/li&gt;
  &lt;li&gt;Facebook目前的机器学习场景同时利用GPU和CPU。在训练的时候，有很多是根据需要使用GPU和CPU，但是在Inference的时候，绝大多数还是使用CPU。&lt;/li&gt;
  &lt;li&gt;Facebook的机器学习架构很在乎分布式训练。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文章中列举了一些主要的Facebook机器学习应用场景包括我们熟知的News Feed、Ads和Search以外，还包括一些不那么为人知的应用，如Sigma（Facebook内部的Anomaly Detection的框架）、Lumos（看似是Image的Embedding和信息提取工具）、Facer（Facebook人脸识别框架）、Language Translation（顾名思义，就是一个语言翻译的平台）以及Speech Recognition（顾名思义，一个语音识别的平台）。由此可见，机器学习在Facebook里已经有了很广泛的应用。&lt;/p&gt;

&lt;p&gt;那么，这些应用究竟在使用什么模型呢？Facer在使用SVM。Sigma在使用GBDT。Ads、News Feed和Sigma都在使用MLP。而Lumos、Facer在使用CNN。Text Understanding、Translation、Speech Recognition在使用RNN。&lt;/p&gt;

&lt;p&gt;对于深度学习框架方面，目前Facebook支持两个框架：Caffe2和PyTorch。它们分别是生产环境和研究环境。作者们阐述了一下为什么要让这两个环境各不同。简而言之就是这两个环境的需求不用，一个要求稳定高效，一个要求能够灵活多变。当然，作者们也看到了多个深度学习框架带来的潜在问题。于是作者们提到了一个叫做Open Neural Network Exchange（ONNX）的交换格式。想来这个交换格式就是为了加快从一个框架到另外一个框架的转换速度。&lt;/p&gt;

&lt;p&gt;从模型训练的时效性来看，有些应用的训练是每天，比如News Feed，而Search是每个小时，而其他应用则有些是每个星期或者每好几个月。而在Inference来看，第一，作者们提到了，不同的应用有可能需要不同的Inference的架构（Architecture）。同时，作者们还提到了并不是一开始就需要最精确的预测，有时候可以先展现给用户看没那么精确的结果，然后更加精确的结果可以算好以后再推给用户。&lt;/p&gt;

&lt;p&gt;这篇文章还有很多细节的点值得关注。总之，如果你对机器学习在大型互联网公司的应用有兴趣，并且也想知道平台、软硬件的整体架构信息，这篇文章是一个不错的阅读材料。&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Dec 2017 00:00:00 -0800</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/12/22/facebook-ml/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/12/22/facebook-ml/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>KDD 2017大会综述</title>
        <description>&lt;p&gt;每年，Association for Computing Machinery（ACM）旗下的Special Interest Group (SIG) on Knowledge Discovery and Data Mining（简称SIGKDD）都要举办年度的SIGKDD Conference on Knowledge Discovery and Data Mining（KDD）大会，为学术界和工业界的数据科学学者、研究人员、工程师以及学生提供一个交流、学习和发展的平台。今年，The 23rd SIGKDD Conference on Knowledge Discovery and Data Mining（KDD）于2017年8月13日到17日在加拿大的Halifax, Nova Scotia举行。&lt;/p&gt;

&lt;p&gt;KDD是数据挖掘以及数据科学领域的顶级会议。KDD最早从1989年开始的KDD 研讨班（Workshop）发展而来。当时的研讨班依托于IJCAI大会或者AAAI大会（另一个有影响力的人工智能大会），由Gregory Piatetsky-Shapiro创办。研讨班成功举办几届之后，1995年Usama Fayyad和Ramasamy (Sam) Uthurusamy把研讨班升级成为了会议，并且在加拿大的蒙特利尔举办了第一届的KDD大会。大会至今已经有20多年的历史。&lt;/p&gt;

&lt;h2 id=&quot;大会主要奖项&quot;&gt;大会主要奖项&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;今年的SIGKDD创新奖（ Innovation Award）授予了加拿大Simon Fraser University计算科学学院的教授Jian Pei。Jian是数据挖掘界的著名华人学者，是ACM和IEEE的双料院士。其发表过200多篇论文，引用量多达7万多次，Google H-Index达到74。他和Jiawei Han以及Micheline Kamber合著的数据挖掘教材《Data mining: Concepts And Techniques》已经成为经典读物，引用数就多于3万次。Jian还是IEEE 旗下的数据挖掘权威期刊Transactions of Knowledge and Data Engineering （TKDE）的主编，并且是清华大学以及浙江大学的客座教授。在此之前，Jian已经获得过2015年的SIGKDD服务奖（ Service Award）、 2014年 IEEE旗下数据挖掘会议 ICDM 的研究贡献奖（Research Contributions Award） ，以及2008年KDD 最佳应用论文奖（Best Application Paper Award）、2014年PAKDD 最佳论文奖（Best Paper Award）等。Jian是数据挖掘领域权威Jianwei Han的博士生（2002年毕业）。这次创新奖主要还提及了Jian在Sequential Pattern Mining（SPM）数据挖掘算法和研究领域的主要贡献，包括FP-Growth 和PrefixSpan算法。这两个算法都是著名的SPM算法，其中FP-Growth的论文（Mining Frequent Patterns without Candidate Generation）引用高达7千多次，而PrefixSpan的论文（PrefixSpan: Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth）引用也多达2千多次。&lt;/p&gt;

&lt;p&gt;大会的另外一个重要奖项SIGKDD时间检验奖（Test of Time Award）授予了美国康奈尔大学信息科学系主任、计算机科学系教授Thorsten Joachims。这个时间检验奖主要是奖给过去10年左右的时间里在KDD的会议上发表的论文中最有影响力的工作（引用次数是其中一个指标）。Thorsten是机器学习界享有盛誉的学者，是ACM和AAAI的双料院士。所有论文超过4万次引用。他2001年在德国的多特蒙德大学博士毕业之后加入康奈尔大学从事机器学习的研究。在获得这个奖项之前，Thorsten获得过2017年ACM WSDM 的最佳论文奖（Best Paper Award）、2016年ACM SIGIR的时间检验奖（Test-of-Time Award）、2015年ACM KDD的时间检验奖、2009年ECML的最佳论文奖（Best Paper Award）、2009年ICML的10年最佳论文奖（Best 10-Year Paper Award）、2006年ACM KDD的最佳论文奖（Best Paper Award）、2005年ICML的最佳论文奖、2005年ICML的优秀学生论文奖、2005年ACM KDD的最佳学生论文奖等。这次时间检验奖授予Thorsten是为了表彰他的论文“Training Linear SVMs in Linear Time”。该论文也是2006年的KDD最佳论文，引用数超过1600多次。这篇文章解决的是大规模优化支持向量机（Support Vector Machines）的问题。在此之前的很多支持向量机的实现都无法达到线性的时间复杂度，因此也就无法应用到大规模的数据上。这篇文章是第一次提出了简单易行的支持向量机实现。算法对于分类问题（Classification）达到了O(SN)（其中S是非0的特征数目而N是数据点的个数），也就是实现了线性时间复杂度。算法本身简单、高效、易于实现，并且理论上可以扩展到Kernel的情况。Thorsten在他的软件包SVMLight中实现了该算法。这个软件包一度成为了支持向量机研究和开发的标准工具。&lt;/p&gt;

&lt;p&gt;大会还把今年的SIGKDD服务奖（Service Award）颁给了香港科技大学计算机系主任Qiang Yang教授，以表彰他在近几年推动SIGKDD的各种活动发展，特别是SIGKDD在中国的分部（China Chapter）所做的努力。Qiang本人是ACM杰出科学家、AAAI院士、IEEE院士。在他的领导下，2016年，SIGKDD中国分部开始运营。2016年一年，中国分部就举行了超过10场活动，并且吸引了超过500名会员。Qiang在中国还举行了多场研讨班和各类讲座，分享了关于Transfer Learning以及Recommendation Systems相关的很多研究成果。Qiang Yang本人的论文有超过3万次的引用。&lt;/p&gt;

&lt;p&gt;从会议论文的角度来看，这次会议的最佳研究类论文（Best Research Paper Award）授予了“ Accelerating Innovation Through Analogy Mining”，其作者群来自耶路撒冷希伯来大学以及卡内基梅隆大学。第二名则被“Toeplitz Inverse Covariance-Based Clustering of Multivariate Time Series”夺取，其作者群来自斯坦福大学。最佳应用数据科学论文（Best Applied Data Science Paper Award）被“HinDroid: An Intelligent Android Malware Detection System”取得，其作者群来自于西弗吉尼亚大学以及香港科技大学。第二名则被“DeepSD: Generating High Resolution Climate Change Projections”夺得，其作者群来自美国的东北大学以及美国NASA。&lt;/p&gt;

&lt;h2 id=&quot;大会参与概况&quot;&gt;大会参与概况&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;今年的大会是在美国本土外举办的最大的一届KDD会议。整个大会有1656名参会者，来自51个国家和地区。其中美国的参会者是最多、其次是中国、加拿大、印度。会议的赞助金额达到了54万美元，是在美国本土外举办的最高记录。为赞助学生旅行，大会总共奖励了高达15多万美元的金额，创下了大会的记录。论文的投稿数达到了1143篇，也是创下了最新的记录。大会最终录用了130篇文章，录用率在8%左右。可以说依然保持了非常高的会议水平。&lt;/p&gt;

&lt;p&gt;这次大会共有3个主题演讲（Keynote Speech）。64个报告演讲（Oral Presentation）和66个展板报告（Poster）。整个大会还有10个全天的研讨班（Workshop）和10个半天的闫天宝。大会包含了20个传统的讲座（Tutorial）以及8个实践（Hands-on）讲座。&lt;/p&gt;

&lt;h2 id=&quot;大会主题演讲&quot;&gt;大会主题演讲&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这次的大会主题演讲有一个特色，那就是三位女性科学家组成的主题演讲者群体。&lt;/p&gt;

&lt;p&gt;大会第一个主题演讲来自Bin Yu，加州大学伯克利分校（University of California at Berkeley
）统计学教授。Bin Yu是美国科学院院士（U.S. National Academy of Sciences）、美国艺术与科学学院院士（American Academy of Arts and Sciences），还是IEEE院士、IMS院士、 ASA院士以及 AAAS院士。她长期从事统计、机器学习方法的研究以及如何应用领域知识解决复杂问题。Bin还是微软和北京大学统计和信息科学联合实验室的创始人。Bin的演讲主题是“Three Principles of Data Science: Predictability, Stability, and Computability”，主要试图讲解的是Stability对于Predictability以及Interpretability的重要性。Bin认为自己提出的这三个要素是统计学习的根本思想之一，他们之间的联系尤为重要。紧接着，她通过如何应用深度模型（特别是卷积神经网CNN）对神经元的活动进行观测这一个项目解释了这三个要素在具体事例中的呈现。她在演讲的第二部分讲解了如何利用隐变量模型（Latent Variable Models）以及基于LASSO的模型来分析政治性的电视广告中的语气和政党倾向性。这两个项目都展现了Bin所谓的稳定性（Stability）对于预测性（Predictability）的重要性。&lt;/p&gt;

&lt;p&gt;第二个主题演讲来自Cynthia Dwork，哈佛大学教授、微软研究院杰出科学家（Distinguished Scientist）。Cynthia是美国科学院院士（National Academy of Sciences）、美国工程院院士（National Academy of Engineering）、美国艺术与科学学院院士（American Academy of Arts and Sciences）、美国哲学学会院士（American Philosophical Society）以及ACM院士。Cynthia长期致力于基于隐私的数据分析（Privacy-Preserving Data Analysis）的工作，并且是著名的Differential Privacy思想的提出者之一。2015年获得理论计算机界的哥德尔奖。Cynthia演讲的主题是“What’s Fair?”。这个是一个近期越来越收到关注的题目，那就是人工智能或者机器学习算法会不会因为从过去的数据中学习从而带有过去的偏见。典型的偏见有比如在预测犯罪的时候，对某一个种族或者族群会有高于常规的预测率。这个演讲就是讨论了包括如何定义是否“公平”，如何算是有偏见，到底是个人偏见还是群体偏见等等问题。从现场的反应来看，总体感觉，算法的公平性或者偏见性是一个非常新、而且可能会有争议性的话题。Cynthia在这个场合提出来也是需要一定勇气和远见的。&lt;/p&gt;

&lt;p&gt;第三个主题演讲来自Renée J. Miller，多伦多大学信息系统系主任、计算机系教授。Renée是加拿大皇家协会院士（Royal Society of Canada）、加拿大科学院院士（Canada’s National Academy）以及ACM院士。Renée是一个具有神秘色彩的学者。大会网站上并没有放她的照片，原因是她不愿意自己的相貌被搜索引擎给准确记住。Renée的演讲主题是“The Future of Data Integration”。应该说这个主题放在一个以数据科学为核心的会议上还是很应景的。毕竟，很多都说数据科学80%甚至更多的时间在处理数据而只有20%的时间在做真正的算法和模型革新。Renée从数据库领域出发，用非常浅显的语言讲解了这20年数据集成（Data Integration）领域的主要发现，以及如何利用这些核心算法来达到“发掘数据和整个数据格式”的作用。&lt;/p&gt;

&lt;h2 id=&quot;大会的几个趋势&quot;&gt;大会的几个趋势&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这次会议有这么几个趋势和亮点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;大家更加重视模型，特别是深度学习模型的可解释性。&lt;/li&gt;
  &lt;li&gt;Causal Inference和Machine Learning的结合成为新方向。&lt;/li&gt;
  &lt;li&gt;对算法和模型的去Bias成为一个新的课题。&lt;/li&gt;
  &lt;li&gt;各大公司的招聘力度非常大，在某一天内就有Amazon、Microsoft、Airbnb、Snapchat、Pinterest以及其它公司的Happy Hour，感觉人才就在那么几家公司赶场。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体最大的感觉是KDD已经成为了数据科学的盛宴。&lt;/p&gt;
</description>
        <pubDate>Wed, 30 Aug 2017 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E4%BC%9A%E8%AE%AE/2017/08/30/kdd2017/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E4%BC%9A%E8%AE%AE/2017/08/30/kdd2017/</guid>
        
        
        <category>会议</category>
        
      </item>
    
  </channel>
</rss>
