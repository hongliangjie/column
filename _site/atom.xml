<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>期望最大化</title>
 <link href="http://column.hongliangjie.com/atom.xml" rel="self"/>
 <link href="http://column.hongliangjie.com/"/>
 <updated>2016-04-18T09:00:10-07:00</updated>
 <id>http://column.hongliangjie.com</id>
 <author>
   <name>洪亮劼</name>
   <email>hongliangjie@gmail.com</email>
 </author>

 
 <entry>
   <title>论推荐系统的Exploitation和Exploration</title>
   <link href="http://column.hongliangjie.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/13/exploration/"/>
   <updated>2016-04-13T00:00:00-07:00</updated>
   <id>http://column.hongliangjie.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/13/exploration</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;/%E4%B8%AA%E6%80%A7%E5%8C%96,%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/07/personalization-or-not/&quot;&gt;上一篇文章&lt;/a&gt;讲到，一个推荐系统，如果片面优化用户的喜好，很可能导致千篇一律的推荐结果。文中曾经用了一节来讨论为什么使用Exploitation &amp;amp; Exploration (E &amp;amp; E)结果可能依然不能“免俗”。其实，E &amp;amp; E是推荐系统里很有意思，但也非常有争议的一个算法。一方面，大家都基本明白这类算法的目的，每年有很多相关论文发表。另一方面，这是工业界对于部署这类算法非常谨慎，有的产品经理甚至视之为“洪水猛兽”。这篇文章就是要分析一下导致这个现象的一些因素。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;走一步看一步的策略&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;这里再简单阐述一下什么是E &amp;amp; E。简单来说，就是我们在优化某些目标函数的时候，从一个时间维度来看，当信息不足或者决策不确定性（Uncertainty）很大的时候，我们需要平衡两类决策：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;选择现在可能最佳的方案&lt;/li&gt;
  &lt;li&gt;选择现在不确定的一些方案，但未来可能会有高收益的方案&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在做这两类决策的过程中，我们也逐渐对所有决策的不确定性不断更新不断加以新的认识。于是，&lt;strong&gt;最终&lt;/strong&gt;，从时间的维度上来看，我们在不确定性的干扰下，依然能够去&lt;strong&gt;优化&lt;/strong&gt;目标函数。&lt;/p&gt;

&lt;p&gt;也就是说，E &amp;amp; E可以看做是一个&lt;em&gt;优化过程&lt;/em&gt;，需要多次迭代才能找到比较好的方案。&lt;/p&gt;

&lt;h2 id=&quot;e--e&quot;&gt;E &amp;amp; E的应用历史&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;早期把E &amp;amp; E应用于新闻推荐系统的文章（比如&lt;sub&gt;[1,2,4]&lt;/sub&gt;）主要关注于Yahoo Today Module（下图中间的模块）这一产品，这也基本上是最早E &amp;amp; E出现在互联网应用的尝试，目的是为了优化点击率（CTR）。而更早一些的奠基性的文章（如&lt;sub&gt;[3]&lt;/sub&gt;）则是在广告的数据集上展示的实验结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/yahoo_today.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Yahoo Today Module其实为E &amp;amp; E提供了一些很多学者和工业界人士忽视了的条件和成功因素。如果不考虑这些因素，鲁莽得使用这些文献相似的算法到其他场景，这可能产生很差的效果。那么是哪些因素呢？主要由两点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;相对少量的优质资源&lt;/strong&gt;： Yahoo Today Module每天的Content Pool其实并不大。这里面都是网站编辑精选了的大概100篇文章。这些文章原本的质量就非常高。无论是这里面的任何一组，用户体验都没有明显变差。Content Pool每天都人为更换。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;非常大的用户量&lt;/strong&gt;：有亿万级的用户可能最终是从算法&lt;em&gt;随机&lt;/em&gt;产生的文章排序中选择了阅读的文章。然而，因为用户数量巨大，所以算法就相对比较容易Converge到稳定的方案。也就是前面讲的，优化CTR的状态。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;正因为有了（1）和（2），Deepak他们享受了在后来学者们所无法想象的“奢侈”，比如运行Epsilon-Greedy这种简单粗暴的E &amp;amp; E算法，甚至是&lt;strong&gt;完全随机&lt;/strong&gt;显示新闻，收集到了很多&lt;em&gt;无偏&lt;/em&gt;（Unbiased）的数据，为很多学术工作奠定了数据基础。时至今日，也有很多后续学者基于Yahoo Today Module的随机数据进行算法改进。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Deepak Agarwal，现任LinkedIn VP Of Engineering，主管Machine Learning和Relevance，是早年Yahoo推荐系统的缔造者之一，也是推荐系统的学术权威之一。其著作《Statistical Methods for Recommender Systems》是初学者必不可少的入门教材。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bee-Chung Chen，现任LinkedIn Senior Staff Software Engineer，其PhD导师Raghu Ramakrishnan现在是微软的CTO for Data和Technical Fellow（此人是早期知识图谱Knowledge Graph概念的推崇者）。Bee-Chung是Deepak在Yahoo年代的老部下，并且追随其到LinkedIn。他们是很多工作的共同作者。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lihong Li，现任微软研究院资深研究员。其在Yahoo的一系列有关Contextual Multi-Armed Bandit以及Thompson Sampling的文章奠定了其在这个领域的权威位置。他在WSDM 2015做的关于如何连接线下和线上系统的评估的讲座&lt;sub&gt;[5]&lt;/sub&gt;，是非常有价值的学术资料。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;没有了这两条因素，Deepak的解决方案可能都没法在当时的Yahoo施行。原因很简单，如果资源良莠不齐，如果资源数量非常大，那么在仅有的几个展示位置，优质资源显示的可能性在短期内就会比较小（因为系统对于大多数的资源还有很高的不确定性，需要Explore）。而由于优质资源显示得少了，用户就会明显感受到体验的下降，直接可能就是更倾向于不点击甚至放弃使用产品。于是用户不Engage这样的行为又进一步减缓了系统学习资源的不确定性的速度。这时也许现在的亿万级用户数都没法满足学习所有资源的用户数量（毕竟所有用户只有一部分会落入Exploration）。&lt;/p&gt;

&lt;p&gt;Deepak后来在LinkedIn推了相似的思路&lt;sub&gt;[6]&lt;/sub&gt;，但是为了模拟Today Module的这些条件，则是对用户的内容流里的数据进行了大规模的过滤。这样只有少数的信息符合高质量的要求，并且能够在用户数允许的情况下Explore到合适的解决方案。&lt;/p&gt;

&lt;h2 id=&quot;e--e-1&quot;&gt;E &amp;amp; E的产品部署难点&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;我们在上一节探讨了E &amp;amp; E的早期产品历史。这一节，我们来讲一下E &amp;amp; E的产品部署难点。这些难点是普遍高于具体E &amp;amp; E算法选择（比如选某一个UCB或者某一个Thompson Sampling)的产品工程解决方案的抉择。为了便于讨论，我们把文献里所有E &amp;amp; E算法整体叫做“Random”简称R算法，而把不做E &amp;amp; E的算法叫做“Deterministic”简称D算法。这里面的假设是，D算法比较静态，能够产生高质量&lt;strong&gt;一致性&lt;/strong&gt;的内容。这里的一致性是指用户在短时间内的用户体验比较稳定，不会有大幅度的界面和内容变化。相反，R算法整体来说是不确定性比较大，用户体验和产生的内容可能会有比较大的波动。&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;难点一：如何上线测试&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;这看上去不应该是难点，但实际上需要额外小心。传统E &amp;amp; E文献，只是把问题抽象为每一次访问需要做一个决策的选择。然而，文献却没有说，这些访问是否来自同一个用户。那么，理论上，E &amp;amp; E应该对所有的访问不加区别，不管其是否来自同一个用户。用我们这篇文章的术语来说，就是所有的流量都做R算法。虽然理论上这样没有问题，但实际上，用户体验会有很大的差别。特别是一些推荐网站，用户希望自己前后两次对网站的访问保持&lt;strong&gt;一致性&lt;/strong&gt;。如何不加区分得做R，很可能对于同一个用户来说，两次看见的内容迥异。这对用户熟悉产品界面，寻找喜爱的内容会产生非常大的障碍。&lt;/p&gt;

&lt;p&gt;那么，我们对绝大部分用户做D，对另外一（小）部分用户做R，这样会好一些吗？这其实就是用“牺牲”少部分用户的代价来换取绝大多数人的体验一致性。这样实现也是最直观的，因为很多在线系统的A/B测试系统是根据用户来进行逻辑分割的。也就是说，某一部分用户会进入一个Bucket，而另一批用户会进入另外一个Bucket。按用户来做D &amp;amp; R可以很容易和Bucket System一致起来，方便部署。当然，这样做也是有潜在风险的。那就是，这部分老做R的用户，在当了别人的小白鼠以后，很可能永远放弃使用产品。&lt;/p&gt;

&lt;p&gt;另外，我们还需要考虑“学习流程”（Learning Procedure）如何搭建。传统的E &amp;amp; E其实是把“学习流程”搭建在同一批流量上。也就是，模型更新所依赖的数据来自于同样一批流量。融合上面的讨论以后，我们可以总结出下面这些方案：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;全部流量做R，全部流量做学习。（方案A）&lt;/li&gt;
  &lt;li&gt;一部分用户做D，其他用户做R。更新D的数据来自D，更新R的数据来自R。（方案B）&lt;/li&gt;
  &lt;li&gt;一部分用户做D，其他用户做R。更新D的数据来自D+R，更新R的数据来自R。（方案C）&lt;/li&gt;
  &lt;li&gt;一部分用户做D，其他用户做R。更新D的数据来自D+R，更新R的数据来自D+R。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最后一个方案其实是逻辑上不对的。因为R本身要求算法的回馈是来自R的决策，而使用D+R来学习模型，就产生了R的反馈信息被“污染”的现象。所以，合理的选择只能是前三种方案中的一种。&lt;/p&gt;

&lt;p&gt;如何选择一个好的部署模式，目前并没有公开的文献以及比较能够通用的方案。这方面其实是一个值得思考的研究课题。&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;难点二：如何评测&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;对现代推荐系统（以及很多类似系统）来说，在线系统的评测，也就是说如何衡量一个算法或者一个功能的好坏，往往依赖于复杂的A/B测试系统。这里的逻辑很简单，那就是，把一群人分为&lt;strong&gt;相等&lt;/strong&gt;的两份（可以扩展到多份），一部分看A系统结果，另一部分人看B系统结果，然后根据一些用户指标（比如点击率）来决定究竟是A系统好还是B系统。也就是说，A/B测试系统是按照人群来分的。对于同一个人来说，在某一段时间内，一般是只能看到A&lt;strong&gt;或者&lt;/strong&gt;B系统，但&lt;strong&gt;不&lt;/strong&gt;是&lt;strong&gt;都&lt;/strong&gt;能看见。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ab_testing.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们来讨论一下前一节的几个方案在评测方面的利弊。方案A要求全部流量做R，于是这个方案，依照定义，就没法和其他D作比较，只能两种不同的R相比。由于R对于用户体验上来说一般是有损失的，只能比较R和R，造成了没法量化整体系统的用户体验损失量，这可能是无法接受的一种局面。&lt;/p&gt;

&lt;p&gt;方案B的设置很自然，可以比较单组或者多组D和R的差别，互相没有影响。坏处当然就是所有D部分的用户都没有Exploration，而R的部分可能流失用户。方案C没法直接评测，因为一个Bucket的D受到了R的影响。两个Bucket不独立。我们至少需要四个Bucket。一组Bucket是D1+R1，另外一组Bucket是D2+R2。在比较Bucket Performance的时候，我们需要综合比较(D1+R1)和（D2+R2）。这当然对A/B Testing系统有了较高的要求。&lt;/p&gt;

&lt;p&gt;另一方面，对于方案B和方案C来说，R只运行在一部分用户上，模型可能需要很长的时间学习，甚至在规定的时间内没法完成学习。这就需要加大R的部分。然而加大R，则可能流失用户。于是，这里的决策核心就是D部分留住的老用户加上扩展的新用户，能否大大超过R部分流失的用户。&lt;/p&gt;

&lt;h3 id=&quot;section-3&quot;&gt;难点三：如何平衡产品&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;通过前面两个难点可以看出，E &amp;amp; E&lt;strong&gt;几乎一定&lt;/strong&gt;会导致产品的用户体验下降，至少在短期内。如何弥补这一点，技术上其实比较困难。比如做Deepak那样的过滤是一种思路，那就是只在优质内容里Explore。当然，有人会说，这样其实也没有多大的意义。然而，一旦把质量的闸门打开了，那就会对用户体验带来很大的影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pm.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这也是很多产品经理对于E &amp;amp; E非常谨慎的原因。能不做就不做。而且，在牺牲了用户体验的结果后，E &amp;amp; E所带来的好处其实很难评测，这主要是线上产品的评测机制和评测原理所决定的。目前还没有比较统一的解决方案。如何能够做到“用户友好型”E &amp;amp; E呢？&lt;/p&gt;

&lt;p&gt;这里面可以有两种思路：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;不是所有人群的所有访问都适合做R。但是和传统的E &amp;amp; E不同的是，做“反向E &amp;amp; E”。也就是说，我们只针对非常Engaged的人做Exploration，而并不是新用户或者是还没有那么Engaged的人群。这个思路是和现在E &amp;amp; E完全相反，但是更加人性化。&lt;/li&gt;
  &lt;li&gt;夹带“私货”。也就是更改E &amp;amp; E的算法，使得高质量的内容和低质量的内容能够相伴产生，并且高质量的内容更有几率排在前面。这样用户体验的损失可控。这个思路我们在&lt;sub&gt;[7]&lt;/sub&gt;里有所尝试，效果不错。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其实，E &amp;amp; E和产品的结合点应该是工程和研究的重点，但很遗憾的是，碍于数据和其他方面的因素，这方面的研究工作几乎没有。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;可以挖掘的问题&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;前面说了E &amp;amp; E在工程部署以及产品上的难点。这里再提及一下E &amp;amp; E可以挖掘的方向：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;“收集数据”，作为Causal Inference中消除现在产品的“偏见”（Bias）的重要步骤&lt;sub&gt;[8,9]&lt;/sub&gt;，这方面的工作还比较少，还没有在推荐系统里广泛使用。&lt;/li&gt;
  &lt;li&gt;用户友好型的E &amp;amp; E方案（前面已经提及了），能够在尽可能少的情况下打扰用户，学到尽可能多的信息。这方面目前不是学术圈的重点，但却是工程产品方面非常需要的解决方案。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;section-5&quot;&gt;结论&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;本篇文章讨论了推荐系统中Exploitation和Exploration的使用，分享了这方面的历史，探讨了工程和产品的技术难点，希望这篇文章能够为相关方向抛砖引玉。&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;参考文献&lt;/h2&gt;
&lt;hr /&gt;
&lt;ol&gt;
  &lt;li&gt;Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. &lt;a href=&quot;http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf&quot;&gt;&lt;strong&gt;A Contextual-Bandit Approach to Personalized News Article Recommendation&lt;/strong&gt;&lt;/a&gt;. In Proceedings of WWW 2010.&lt;/li&gt;
  &lt;li&gt;Deepak Agarwal, Bee-Chung Chen, Pradheep Elango. &lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=5360225&quot;&gt;&lt;strong&gt;Explore/Exploit Schemes for Web Content Optimization&lt;/strong&gt;&lt;/a&gt;. In Proceedings of ICDM 2009.&lt;/li&gt;
  &lt;li&gt;John Langford, Alexander Strehl, and Jennifer Wortman. &lt;a href=&quot;http://dl.acm.org/citation.cfm?doid=1390156.1390223&quot;&gt;&lt;strong&gt;Exploration Scavenging&lt;/strong&gt;&lt;/a&gt;. In Proceedings of ICML 2008.&lt;/li&gt;
  &lt;li&gt;Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. &lt;a href=&quot;http://www.gatsby.ucl.ac.uk/~chuwei/paper/wsdm11.pdf&quot;&gt;&lt;strong&gt;Unbiased Offline Evaluation of Contextual-Bandit-Based News Article Recommendation Algorithms&lt;/strong&gt;&lt;/a&gt;. In Proceedings of WSDM 2011.&lt;/li&gt;
  &lt;li&gt;Lihong Li. &lt;a href=&quot;http://research.microsoft.com/pubs/240388/tutorial.pdf&quot;&gt;&lt;strong&gt;Offline Evaluation and Optimization for Interactive Systems&lt;/strong&gt;&lt;/a&gt;。 In Proceedings of WSDM 2015.&lt;/li&gt;
  &lt;li&gt;Deepak Agarwal. &lt;a href=&quot;http://www.ueo-workshop.com/wp-content/uploads/2013/10/UEO-Deepak.pdf&quot;&gt;&lt;strong&gt;Recommending Items to Users: An Explore/Exploit Perspective&lt;/strong&gt;&lt;/a&gt;. In Proceedings of the 1st Workshop on User Engagement Optimization at CIKM 2013.&lt;/li&gt;
  &lt;li&gt;Liangjie Hong and Adnan Boz. &lt;a href=&quot;http://arxiv.org/abs/1604.03506&quot;&gt;&lt;strong&gt;An Unbiased Data Collection and Content Exploitation/Exploration Strategy for Personalization&lt;/strong&gt;&lt;/a&gt;. ArXiv. 2016.&lt;/li&gt;
  &lt;li&gt;Lihong Li, Jin Young Kim, and Imed Zitouni. &lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2685311&quot;&gt;&lt;strong&gt;Toward Predicting the Outcome of an A/B Experiment for Search Relevance&lt;/strong&gt;&lt;/a&gt;. In Proceedings of WSDM 2015.&lt;/li&gt;
  &lt;li&gt;Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, Thorsten Joachims.
&lt;a href=&quot;http://arxiv.org/abs/1602.05352&quot;&gt;&lt;strong&gt;Recommendations as Treatments: Debiasing Learning and Evaluation&lt;/strong&gt;&lt;/a&gt;. ArXiv. 2016.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>个性化推荐是不是伪命题</title>
   <link href="http://column.hongliangjie.com/%E4%B8%AA%E6%80%A7%E5%8C%96,%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/07/personalization-or-not/"/>
   <updated>2016-04-07T00:00:00-07:00</updated>
   <id>http://column.hongliangjie.com/%E4%B8%AA%E6%80%A7%E5%8C%96,%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/07/personalization-or-not</id>
   <content type="html">&lt;p&gt;最近，有一位网友在微博上说，&lt;a href=&quot;http://weibo.com/1830516311/Dp4Vs81ih?from=page_1005051830516311_profile&amp;amp;wvr=6&amp;amp;mod=weibotime&amp;amp;type=comment&quot;&gt;推荐是不是个伪命题？连续几天试用了据说很好的某头条，某资讯以及某快报，感觉逃脱不了看什么就是什么的套路&lt;/a&gt;。也有人说，这是Exploitation &amp;amp; Exploration出了问题，没有很好得Exploration导致的结果。那么，个性化推荐到底是不是伪命题呢？为什么很多推荐系统过了一段时间以后就老是推荐类似的东西呢？本篇文章就要尝试分析和探讨这个“千篇一律”的问题。&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;推荐是为了预测用户喜好的物品吗&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;要知道个性化推荐是不是伪命题，我们就必须从个性化推荐的&lt;strong&gt;目的&lt;/strong&gt;说起。一个通常意义上的推荐系统，顾名思义，就是要给用户推荐可能会交互（包括购买、点击、点赞等等）并且可能喜爱的物品，比如Amazon的商品、Netflix的电影、LinkedIn的工作以及Yahoo的新闻等。当然，这只是一个非常肤浅的定义。我们等会儿会看到这个定义的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/netflix.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;自从Netflix Prize以来，推荐系统的研究和生产实际，基于以上这个关于推荐的肤浅定义，把整个系统的模型简化成了——预测用户对于某个事物的喜爱，也就是人们常说的Rating Prediction的问题&lt;sub&gt;[3]&lt;/sub&gt;。Collaborative Filtering，特别是基于Matrix Factorization&lt;sub&gt;[2]&lt;/sub&gt;和Latent Factor Model&lt;sub&gt;[1]&lt;/sub&gt;的各种方法及其变种大行其道，一时间似乎成为了推荐系统的代名词。于是，很多实际系统的设计者和开发着，不管自己产品的真实定位究竟如何，都选择利用协同过滤来打造自己的推荐系统。&lt;/p&gt;

&lt;p&gt;协同过滤是否有效呢？答案是肯定的。当然，这有一个巨大的前提，那就是，如果我们的产品，真的采用这个推荐的肤浅定义，仅仅注重于推荐用户是否喜欢的东西。协同过滤，辅佐以Machine Learning的很多手段（比如Tree-based Models)，常常能够在Rating Prediction这个问题上有不俗的成绩。然而，往往用户在使用产品一段时间以后就会得出微博上那位网友的体验。产品经理也会常常陷入困境，不知道如何改进产品。&lt;/p&gt;

&lt;p&gt;注意，有一些Rating Prediction的变种问题，其实质还是在优化用户对某一类事物的喜爱。比如，不仅仅预测单个物品的评分，而是看用户在一个物品列表中选择了哪些物品（代表作&lt;sub&gt;[7]&lt;/sub&gt;）。也就是看用户是否更&lt;strong&gt;偏好&lt;/strong&gt;某些物品。尽管这样似乎更准确抓住了推荐问题的产品定义，但依然没有能够摆脱优化用户喜好所带来的问题。&lt;/p&gt;

&lt;p&gt;实际上，任何以用户喜好为目标的推荐系统，不管优化对象是简单的点击率（Click-Through-Rate）还是驻留时间（Dwell-Time）&lt;sub&gt;[4]&lt;/sub&gt;，抑或是上面提到的评分，都很难逃脱上述问题。那么为什么优化用户喜好就会带来上述问题呢？&lt;/p&gt;

&lt;p&gt;原因很直观，要想优化用户喜好，那就必然强调用户的历史行为。协同过滤或者是机器学习导向的算法，都试图充分挖掘单个用户以及群体用户的喜好，并且加以推崇到极致（Optimization)。打个比方，如果你才查看了Amazon上的某款最新的相机，一般的推荐系统就会显示很多相似的相机或者其他各种相机配套产品，并希望最大化这&lt;strong&gt;单次&lt;/strong&gt;点击（或者查询）的“收益”。在这些系统看来，既然你已经“表达了”对相机兴趣，那么系统就要抓住这么一个机会。如果你不单单是偶然看了一次相机，而是研究了一小会儿以后，推荐系统就会认为你已经表达了很“&lt;strong&gt;强烈&lt;/strong&gt;”的对相机的喜好，那好，让你的整个屏幕都充满相机吧。也许有人可能会想到Discount用户短期内的一些行为这种做法，而对用户长期的一些行为更加关注（比如&lt;sub&gt;[8]&lt;/sub&gt;）。这种方法也许可以缓解“满屏相机”的现象，但是很难从根本上解决问题，况且这个Discount的参数本身也很难调试。于是，长期优化用户喜好，在绝大多数情况下，用户就会产生Filtering Bubble的效果，也就是说，用户自己只能看见自己喜欢的东西，并且不断强化。而从整个系统来讲，很难跳出推荐的东西千篇一律的效果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/filter_bubble.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当然，这里还有一个更加严重的问题，这也是新闻推荐经常容易出现的问题。那就是，一些“资深用户”（Engaged Users），因为比常人更多得和一个系统交互，看了各种各样的新闻，有时可能完全不是因为喜欢，而是消磨时间或者随便看着玩儿，强化优化用户喜好的推荐系统很可能无法分辨这样的行为。过度优化“喜好”，可能带来的结果就是系统误认为这些用户什么都喜欢。我们下面还会深入讨论这个问题。&lt;/p&gt;

&lt;p&gt;只优化用户喜好的&lt;strong&gt;根本问题&lt;/strong&gt;，其实是&lt;strong&gt;忽略了大视野&lt;/strong&gt;（Big Picture）。那么，什么是推荐系统的大视野呢？这里先卖一个关子，我们到文章的最后再来揭晓。&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;看一步走一步的优化策略&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;上一节我们剖析了优化用户喜好的问题。熟悉推荐系统的人可能会说，这有很成熟的解决方案啊，Exploitation &amp;amp; Exploration（E &amp;amp; E）就是专门干这个的。那么，E &amp;amp; E是不是就解决问题了呢？&lt;/p&gt;

&lt;p&gt;我们先来看看E &amp;amp; E究竟是干什么的。E &amp;amp; E的核心思想&lt;sub&gt;[5]&lt;/sub&gt;是，我们在优化某些目标函数的时候，从一个时间维度来看，当信息不足或者决策不确定性（Uncertainty）很大的时候，我们需要平衡两类决策：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;选择现在可能最佳的方案&lt;/li&gt;
  &lt;li&gt;选择现在不确定的一些方案，但未来可能会有高收益的方案&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在做这两类决策的过程中，我们也逐渐对所有决策的不确定性不断更新不断加以新的认识。于是，&lt;strong&gt;最终&lt;/strong&gt;，从时间的维度上来看，我们在不确定性的干扰下，依然能够去&lt;strong&gt;优化&lt;/strong&gt;目标函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/exploration.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;举个例子，比如一个用户看新闻，如果这个用户只点击娱乐类的新闻，作为推荐系统而言，虽然我们知道下面接着显示娱乐新闻可能是比较不错的选择，但是&lt;strong&gt;完全忽视&lt;/strong&gt;显示其他类别新闻则显得整个系统高估了自己对用户的认知。于是，一个比较现代的推荐系统，往往会兼顾一些其他类别，看看用户是否对其他类别是不是也有兴趣。这就是E &amp;amp; E的典型案例。&lt;/p&gt;

&lt;p&gt;然而，E &amp;amp; E并不能解决我们之前提到的“千篇一律”的问题。原因倒不是说E &amp;amp; E本身可能会有什么问题，原因的核心还是，我们是否&lt;strong&gt;优化用户喜好&lt;/strong&gt;。也就是说，即便有E &amp;amp; E，只要我们的目标函数是用户喜好及其变种，那么，整个系统依然会&lt;strong&gt;收敛&lt;/strong&gt;（Converge）到“满屏相机”的状态。因为，也许用户&lt;em&gt;就是&lt;/em&gt;对相机喜好最大。那系统在Explore了一些其他类别的东西之后，发现用户没有太大兴趣，于是就“安全”得觉得，可以放心现实用户喜欢的类别了。&lt;/p&gt;

&lt;p&gt;也就是说，E &amp;amp; E没有错，错的是我们要优化用户喜好这件事情。或者换句话说，我们如果知道，一个用户真心只喜欢相机，而且在尝试给用户看了各种其他类别以后，系统是不是就以非常大的概率显示相机呢，而基本或者完全忽略其他类型的物品呢？&lt;/p&gt;

&lt;p&gt;另外，E &amp;amp; E在真实产品中应用还有一些实际的难度。很多公司的产品经理并不一定愿意实现这个功能。当然，这是另外一个话题了。&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;复杂的人类行为&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;我们在第一节提到了一点用户行为的不确定性和复杂性（短期行为和长期行为的区别）。这里我们再讨论一下因为复杂的人类行为给推荐系统所带来的麻烦。也就是说，推荐系统目前只能“千篇一律”也部分因为建模水平有限。&lt;/p&gt;

&lt;p&gt;还是以新闻推荐为例子，用户在使用产品的时候，显然是有一些潜在的&lt;em&gt;意图&lt;/em&gt;（Intents）和使用习惯。比如，有一些用户，习惯于阅读所有的排在重要版面的新闻，&lt;strong&gt;不管&lt;/strong&gt;这些新闻是否真的激起用户的兴趣。这类似于搜索问题（Search）中的&lt;em&gt;位置偏见&lt;/em&gt;（Position Bias）——用户以为排在前面的就是重要的，就是需要他们阅读的。盲目认为用户点击了的就是用户喜欢的，往往是导致“越来越富”（Rich-Get-Richer）现象的一个简单原因。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/user_behaviors.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当然，简单尝试去除这种偏见，也需要注意到，的确是有用户是习惯&lt;strong&gt;读完所有重要新闻&lt;/strong&gt;的。也就是说即便是去除偏见，粗看，用户的行为依然杂乱无章，今天看伊朗问题，明天看世界杯，后天看巴西政府丑闻，大后天看Kim Kardashian，貌似喜欢所有的话题和类别。这里的核心问题还是，只对喜好建模，就无法检测到用户的行为在“目的性”这一维度的差异性，于是误判用户喜欢很多类别的事物。这类的例子其实有很多，比如在奥斯卡季，用户看了最新的一批奥斯卡获奖电影，涵盖很多类别，但这并不代表用户真的就喜欢这些类别。&lt;/p&gt;

&lt;p&gt;同样在“意图”上容易误判的是有突发事件的时候，比如四年一度的世界杯（或者其他时间）。很多用户在短期内阅读了大量足球信息，而大多数这类用户都是平时&lt;strong&gt;完全&lt;/strong&gt;对足球没有兴趣的人。这种在短时间内&lt;strong&gt;过度&lt;/strong&gt;对于某一个类别新闻进行信息消费（Content Consumption），会对以喜好为基础的推荐系统造成极大困扰。系统很难&lt;em&gt;忘却&lt;/em&gt;这些用户的行为，或者说系统很难甄别那些该被忘掉。&lt;/p&gt;

&lt;p&gt;要抓住用户的行为，理解用户的意图，那么就对推荐系统的构建提出了更高要求。即便是优化用户喜好，为了评测系统是否能够区分短期、长期喜好和不同的阅读习惯，对数据的采集，系统的评价体系以及最终模型的更新都提出了更高的要求。&lt;/p&gt;

&lt;p&gt;当然，这一节我们是要说明，“千篇一律”问题的复杂性在于，我们需要判断是否是现有模型和系统对于哪怕就是优化用户喜好也没有做好。&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;巧妇难为无米之炊&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;在最终讨论“满屏相机”问题的解决方案之前，我们再来看一个可以很容易侦测到的问题，这也是经常导致一个推荐结果“千篇一律”的罪魁祸首之一。那就是，系统的物品池（Item Pool）太小。换句话说，就是根本没什么东西可以推荐。&lt;/p&gt;

&lt;p&gt;这个问题虽然说起来非常容易理解，但却是很多内容推荐平台（比如新闻推荐、视频推荐）的核心短板，也就是缺乏优质内容。比方说，用户喜欢看科幻文章，但遗憾的是，整个平台也许就只有几篇科幻文章，于是系统没法给用户提供更好的推荐。自然，用户也就只能反复看见剩下的东西在屏幕上占据显著的位置。&lt;/p&gt;

&lt;p&gt;然后这个问题说起来容易，真正要去着手解决却很麻烦。核心难点是，茫茫互联网，到哪里去获取优质内容。这个问题，我们留到以后再来探讨。&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;推荐系统的大视野&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;在卖了一个大关子以后，我们在最后这节讨论一下如何解决“千篇一律”的核心问题，那就是把握住推荐系统的&lt;em&gt;视野&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;推荐系统，或者说任何用户系统，的视野，就是如果把为用户提供服务（这里是推荐物品）作为&lt;strong&gt;一个环节&lt;/strong&gt;，&lt;strong&gt;和其他子系统协同来达到整个产品生态系统&lt;/strong&gt;的&lt;strong&gt;健康&lt;/strong&gt;。这里的核心的核心，是整个产品生态系统的健康。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/system_health.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;什么是推荐系统所在的整个生态系统的健康？以新闻平台来说，这里涉及：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;单个用户是否能够长期活跃，单个用户是否能在这里得到帮助，得到成长&lt;/li&gt;
  &lt;li&gt;用户族群（Community）是否得到保护，是否促进了不同形态的用户群的增长&lt;/li&gt;
  &lt;li&gt;信息提供商是否能够通过平台得到自己的收益（比如，投放的信息获得了广告收益；增加了知名度等）&lt;/li&gt;
  &lt;li&gt;信息提供商的多样性，良性的竞争关系。（比如不是单个信息来源占据了绝大多数的信息来源等）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;还有很多很多。一旦把这些因素考虑进系统，并且加以量化，融合进目标函数（比如，一个简化版的代表作&lt;sub&gt;[6]&lt;/sub&gt;），我们就可以清晰得看到，优化这么一个目标，至少在理论上和实践中，都很难提供“千篇一律”的推荐结果，原因就是那样的结果，会最终流失用户、信息提供商，最终让产品僵化。&lt;/p&gt;

&lt;p&gt;也可以这么说，“千篇一律”的问题核心，简单说来就是，优化目标过于简单，没有把产品的健康考虑进去。&lt;/p&gt;

&lt;p&gt;说到这里，貌似这个问题已经“解决”了，其实不然，原因是，如何定义出一个健康指标，不仅仅是一个技术活儿，甚至是一个艺术活儿，这里就不仅仅是数据科学以及机器学习的范畴了，我们以后再讨论相关话题。&lt;/p&gt;

&lt;h2 id=&quot;section-5&quot;&gt;结论&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;本篇文章讨论了个性化推荐不是伪问题，而是一个非常深的产品问题，我们需要考虑时时刻刻优化产品的全局健康。&lt;/p&gt;

&lt;h2 id=&quot;section-6&quot;&gt;参考文献&lt;/h2&gt;
&lt;hr /&gt;
&lt;ol&gt;
  &lt;li&gt;Deepak Agarwal and Bee-Chung Chen. 2009. &lt;strong&gt;Regression-based latent factor models&lt;/strong&gt;. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, USA, 19-28.&lt;/li&gt;
  &lt;li&gt;Yehuda Koren. 2010. &lt;strong&gt;Factor in the neighbors: Scalable and accurate collaborative filtering&lt;/strong&gt;. ACM Transactions on Knowledge Discovery from Data 4, 1, Article 1 (January 2010), 24 pages.&lt;/li&gt;
  &lt;li&gt;Robert M. Bell and Yehuda Koren. 2007. &lt;strong&gt;Lessons from the Netflix prize challenge&lt;/strong&gt;. ACM SIGKDD Explorations Newsletter - Special Issue on Visual Analytics 9, 2 (December 2007), 75-79.&lt;/li&gt;
  &lt;li&gt;Xing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, and Suju Rajan. 2014. &lt;strong&gt;Beyond clicks: dwell time for personalization&lt;/strong&gt;. In Proceedings of the 8th ACM Conference on Recommender Systems. ACM, New York, NY, USA, 113-120.&lt;/li&gt;
  &lt;li&gt;Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. 2010. &lt;strong&gt;A contextual-bandit approach to personalized news article recommendation&lt;/strong&gt;. In Proceedings of the 19th International Conference on World Wide Web. ACM, New York, NY, USA, 661-670.&lt;/li&gt;
  &lt;li&gt;Deepak Agarwal, Bee-Chung Chen, Pradheep Elango, and Xuanhui Wang. 2011. &lt;strong&gt;Click shaping to optimize multiple objectives&lt;/strong&gt;. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, USA, 132-140.&lt;/li&gt;
  &lt;li&gt;Alexandros Karatzoglou, Linas Baltrunas, and Yue Shi. 2013. &lt;strong&gt;Learning to rank for recommender systems&lt;/strong&gt;. In Proceedings of the 7th ACM Conference on Recommender Systems. ACM, New York, NY, USA, 493-494.&lt;/li&gt;
  &lt;li&gt;Amr Ahmed, Yucheng Low, Mohamed Aly, Vanja Josifovski, and Alexander J. Smola. 2011. &lt;strong&gt;Scalable distributed inference of dynamic user interests for behavioral targeting&lt;/strong&gt;. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, USA, 114-122.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>我为什么开设这个专栏</title>
   <link href="http://column.hongliangjie.com/%E7%AB%99%E5%8A%A1/2016/04/05/start-column/"/>
   <updated>2016-04-05T00:00:00-07:00</updated>
   <id>http://column.hongliangjie.com/%E7%AB%99%E5%8A%A1/2016/04/05/start-column</id>
   <content type="html">&lt;p&gt;经过一段时间的思考，我决定开一个技术、管理和团队的专栏，分享和探讨关于大数据、人工智能（AI）及机器学习（Machine Learning）的话题，以及这些相关技术的行业思考。在已经有不少优质内容（包括博客、微信公众号）的情况下，我希望这个专栏能够更加专注、专业，少一些关注个别技术的细节，多一些对数据在一个生态系统中的把握以及行业动态的分析。&lt;/p&gt;

&lt;p&gt;在接下来的文章中，我准备着重分享和探讨如下这些方面的内容：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;机器学习、人工智能和大数据相关领域的核心技术，如何应用这些核心技术到生产实践中。解析从单一算法到产品流程的距离和取舍（Compromise）。&lt;/li&gt;
  &lt;li&gt;什么是数据驱动(Data-Driven)的团队，如何构建具有核心竞争力的大数据团队。&lt;/li&gt;
  &lt;li&gt;如何设计和开发智能型数据驱动产品，作为产品经理，如何在产品功能和数据驱动之间寻求动态平衡。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;正如前面提及的一样，第一方面已经有不少优秀内容涵盖。这个专栏的特色则是寻求如何在学术圈的最新研究成果（State-of-the-Art）和工业界的标准流程中建立桥梁，在浩如烟海的相关文献中，找到最适合的算法和模型。&lt;/p&gt;

&lt;p&gt;第二和第三方面则是这个专栏重点想提及的部分。那就是如何转变现有的团队建设和产品开发思维，能够从数据驱动的角度，能够从数据工程的角度来看待问题。现代产品为什么失败，其中有一个原因就是没法和数据很好衔接。这里说的衔接，指的是产品功能上的衔接，数据链条的衔接以及产品经理的理念的衔接。这个专栏希望起到抛砖引玉的作用，能够真正引发对于数据产品的思考，推进产品的质量。&lt;/p&gt;

&lt;p&gt;最后，为什么这个专栏叫“期望最大化”，这源自于一个机器学习里有名的算法：Expectation Maximization，不断在现有参数下更新模型对周围的认知然后又不断更新模型的参数，最终能够达到一个局部最优解。这个专栏也希望像这个算法一样，不断提升自己的认识，不求最完美，但求能够促进业界的分享和交流。&lt;/p&gt;
</content>
 </entry>
 

</feed>
