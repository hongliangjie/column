<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>期望最大化（洪亮劼的专栏）</title>
    <description>Etsy数据科学主管、前雅虎研究院高级研发经理，长期从事机器学习、大数据分析、个性化系统架构的研究；这是一个分享技术、管理、团队和业界思考的专栏。</description>
    <link>http://column.hongliangjie.com/</link>
    <atom:link href="http://column.hongliangjie.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 30 Apr 2017 17:47:21 -0400</pubDate>
    <lastBuildDate>Sun, 30 Apr 2017 17:47:21 -0400</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>WWW 2017文章精读（七）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Monetary Discount Strategies for Real-Time Promotion Campaign进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://oak.cs.ucla.edu/~chucheng/publication/www17.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的来自于一批来自台湾国立成功大学的学者和一个叫Slice Technologies的公司。这篇文章要解决的是一个非常实际的在E-Commerce会遇到的问题，那就是如何进行实时的促销（Promotion Campaign）使得可以吸引用户而同时也可以达到利润最大化的目的。&lt;/p&gt;

&lt;p&gt;作者们在这篇文章提出了一个叫做Real-Time Promotion（RTP）的概念，类比于广告里面经常提到的Real-Time Bidding。同时，这个RTP是一个针对某一个特定用户的一次性Deal。也就是说，这里面有了个性化的成分，使得能够对用户有一定的吸引力。然而，这个问题的难点是，如果能够做到在做RTP的同时，不影响到或者尽可能小的影响到用户对于品牌的一个认知，不至于让用户有负面的感觉。&lt;/p&gt;

&lt;p&gt;这篇文章的数据来源于这个叫Slice的公司。具体说来，Slice就是对百万用户的Receipts进行分析，从而对用户进行建模。这里面有一个基本的假设就是，如果一个用户已经以一定的价格（Price）购买了某种商品，那么，比这个价格低的价格，用户也一般愿意接受。而相反，用户可能不会接受比当前这个价格更高的价格。&lt;/p&gt;

&lt;p&gt;首先，作者们定义了这个所谓Discount-Giving Strategy的问题。那就是在给定的Discount预算（Budget）的情况下，如何最大化利润。文章指出，这个问题很类似传统的背包问题（Knapsack）。当然，与背包问题的最大不同的就是在于，这个问题中的很多参数是未知的，比如顾客是否愿意购买，再比如当前的折扣价格。&lt;/p&gt;

&lt;p&gt;在假设知道当前客户购买一个商品的价格分布的情况下，我们是可以得到最大化利润的一个表达的。然而遗憾的是，我们并不知道这个价格分布。于是在这篇文章里，作者们就提出了使用Kernel Density Estimation（KDE）来对价格分布进行估计。而得知了这个分布以后，我们就能够对每一个商品的所谓Cut-off Price进行一个准确的估计。这里的细节建议大家看文章。有了这些组成部分以后，作者们在这篇文章中提出了一个基于Thompson Sampling的办法，这样做的好处是可以对实时变化的数据进行很好的估计，同时也可以让整个优化过程更加Robust。&lt;/p&gt;

&lt;p&gt;实验就是在Slice过去手机的Receipts来进行的Simulation。应该说，实验的结果还是证明了动态的实时优化对于曾家利润是有帮助的。&lt;/p&gt;

&lt;p&gt;这篇文章的具体技术比较繁复，很难看出能够直接在这个基础上再扩展算法。然而这篇文章提出的问题的确比较新颖，也是电商或者网络运营商（比如Uber、DiDi）等经常遇到的问题，所以，值得对相关技术有兴趣的读者泛读。&lt;/p&gt;
</description>
        <pubDate>Sun, 30 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/30/www2017-slice/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/30/www2017-slice/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（六）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Situational Context for Ranking in Personal Search进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1268&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自于University of Massachusetts Amherst（UMASS）以及Google。UMASS因为W. Bruce Croft（Information Retrieval领域的学术权威）的原因 ，一直以来是培养IR学者的重要学校。文章做这种的Michael Bendersky以及Xuanhua Wang都是Bruce Croft过去的学生。这篇文章想要讨论的是如何在个人搜索（Personal Search）这个领域根据用户的场景和情况（Situational Context）来训练有效的排序模型（Ranking Model）。&lt;/p&gt;

&lt;p&gt;这篇文章的核心思想其实非常直观：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;场景信息对于个人搜索来说很重要，比如时间，地点，Device，因此试图采用这些信息到排序算法中，是非常显而易见的。&lt;/li&gt;
  &lt;li&gt;作者们尝试采用Deep Neural Networks来学习Query以及Document之间的Matching。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;具体说来，作者们提出了两个排序模型来解决这两个设计问题。第一个模型应该说是第二个模型的简化版。&lt;/p&gt;

&lt;p&gt;第一个模型是把Query，Context，以及Document当做不同的模块元素，首先对于每一个模块分别学习一个Embedding向量。与之前的一些工作不同的是，这个Embedding不是事先学习好的（Pre-Trained）而是通过数据End-to-End学习出来的。有了各个模块的Embedding向量，作者们做了这么一个特殊的处理，那就是对于不同的Context（比如，时间、地点）学习到的Embedding，在最后进入Matching之前，不同Context的Embedding又组合成为一个统一的Context Embedding（这里的目的是学习到例如对时间、地点这组信息的统一规律），然后这个最终的Context Embedding和Query的，以及Document的Embedding，这三个模块进行Matching产生Relevance Score。&lt;/p&gt;

&lt;p&gt;那么，第二个模型是建立在第一个模型的基础上的。思路就是把最近的一个所谓叫Wide and Deep Neural Networks（Wide and Deep）的工作给延展到了这里。Wide and Deep的具体思想很简单。那就是说，一些Google的研究人员发现，单靠简单的DNN并不能很好的学习到过去的一些非常具体的经验。原因当然是DNN的主要优势和目的就是学习数据的抽象表达，而因为中间的Hidden Layer的原因，对于具体的一些Feature也好无法“记忆”。而在有一些应用中，能够完整记忆一些具体的Feature是非常有必要的。于是Wide and Deep其实就是把一个Logistic Regression和DNN硬拼凑在一起，用Logistic Regression的部分达到记忆具体数据，而用DNN的部分来进行抽象学习。这第二个模型也就采用了这个思路。在第一个模型之上，第二个模型直接把不同Context信息又和已经学到的各种Embedding放在一起，成为了最后产生Relevance Score的一部分。这样的话，在一些场景下出现的结果，就被这个线性模型部分给记忆住了。&lt;/p&gt;

&lt;p&gt;在实验的部分来说，文章当然是采用了Google的个人搜索实验数据，因此数据部分是没有公开的。从实验效果上来说，文章主要是比较了单纯的用CTR作为Feature，进行记忆的简单模型。总体说来，这篇文章提出的模型都能够对Baseline提出不小的提升，特别是第二个模型仍然能够对第一个模型有一个小部分但具有意义的提升。&lt;/p&gt;

&lt;p&gt;这篇文章对于研究如何用深度学习来做文档查询或者搜索的研究者和实践者而言，有不小的借鉴意义，值得精读。&lt;/p&gt;
</description>
        <pubDate>Fri, 28 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/28/www2017-personal-search/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/28/www2017-personal-search/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（五）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Streaming Recommender Systems进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.yichang-cs.com/yahoo/WWW17_StreamingRec.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自雅虎研究院和University of Illinois at Urbana-Champaign。第一作者&lt;a href=&quot;http://www.ifp.illinois.edu/~chang87&quot;&gt;Shiyu Chang&lt;/a&gt;，是今年来一位学术新星，目前在IBM华生研究院工作。这篇文章的核心思想是想提出一个完全基于流（Stream）信息的推荐系统框架。&lt;/p&gt;

&lt;p&gt;作者们认为，流信息和普通的静态数据有很大的区别：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;大量的数据流入系统，系统必须对这些数据进行实时的反应。比如用户和某一个物品进行了交互；比如有新的物品产生需要被系统识别到并且能够查询等等。&lt;/li&gt;
  &lt;li&gt;流入系统的数据的量是未知的。这部分信息无法在产生系统之前拿到。&lt;/li&gt;
  &lt;li&gt;随着时间的推移，数据会产生所谓的“概念漂移”（Concept Shift）的现象。用户的喜好也会随着时间的推移而发生变化。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;于是，这篇文章就是希望从根本上来解决这些问题，提出一个基于信息流的推荐系统框架。&lt;/p&gt;

&lt;p&gt;文章提出的模型是一个具有时间信息的概率图模型（Probabilistic Graphical Model）。核心思想就是所有的元素都有时间的概念。举例来说，用户对于某一个物品的喜爱也仅仅是一个时间点的信息，并不代表之后的时间点的信息。这一点来说，就给了用户喜好发生变化的可能性。模型的核心还是基于用户向量（User Vector）和物品向量（Item Vector）的点积。不过，这里的用户向量和物品向量都是某一个时间点的估计。这些向量都随着时间发生变化。具体说来，作者们定义了一个基于布朗随机运动（Brownian Motion）的变化过程来对用户向量随着时间变化的改变来建模。也就是说，下一个时间点的用户向量是一个基于上一个时间点的用户向量的高斯分布。同样的建模手段也用到了物品向量上。整个模型可以说还是比较直观的，从概念上来说，提出的这个框架其实非常类似用卡曼滤波（Kalman Filtering）来进行时间维度的建模。而用卡曼滤波建模也是过去在概率图模型里经常使用的技巧。&lt;/p&gt;

&lt;p&gt;这个模型的难点是做模型的在线预测（Online Prediction）和离线模型参数估计（Offline Parameter Estimation）。对于在线预测的部分，作者们提出了一个叫Recursive Mean-field Approximation的技术。对于离线模型参数估计来说，作者们使用了标准的EM算法。总体来说，整个学习流程其实是比较复杂的。这也和其他使用类似卡曼滤波的方法类似。这也是概率图模型对时间信息处理的通病。&lt;/p&gt;

&lt;p&gt;文章实验的部分还是非常详尽的。文章在MovieLens的比较小的以及比较大的数据集上都做了实验，并且还加上了经典的Netflix的数据集。从Baseline的比较上来说，文章比较了传统的Probabilistic Matrix Factorization，经典的Time-SVD++算法（赢得Netflix大赛的算法）以及比较先进的Gaussian Process Factorization Machines。从实验的效果上来看，文章提出的方法在三个数据集上都有不错的效果。&lt;/p&gt;

&lt;p&gt;这篇文章提出的方法因为其算法复杂性，很难应用在生产中。而且要想在这个模型上做进一步的扩展，只能使得算法的复杂性进一步提升。这篇文章适合对于推荐系统有研究的学者和实践者泛读。&lt;/p&gt;
</description>
        <pubDate>Thu, 27 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/27/www2017-stream/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/27/www2017-stream/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（四）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Modeling Consumer Preferences and Price Sensitivities from Large-Scale Grocery Shopping Transaction Logs进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cseweb.ucsd.edu/~m5wan/paper/www17_mwan.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自加州大学圣地亚哥分校（University of California at San Diego）和微软研究院。最后一个作者Julian McAuley在加州大学圣地亚哥分校长期从事推荐系统以及用户模型的研究工作。建议对推荐系统有研究的朋友经常看看他又有什么新的研究成果这篇文章的特色在于希望把推荐系统的用户喜好建模和经济学里的对于价格的研究结合起来。作者们认为，在推荐系统领域，对于用户喜好建模已经是比较成熟的研究领域了，而对于价格，特别是价格的敏感度（Sensitivity）的研究还并不是很多。于是这篇文章就是要弥补这么一个研究缺失（Gap）。&lt;/p&gt;

&lt;p&gt;作者们首先提出了一个分三阶段（Three Stage）的概率模型，用来刻画用户选择购买商品时候的选择过程。具体来说，这篇文章把用户的行为分为了这么三个阶段：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;类别选择（Category Purchase），也就是说，用户首先选择要购买哪个类别的商品。&lt;/li&gt;
  &lt;li&gt;产品选择（Product Choice），这里面就是在已经选定了一个类别以后，用户如何在这个类别里面选择商品。&lt;/li&gt;
  &lt;li&gt;数量购买（Purchase Quantity），选择要购买多少商品。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有了这三个阶段以后，用户的购买需求就成为了这三种概率的联合分布。&lt;/p&gt;

&lt;p&gt;为了对这三种行为有效建模，作者们首先提出了一个所谓的Feature-Based Matrix Factorization（FMF）的框架。总的说来，这是之前的LinkedIn提出的所谓的Generalized Linear Mixed Model（GLMix）变种。读者可以仔细参考原论文看看FMF的细节。这个FMF结合了全局特征（Global Features），物品特征，用户特征，以及用户和物品的隐含特征（Latent Features）。可以说是一个比较完善的框架体系。&lt;/p&gt;

&lt;p&gt;有了FMF这个工具，我们再回到刚才的三个阶段的建模。作者们的思路就是用FMF的不同表达形式为三个阶段进行分别的建模。具体说来，类别选择的部分，采用了FMF的Logistic表达形式，也就是对每个类别进行简单的“是”还是“不是”的购买选择。产品选择的部分则采用了Multinomial Regression的形式，也就是在所有同类商品里面进行选择。第三部分数量购买则采用了Poisson Regression的形式。然而核心这三部分采用的是同样的一套思路。因为这三个部分的独立性，使得模型的学习可以把这三部分分来，有利于能够并行化。在整体的模型学习上，作者们还加上了AUC Optimization的“作料”。&lt;/p&gt;

&lt;p&gt;接下来，作者们介绍了这篇文章的一个重点，那就是把价格因素引入到了整体框架中。其实思路还是很简单，就是直接把价格（在模型中用了Log Transformation）当做一个Feature，进行参数学习。这样做的好处还有直接可以计算所谓的价格敏感度，也就是购买一个东西的可能性的变化和价格变化的比值。这个数量可以用来描述价格的变化敏感度，可以让我们对价格做进一步的分析。&lt;/p&gt;

&lt;p&gt;作者们在一个非公开的西雅图的商店数据集上，和公开的Dunnhumby数据集上做了实验。实验结果是三个阶段的模型都有不错的表现。并且作者们还利用价格敏感度进行了数据的进一步分析。这里就不复述了。&lt;/p&gt;

&lt;p&gt;这篇文章值得对推荐系统有研究的学者和实践者精读。&lt;/p&gt;
</description>
        <pubDate>Wed, 26 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/26/www2017-ec/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/26/www2017-ec/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（三）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Usage Patterns and the Economics of the Public Cloud进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://vita.mcafee.cc/PDF/EconPublicCloud.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自微软研究院和Uber。作者之一的R. Preston McAfee是著名的经济学家，曾在雅虎担任副总裁和首席经济学家，2012年以后到Google的Strategic Technology担任总监，2014年之后到微软担任首席经济学家。这篇文章是探讨现在第三方云计算平台（比如Amazon的AWS或是微软的Azure）是否能采用动态价格（Dynamic Pricing）的计价模式，特别是在所谓的“巅峰负载”（Peak-Load）的时候。&lt;/p&gt;

&lt;p&gt;首先，这篇文章对“云服务”模式进行了一个简单的介绍。这部分内容还是有很强的科普意义。这里面有一点可能比较容易忽视的科普点是，客户公司（Firm）需要对服务和软件进行重写才能使用云服务商提供的Auto-Scaling等方便的服务。如果客户公司仅仅是简单得把运行在传统数据中心上的服务给部署到云服务商的设施上面的话，则很难能够真正利用云服务的“易伸缩性”（Elastic）。&lt;/p&gt;

&lt;p&gt;紧接着，作者们对于其他工业怎么采用动态价格进行了简单的介绍。动态价格有两个条件，那就是Capacity在短期内是恒定的（Fixed）并且恒定的一部分陈本（Cost）是总成本不小的一部分。当然这都是对于服务商而言。目前我们对于动态价格的主要认识，来源于电力、航空和酒店这些行业。云服务如果按照刚才那个条件来说，是具备动态价格的一些先决条件的。因此，作者们认为应该对云服务的供需进行研究来看如何设计动态价格的策略，也就是说，作者们想看一看现在的云服务的使用率是不是不够优化，为动态服务提供了可操作的空间。&lt;/p&gt;

&lt;p&gt;这篇文章能够被WWW录取的一个重要原因可能是因为结果比较出人意料。作者们通过对微软的云服务数据（虽然在文中没有明说）进行分析得出，当前的云服务使用率（主要是从VM这个角度来说）的差别度（Variation） ，不管是看单个客户还是整体数据中心这个级别，都在5%以下。意思就是说，从云服务商这个整体来说，并没有出现特别大的服务需求起落。作者们的确从单个客户的数据中看到了使用率的震荡（Fluctuation），但是在云服务商这个层级，这样的震荡随着不同的客户数据，从而达到了整体“抵消”（Average Out）的效果。&lt;/p&gt;

&lt;p&gt;作者们认为这样的现实数据为现在的计费模型，也就是恒定的价格（Static Price）提供了一定的基础。同时，目前的可以预测的使用率也为服务商充分利用资源提供了保证。这一点与电力系统不同，电力系统为在巅峰时刻的用电一般必须调用额外的设备。当然，作者们也认为这样的使用数据，以及计费模型，是现在多数客户都简单把原来的软件系统给搬运到云计算平台上，而并没有充分利用云服务的Auto-Scaling有关系。&lt;/p&gt;

&lt;p&gt;为了对以后的可能性进行探索，作者们又从CPU的使用率这个级别进行分析。与VM的使用率不同的是，CPU的使用率看出了比较大的幅度。平均的最高CPU使用率比巅峰时期CPU使用率要小40%左右。因此，如果服务商能够通过CPU使用率来进行计价，或者VM资源能够在不使用的时候自动关闭，则为动态价格提供了一种可能性。作者们的与测试，这可能是未来的一种模式。&lt;/p&gt;

&lt;p&gt;总体来说，这篇文章算是科普性质的一篇文章。对于动态价格，以及云服务商的计价模式有兴趣的读者可以泛读本文。&lt;/p&gt;
</description>
        <pubDate>Wed, 19 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/19/www2017-cloud/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/19/www2017-cloud/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（二）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Collaborative Metric Learning进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cs.cornell.edu/~ylongqi/paper/HsiehYCLBE17.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cs.cornell.edu/~ylongqi/publication/www17b/&quot;&gt;论文的项目页面&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自于加州大学洛杉矶分校（University of California at Los Angeles）以及康奈尔科技大学（Cornell Tech）。 文章的核心思想是如何把Metric Learning和Collaborative Filtering（CF）结合起来从而达到更好的推荐效果。&lt;/p&gt;

&lt;p&gt;那么这篇文章为什么会想到把Metric Learning结合到CF上面呢？文章做了比较详细的交代。这里面的重点来自于传统的基于Matrix Factorization的CF模型都使用了Dot-Product来衡量用户向量（User Vector）和物品向量（Item Vector）的距离。也就是说，如果Dot-Product的值大， 就代表两个向量相近，值小就代表距离远。对于Dot-Product的默认使用已经让广大研究人员和实践者都没有怎么去质疑过其合理性。文章这里指出，Dot-Product并不是一个合理的距离测度，因此可能会带来对于相似度的学习不准确的问题。&lt;/p&gt;

&lt;p&gt;这里简单说一下什么是一个合理的距离测度。一个距离测度需要满足一些条件，而其中比较普遍的条件是所谓的“三角不等式”。所谓的“三角不等式”关系其实也就是说，距离的大小是有传递性的。举例来说，就是如果X与Y和Z都相近，那么Y和Z也应该相近。也就是说，相似度是可以传播的，在使用一个合理的距离测度的情况下。然而，文章指出Dot-Product并不具备这样的相似传递性，因此在实践中常常会不能有效得学习到数据中全部的信息。&lt;/p&gt;

&lt;p&gt;Metric Learning就是如何在一定的假设下，进行有效距离测度学习的工具。文章使用了一种Relaxed Version的Metric Learning，叫做Large-Margin Nearest Neighbor（LMNN）来学习数据之间的相似度。LMNN简单说来，就是同一个类型的数据应该更加紧密聚集在一起（通过Euclidean Distance），而不同类的数据应该远离。同时，同类的数据和不同类的数据之间保持一个Margin（模型的一个参数）的安全距离。&lt;/p&gt;

&lt;p&gt;作者们把这个概念拿过来，应用在CF的场景下，做了进一步的简化，那就是把“相同类数据聚合”这个部分去掉了，仅仅留下了“不同类远离”这个部分。作者们认为，一个物品可能被多个人喜欢，那么在这样的含义下，很难说清楚，到底怎么聚类比较有意义。具体说来，一个用户所喜欢的物品要远离这个用户所不喜欢的物品，同时这个距离会被一个与Rank（这里所说的Rank是指物品的排序）有关Weight所控制。也就是Rank越大，所产生的Penalty就越大。文章具体采用了一个叫Weighted Approximate Rank Pairwise Loss（WARP）的Loss来对Rank进行Penalty。这个WARP是早几年的时候还在Google的Weston等人提出的，目的是要对排在Rank比较大的正样本（Positive Instance）做比较大的Penalty。这里就不复述WARP的细节了。&lt;/p&gt;

&lt;p&gt;除了外加WARP的Metric learning，这篇文章还为整个模型的目标函数加了不少“作料”。“作料一”就是使用了Deep Learning来学习从物品的Feature到物品的Latent Vector的映射。这解决了Cold-start的问题。“作料二”则是对物品和用户的Latent Vector都做了正则化，使得学习起来更加Robust。&lt;/p&gt;

&lt;p&gt;文章简单描述了一下整个模型的训练过程。整个模型的目标函数由三个部分组成：Metric Learning的部分，加Deep Learning的部分，外加正则化的部分。比较意外的是，文章并没有提及模型在训练好以后如何在Test数据上进行Inference。&lt;/p&gt;

&lt;p&gt;文章在一系列标准数据集上做了测试，对比的Baseline也比较完整。总体说来，提出的模型都能达到最好的效果，有些在目前比较好的模型基础上能够提高10%以上，这比较令人吃惊。比较遗憾的是，文章并没有很好的展示这个模型的三个模块究竟是不是都必须。值得一提的是，文章指出使用了WARP的任何模型（包括本文章提出的模型）都要好于其他的模型。&lt;/p&gt;

&lt;p&gt;这篇文章总的来说还是可以参考。虽然有一些细节很值得推敲，但是，提出把Metric Learning引入到CF里来说，还是有一定价值的。&lt;/p&gt;

&lt;p&gt;建议对推荐系统正在研究的学者精读，对推荐系统有兴趣的实践者泛读。&lt;/p&gt;
</description>
        <pubDate>Sun, 16 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/16/www2017-cml/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/16/www2017-cml/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（一）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Beyond Globally Optimal: Focused Learning for Improved Recommendations进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://alexbeutel.com/papers/www2017_focused_learning.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章来自一群前CMU的学者，目前在Google和Pinterest。那么这篇文章试图解决什么问题呢？具体说来，就是作者们发现，传统的推荐系统，基于优化一个全局的目标函数，通常情况下往往只能给出一个非常有“偏差”（Skewed）的预测分布。也就是说，传统的推荐系统追求的是平均表现情况，在很多情况下的预测其实是十分不准确的。这个情况在评价指标是Root Mean Squared Error（RMSE）的时候，就显得尤为明显。&lt;/p&gt;

&lt;p&gt;这篇文章的作者是这么定义了一个叫做Focused Learning的问题，那就是如果让模型在一个局部的数据上能够表现出色。那么，为什么需要模型在一个局部的数据上表现出色呢？作者们做了这么一件事情，那就是对每个用户，以及每一个物品的预测误差（Error）进行了分析统计，发现有不小比例的用户的预测误差比较大，也有不小比例的物品的预测误差比较大。作者们发现模型在一些数据上存在着系统性的误差较大的问题，而不是偶然发生的情况。&lt;/p&gt;

&lt;p&gt;作者们又从理论上进行了对这个问题一番讨论。这里的讨论十分巧妙，大概的思路就是，假定现在在全局最优的情况下，模型的参数的梯度已经为0了，但模型的Loss依然不为0（这种情况很常见）。那么，就一定存在部分数据的参数梯度不为0，因为某一部分数据的Loss不为0。这也就证明了部分数据的模型参数在这些数据上的表现一定不是最优的。值得注意的是，这个证明非常普遍，和具体的模型是什么类型没有关系。&lt;/p&gt;

&lt;p&gt;在有了这么一番讨论之后，那么作者们如何解决这个问题呢？这篇文章走了Hyper-parameter Optimization的道路。文章展示了这在普通的Matrix Factorization里面是如何做到。具体说来，就是对于某个Focused Set做Hyper-parameter的调优，使得当前的Hyper-parameter能够在Focused Set上能够有最好表现。而这组参数自然是针对不同的Focused Set有不同的选择。文章提到的另外一个思路，则是对Focused Set以及非Focused Set的Hyper-parameter进行区分对待，这样有助于最后的模型能够有一个比较Flexible的表达。&lt;/p&gt;

&lt;p&gt;文章在实验的部分针对几种不同的Focused Set进行了比较实验。比如，针对Cold-Start的物品，针对Outlier的物品，以及更加复杂的libFM模型都进行了实验。我们在这里就不去复述了。总体来说，Focused Learning在不同的数据集上都得到了比较好的提升效果。同时，作者们还针对为什么Focused Learning能够Work进行了一番探讨，总体看来，Focused Learning既照顾了Global的信息，同时又通过附加的Hyper-parameter调优对某一个局部的数据进行优化，所以往往好于Global的模型以及也好于单独的Local模型。&lt;/p&gt;

&lt;p&gt;本文非常适合对推荐系统有兴趣的学者和工程人员精读。&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/13/www2017-beyond-globally-optimal/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/13/www2017-beyond-globally-optimal/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>论互联网公司与研究院</title>
        <description>&lt;p&gt;随着吴恩达离开百度研究院，关于互联网公司设立研究院的话题又被推到了风口浪尖。一时间，大家对互联网公司到底该不该设立研究院、研究院在公司内部又该起到怎样的作用、怎么能够设置一个有效的研究院架构、怎么来衡量研究院是否成功等问题展开了激烈的讨论。我打算在这篇专栏文章里，以本人在雅虎研究院的经历为基础，来剖析一下现代高科技企业尤其是互联网公司如何设置一个成功的研究院，研究院究竟该如何运作。这篇文章是在公开领域少有的论述研究院的系统性文章，值得大家精读。&lt;/p&gt;

&lt;h2 id=&quot;什么是研究院&quot;&gt;什么是研究院&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/andrew_ng.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在我们讨论其他话题之前，我们首先来看看目前互联网公司的各种研究院有什么特征。怎样的团队就算是一个“研究院类型”的团队（因为有一些公司并不直接单独称这些团队为“研究院”）。我们这里总结下面这么一些特征:&lt;/p&gt;

&lt;h3 id=&quot;特征一以博士为核心组成的团队&quot;&gt;特征一：以博士为核心组成的团队&lt;/h3&gt;
&lt;p&gt;大多数研究院的核心人员，甚至是全部研发人员都具有博士或以上（含博士后、有教职经验）研究经历。这个特征是因为很多研究院需要解决的问题或者研究的方向是产业的前沿，的确需要有掌握高级知识的人才进行研发工作。然而这个特征也直接导致了很多其他问题，那就是一个以博士为核心组成的团队和其他团队来比较，有一些其他团队所不具备的特点，为管理工作带来了额外的挑战。比如，很多博士习惯做长期项目（三个月以上甚至更长）。这些研发人员很不习惯更换项目，而且博士对于项目就像是研究课题，有个人的归属感和荣誉观，这是好事也是坏事。再比如，博士希望有比较长期的职业规划，对于自己的研究方向希望能够有所延续，能够参加学术会议，能够发表论文。这些需求都是其他一般的研发团队一般不具有的。如果一个研究院的管理层不能正视这些需求，则很难形成一个有很强创新力和执行力的团队。&lt;/p&gt;

&lt;h3 id=&quot;特征二相对比较独立的运作环境&quot;&gt;特征二：相对比较独立的运作环境&lt;/h3&gt;
&lt;p&gt;尽管我们后面要提到，很多研究院都和产品部门有或多或少的联系，有时候甚至和产品部门有密切的合作，但绝大多数研究院，都需要有一个相对比较独立的运作环境。比如，研究院是一个独立的团队，有自己部门的领导（而不是工程部门的兼任），有自己部门的单独预算，有自己部门的Key Performance Indicator（KPI)，有自己部门的组织结构和运作模式等等。这些都是建立一个研究院独立的形象。而且，也由于我们刚才提到的第一个特征，也就是研究院以博士为核心的特点，一个相对独立的运作环境有助于管理这一个可能和公司其他部门组成结构非常不一样的人群（因为这个人群的需求可能很不一样）。&lt;/p&gt;

&lt;h3 id=&quot;特征三研究院不是产品部门&quot;&gt;特征三：研究院不是产品部门&lt;/h3&gt;
&lt;p&gt;绝大多数研究院作为一个独立的运行实体都不直接掌管（Ownership）产品线。研究院可以作为产品部门的协作单位，但大多数成熟的研究院均不直接运作产品线。一个简单的原因是，产品线的研发和运作与研究院的目标是不完全一致的。那么这一点特征，可能会带来研究院在管理和定位上出现问题。我们下面会提到研究院的目标中就要来分析一下，在不掌管产品线的情况下，研究院如何能够保持其在公司内的影响力。&lt;/p&gt;

&lt;p&gt;上面三个特征只是研究院诸多特征中的代表。然而我们已经可以看出，研究院在现代互联网公司中的一个比较特殊的地位：人员构成、运作模式、需要为产品做贡献但又不是产品部门。正是因为有这些特点，成功运行一个研究院对于现代高科技企业来说，是一个巨大的管理挑战。&lt;/p&gt;

&lt;h2 id=&quot;研究院的目标&quot;&gt;研究院的目标&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/moonshot.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;什么样的公司需要研究院呢？要回答这个问题，我们必须要来看，什么样的产品需要研究院的支持。有两类产品很适合搭配研究院：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;比较成熟的产品&lt;/li&gt;
  &lt;li&gt;和公司现在产品线没有太大关系的前沿产品，有时候也叫“打月亮”（Moonshot）产品。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们先来说说为什么“比较成熟的产品”适合搭配研究院。成熟的产品，已经有了比较成熟的数据链条（Data Pipeline)，能够使得基于数据（Data-Driven)的研究工作有了可能性。而目前几乎所有的前沿研究，包括机器学习（Machine Learning)、人工智能（Artificial Intelligence）、数据科学（Data Science）等都无一例外非常强烈依赖于大量的数据。没有数据，绝大多数这类研究都没法进行。早期的产品并不具备这样的条件。比如，产品部门需要推出一款新的手机应用（App），而如何这个应用有比较多的功能之前并没有在公司其他产品中存在过，那么研究部门很难进行基于数据的研究工作。成熟的产品，也有相对比较成熟的衡量指标（Metrics）。这一点对于数据驱动的研究来说额外重要。因为有了衡量指标，就能够围绕这个指标展开特定的研究工作，设计相应的模型和算法，提出合理的优化解决方案。比如，当前的产品是搜索引擎，那么研究院就可以针对搜索引擎的成功衡量指标进行建模，更新搜索排序算法等等。早期的产品一般也没有固定、和合理的衡量指标，这会让大多数的研究工作一筹莫展。当然，研究院可以帮助产品部门建立衡量指标。不过这也是一个需要一定时间的过程。在这个过程结束前，其他的研究工作很难进行。&lt;/p&gt;

&lt;p&gt;我们再来说说为什么和现有产品线没有太大关系的前沿产品也是比较适合搭配研究院的原因。我们刚才提到研究院的特点的时候说到，绝大多数研究院都是相对比较独立运行的团队或者机构。这个特点就非常利于研发前沿产品。前沿产品因为其高失败率的特点并不适合普通的已经有成熟产品运维压力的产品部门进行研发。同时，前沿产品的“前沿”特点也使得研究院成为这种类型产品研发当仍不让的选择。另外，前沿产品一般并没有一个特定的产品公布时间表。这和前面所说的“非成熟”或者早期产品不一样。早期产品，尽管没有数据，没有成功指标，但往往有惊人的产品公布时间表，产品上线压力很大。而前沿产品，虽然也没有数据，也没有成功指标，但一般没有上线压力。这也就给了研究院自由空间去收集数据（比如Google的无人驾驶车），定义成功指标，进行迭代。当然，从这个角度来看，这也直接导致了，前沿产品的研发周期非常长，而且也很难去定义其上线的时间，于是成为其失败率高的部分原因。&lt;/p&gt;

&lt;p&gt;在我们了解了什么样的产品比较容易搭配研究院以后，我们再回到最开始的那个问题，“什么样的公司需要研究院”。如果一个公司的产品线相对还不稳定，很多产品处于快速迭代的状态下，这个时候，这样的公司其实并不太适合建立研究院。因为绝大多数产品线都没法真正“享受”到研究院的成果。如果一个公司并没有足够稳定的内部环境和财务基础，那么这个公司也就没有研发前沿产品的基础。那自然这样的情况下，配置一个以研发前沿产品为导向的研究院就更加显得没有必要。基于这样两个原因，绝对多数的初创公司，或者其实说，在上市前的初创公司都并不真正具备配置研究院的内外部环境。只有相对比较稳定的公司才有对研究院真正的需求。&lt;/p&gt;

&lt;p&gt;值得注意的是，我们也可以从这里关于研究院和产品线的讨论引申得到这么一个结论。因为研究院最大的功效是在对成熟产品的优化和改进上，以及对前沿产品的研发上，要想依赖研究院对一个公司的商业模式进行创新，或者寄希望研究院对快速迭代的产品产生贡献使得公司进入高速增长期都是不可能完成的任务。这些不切合实际的初衷往往给研究院的定位和发展带来困境。从另一个角度来说，那就是研究院可能对公司的长期商业运行可能会有比较大的影响（比如一些前沿产品如何研发成功），但在中短期来看，影响是相对比较有限的、是渐进式（Incremental）的（主要来自于对成熟产品的优化）。&lt;/p&gt;

&lt;h2 id=&quot;研究院的架构和运行&quot;&gt;研究院的架构和运行&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/research_lab.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在我们了解了什么样的产品需要研究院，什么样的公司需要配备研究院以后，我们现在就来探讨一下研究院的架构问题。&lt;/p&gt;

&lt;p&gt;我们上面提到了研究院在公司内部需要有一定的独立性。但是，现代高科技公司，毕竟从根本上来说还是追逐利润的企业，如何来确保研究院能够从长期上是符合公司发展的利益呢？这一点，是研究院生存的根本。&lt;/p&gt;

&lt;p&gt;从历史上来说，早期研究院很多都是这么一种运作模式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;研究院的科学家针对某个技术难题（这个技术难题有可能是来自产品工程部门，也有可能是研究院的科学家自己发现）找到了一种解决方案， 形成一个研究成果。&lt;/li&gt;
  &lt;li&gt;根据不同的研究院的情况，科学家可能会选择发表研究成果，形成论文，或者是申请形成专利。&lt;/li&gt;
  &lt;li&gt;科学家根据这个研究成果做出一个解决方案的原型（Prototype）。&lt;/li&gt;
  &lt;li&gt;研究院团队根据解决方案的原型，到产品工程部门进行游说。产品工程部门根据自身的需求和产品周期，决定是否要把目前的原型重新在工程中实现，从而在下一代产品中使用上这个新成果。&lt;/li&gt;
  &lt;li&gt;产品工程团队和科学家一起把原型在工程代码中重新实现。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这个模式看似有一定道理，但也存在一些非常关键的问题。&lt;/p&gt;

&lt;p&gt;首先，第（1）步中就直接存在可能导致第（4）和第（5）没法发生的诱因。我们假设研究院的科学家拿到的技术难题是来自产品工程部门的。从现代产品的角度来说，一般的产品工程迭代都非常快。现在的技术难题可能几个星期后就有了能够解决80%问题的解决方案。也就是说，研究院拿到的技术难题有可能是有时效性的。这并不代表这些技术难题随着时间都有可能被解决，而是说，随着时间进程，很多技术难题可以出现多种解决方案。科学家能够找到的比较完美的解决方案（姑且假设能够100%解决问题）需要（2）-（5）这些步骤进入产品，这必然导致产品部门必须在科学家方案推出之前找到可以运行但很粗犷的方案。然而这种方案一旦进入产品，就会成为日后科学家的完美方案进驻的强大阻力。因为产品工程部门会觉得，在产品已经进一步迭代的情况下，是不是有精力和时间去改进一个已经可以运行的方案为更加完美的方案，其实是一个很棘手的问题。这也就会导致步骤（4）常常非常政治化（Political），成为各个团队扯皮的重要原因。刚才说的，还只是假设研究院的科学家拿到的技术难题是来自产品部门的，还有很多情况是，科学家或者研究院自身认为某些技术难题需要得到解决。这样发展出来的研究成果或者产品原型往往就更加难以通过第（4）和第（5）步得到产品化。&lt;/p&gt;

&lt;p&gt;因为第（4）和第（5）步的不确定性，很多研究院在发展过程中，往往把第（2）和第（3）步作为绩效评定的重要结果。这也就导致了很多研究院的成果只能完成第（1）步到第（3）步这个流程。而第（4）步成为了研究院成果产品化的不可逾越的鸿沟。&lt;/p&gt;

&lt;p&gt;那么如何运作研究院能够跨过这个鸿沟呢？雅虎研究院在过去10年的时间里对这个问题有着不错的实践经验。这里的核心问题就是如何把研究院的目标和一般产品工程团队的目标统一起来，使得大家对于产品的开发和运作是同步的。我们这里要提到这么一个概念，那就是“共享目标”。什么意思呢？那就是研究院和产品工程团队虽然从行政上隶属不同的部门，但在项目开发上，两个团队必须组成一个“虚拟团队”，有统一的领导和统一的进程管理，并且执行统一的、共享的目标。研究院和产品工程团队只是在这么一个共享的、统一的目标下分工不一样，责任不同而已。&lt;/p&gt;

&lt;p&gt;具体说来，以笔者参与过的雅虎首页推荐系统为例。产品工程团队每个季度都会和研究院的研究团队一起指定目标。这个目标是一个 综合性目标，有产品的部分（比如提高多少用户访问、提高多少用户点击），有纯工程的部分（比如如何加快代码部署），有研究的部分（比如应该采用什么模型来达到用户访问的提高、比如应该怎么加快模型的训练速度）。那么，“虚拟团队”就会根据这个综合性的目标来分配资源，确保整个团队的工作量和各个方面的目标达到一个不错的平衡。目标共享以后，研究院的研究周期得到了明确，也就是每个季度。同时，研究院的“成果落地”得到了保证，那就是直接和产品对接，每一个季度都需要“上线”。这种模式下的研究院团队，也不会去做“天马行空”的项目，而是仅仅围绕产品工程，做很多“增量式”的创新工作。&lt;/p&gt;

&lt;p&gt;“共享目标”对于雅虎的很多产品决策过程以及运作过程产生了深远的影响。首先，那就是采用“共享目标”架构的产品全责更加清晰，工程负责什么，研究院负责什么，设计师负责什么，每个季度这几个方面一目了然。另一个非常显著的改变，那就是这些产品第一次把AI（这也就是研究院往往负责的部分）、工程以及设计三个方面作为一个产品每个季度推进的三个主要方面。也就是让AI成为了产品的目标的一类公民。&lt;/p&gt;

&lt;p&gt;那么，“共享目标”是不是就解决了研究院的运作问题了呢？答案是，不完全是。首先，“共享目标”听上去容易，但在实际运作中难度其实还是很大。这里面最重要的是信任问题。从公司结构上来说，产品工程团队往往对产品有“所有权”（Ownership），自然希望能够对产品的方方面面有所把握。然而在“共享目标”的框架下，实质上发生的则是，研究院对于产品的部分方面有了一定的决策权和执行权，这势必需要产品工程团队的领导和人员对于这方面有足够的认识和预期。实际上，从另外一种角度来说，这种“共享目标”其实就是产品工程部门把部分产品开发方面长期外包给了研究院的团队。雅虎的产品工程团队能够和研究院针对某些产品这么做，是因为研究院长期以来能够对这些产品持续做出不俗的贡献，赢得了信任。但并不是所有的产品都能够在这样的框架下运作。&lt;/p&gt;

&lt;p&gt;同时，因为和产品工程达成“共享目标”，这势必也就造成了研究院的研究目标和成果相对比较“短视化”，常常迎合了产品周期。这也就呼应了我们之前提到的，比较适应研究院的一类产品，那就是成熟产品。实际上，“共享目标”的模式很好的契合了成熟产品的迭代。&lt;/p&gt;

&lt;p&gt;对于前沿产品来说，这样的架构显然不太适用。因为这个时候产品和工程组可能都还不存在。对于这样的项目来说，最好以研究院的科学家为核心，然后辅以工程师作为支持。从某种意义上来说，这依然是一种“共享目标”，不过则是之前谈到的相反的结构。&lt;/p&gt;

&lt;h2 id=&quot;研究院的成功&quot;&gt;研究院的成功&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/research_leaders.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;之前已经讨论了研究院的架构和运作，那么，我们怎么能够保证研究院的成功呢？我们这里谈两个比较显著的问题。&lt;/p&gt;

&lt;p&gt;第一个方面那就是研究院需要怎么样的领导。这个问题看似很简单，其实需要相当认真的思考。因为研究院需要负责招聘大量的博士层次的候选人。因此一个有声望的、在学术圈有一定地位的人担任研究院的领导势必会对招聘起到很大的帮助作用。同时，因为对于具有博士文凭的研究人员的背景更加熟悉，有学术背景的领导往往更加能够制定人性化的管理方案，让这些博士觉得能够放心工作（比如对于参加学术会议的鼓励，比如对于发表论人的支持等等）。相反，如果这个领导只有工程背景或者是产品背景，即便是以前公司内部的高管，因为背景的差异，除了在招聘方面可能会遇到困难以外，在日常的管理上也可能无法往往都很难胜任研究院领军人这个职务。&lt;/p&gt;

&lt;p&gt;然而这方面的反面，则是从学术圈里直接挖来一些知名教授，来领导研究院。这里面有一些公司希望能够通过教授名气来吸引眼球的目的，而另一方面，也是希望知名教授能够带来招聘上的便利。不过，这样的行为往往忽视了这些知名教授在学术圈的日常运作和公司运作的巨大区别。就算是知名教授，不少人也很难直接管理超过十个学生，而在大公司，特别是研究院这个级别的组织中，管理超过几十人甚至上百人，并且有可能管理其他的中层领导，那么丝毫没有经验的人往往没法胜任这样的复杂协作分工管理。同时，没有公司经验的教授也往往无法在很短时间内领会到现代企业文化（比如晋升、比如公司政治、比如资源协调），能够为自己的团队在众多的团队的合作与竞争中谋取相应的利益。&lt;/p&gt;

&lt;p&gt;因此，比较合适的研究院的领导是至少有一定工业界经验，但可能早年在学术圈或者学校任职的优秀科技管理者。比如雅虎研究院的第一任领导Prabhakar Raghavan，就是这样一位人物。首先本人就是知名的学者，出版过知名教科书《Randomized Algorithms》和《Introduction to Information Retrieval》，并且是ACM，IEEE的院士，也是美国工程院院士。同时，其在加入雅虎之前，已经在IBM研究院以及Verity任职多年，特别是IBM的经历，让他对企业文化和工业界的研究机构有了很深的了解。可以说Prabhakar到雅虎之后很快就能建立起一个非常有效的团队，吸引了一大批的知名学者诸如Andrei Broder、Ricardo Baeza-Yates、Alex Smola等的加入，这和Prabhakar本人的背景可以说息息相关。同时，我们之前提到的关于研究院的运作规律，这其中有很多都是Prabhakar总结了他在多个组织的任职经验以后，在雅虎慢慢发展成熟起来的。&lt;/p&gt;

&lt;p&gt;第二个问题就是公司上下一定要对研究院究竟能给公司带来什么样的价值有一个清晰的判断。从我们刚才的一系列论述来看，研究院虽然在很多产品的研发中占有举足轻重的地位，但总体说来在公司是还是一个合作者的角色，是一个锦上添花，而非雪中送炭的角色。从这一点说来，整个公司的管理者和运行者要十分清楚。不过我们也要防止把研究院的价值庸俗化或者完全以产品成果为唯一的衡量标准。比如Google收购了位于伦敦的DeepMind团队来做深度学习的研究工作。DeepMind最近几年的研究成果，外加炒作的沸沸扬扬的AlphaGo究竟直接为Google的线上产品带来了多大收益恐怕很难直接衡量。但是DeepMind引领的这股深度学习的风潮，让Google在吸引这方面的人才这一方面则形成了巨大优势。这部分为Google节约的公关广告成本或者招聘陈本应该很容易就能覆盖对DeepMind的运营陈本。同时，DeepMind的成果，虽然很多不能直接应用到Google的现有产品上，但是Google的领导人借着这股风潮，让公司更多的工程师和产品人员开始深度介入深度学习领域，在内部进行了很多培训和推广工作，也是利用DeepMind这个研究团队来达到了原本不容易达到的目的。当然，从长远来看，研究院还是需要从产品和视角（Vision）上为公司带来价值，而且这些价值是普通研发团队所不能带来的。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;我们在这篇文章里详细讨论了什么样的互联网公司需要研究院，研究院又适合在什么样的产品线上发挥作用。我们还在这篇文章中深入剖析了研究院的研发团队如何和一般的产品工程团队合作，能够为现在成熟的产品线或者是前沿的产品的研发提供有力的支援。最后我们谈了一下制约研究院成功的两个关键的因素。本篇文章是第一篇比较完整得系统性阐述互联网公司以及研究院制度的文章，希望能够起到抛砖引玉的作用，让大家更加深入思考如何让研究机构在现代企业，特别是高新技术企业中生根发芽。&lt;/p&gt;
</description>
        <pubDate>Sun, 09 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E7%AE%A1%E7%90%86/2017/04/09/research-labs/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E7%AE%A1%E7%90%86/2017/04/09/research-labs/</guid>
        
        
        <category>管理</category>
        
      </item>
    
      <item>
        <title>数据科学发展的一些感悟</title>
        <description>&lt;p&gt;上个星期，我参加了位于San Diego召开的一个工业界数据科学会议Predictive Analytics Innovation Summit。在这里分享一些参会后对于数据科学在工业界发展状况及前景的感悟。&lt;/p&gt;

&lt;h2 id=&quot;感悟一数据科学的思潮席卷各个行业&quot;&gt;感悟一：数据科学的思潮席卷各个行业&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/san_diego.jpg&quot; alt=&quot;&quot; /&gt;
参加会议的代表来自各行各业，有互联网公司的数据佼佼者诸如Google、Bing、Netflix、Etsy（我所代表的公司）、Groupon；也有传统的金融产业公司Bloomberg、American Express、Visa；电信公司Verizon；保险公司Zurich；还有更传统的生产行业公司Bosch、Honeywell、Ford、GE Digital；以及一些你可能通常意义下不会认为是数据公司的代表诸如Weather.Com。除了这些有演讲内容的公司以外，还有不少医药行业的公司包括FDA的代表，以及很多其他行业的与会人员。总之从整体上看，对于数据科学的热衷已经席卷了各行各业。每一个行业都开设了诸如Chief Data Scientist、VP of Data Science的高端职位以及开始招聘各类数据科学家（Data Scientist）团队。每一个行业都在介绍自己是如何希望能够建立“数据驱动”（Data-Driven）的文化以及自己如何从数据中获益。每一个行业又是那么急切想从互联网公司、特别是已经在数据的使用和文化上有所建树的公司上得到启发和灵感。&lt;/p&gt;

&lt;h2 id=&quot;感悟二数据科学到底是什么大家并不清楚&quot;&gt;感悟二：数据科学到底是什么，大家并不清楚&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/san_diego2.jpg&quot; alt=&quot;&quot; /&gt;
虽然数据科学的浪潮已经深入各个行业，但大家对于到底什么是“数据科学”，甚至什么是“机器学习”、“深度学习”抑或“人工智能”，其实都有一种“雾里看花”的感觉。很多公司其实并不太清楚这些感念之间的区别或者异同。比较传统的一些公司，甚至是把以前存在过的Business Analysis或者是Business Intelligence部门直接转换成为数据科学部门，感觉有一种为了抓住这个目前的浪潮不惜偷梁换柱的意味。而且究竟数据科学，甚至是人工智能的标签，能为各个企业带来什么根本的变化，大家其实可能心里有不太一样的期待，或者是并没有真正去了解自己的期望究竟是什么。比如有些企业其实只是把数据科学认知为简单的数据分析、有的企业其实也没有太多太大的数据需要真正复杂的数据科学流程和高端的数据科学人才。&lt;/p&gt;

&lt;h2 id=&quot;感悟三数据科学人才极度匮乏&quot;&gt;感悟三：数据科学人才极度匮乏&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/bootcamp.jpg&quot; alt=&quot;&quot; /&gt;
尽管不同行业的各个企业可能还没有搞清楚数据科学到底意味着什么，但有一个共同的趋势，那就是各个行业的企业都发现了相关人才的极度匮乏。一方面，因为大家对数据科学的不确定性造成了其实各个企业并不是特别清楚自己需要的人才究竟是什么样的，也就造成了无法从现在的人才市场里清晰分别优质人才。另一方面，相对于几年前的“数据分析”人才而言，那时候公司还比较能够清晰得从统计背景的候选人中挑选，时至今日，数据科学或者人工智能人才需要全方面的背景，这使得入行门槛急剧增加。于是，目前造成的短期困境就是很多企业有大量职位空缺，但是从候选人池中很难找到如意的从事数据科学的相关人选。&lt;/p&gt;

&lt;h2 id=&quot;感悟四公司之间的巨大鸿沟&quot;&gt;感悟四：公司之间的巨大鸿沟&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/gap.jpg&quot; alt=&quot;&quot; /&gt;
因为对于数据科学认识的匮乏和以及对于公司如何来利用数据科学的混沌，以及由于人才的匮乏这两个显著的特征所带来的另外一个目前一个比较明显的现象就是，传统行业或者互联网的中小企业和目前利用数据科学的佼佼者甚至是人工智能的领军企业只有有非常大的鸿沟。从数据驱动文化上，到如何利用数据上，到具体的技术链条上，到人才的管理和挖掘上，领先的企业已经把大部分的其他玩家给远远抛在脑后。行业与行业之间的鸿沟也非常明显。互联网企业已经建立起了一整套的数据工具、规范和流程以及人才池的培养，紧跟其后的是金融企业（这也是最近一段时间以来大家所宣扬的FinTech带来的结果），然后其他大部分行业都要远远落后。这里面也需要注意的是，从各行各业的对于数据的需求来看，并不是盲目地照搬互联网企业的所谓的成功经验就能够轻而易举地搭上这个数据及智能的快车。其实这也可能表明，很可能没有一个普世的数据策略，每个行业需要摸索最适合自己发展的行业数据科学文化和标准。&lt;/p&gt;

&lt;h2 id=&quot;感悟五数据浪潮方兴未艾&quot;&gt;感悟五：数据浪潮方兴未艾&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/wave.jpg&quot; alt=&quot;&quot; /&gt;
如果我们长期只看少部分互联网尖端企业而言，那么我们很容易陷入当前阶段已经达到人工智能高峰的假象。当然，也不能说这就是假象，只是说少部分企业在他们所在的领域有着巨大的优势。但是如果我们放眼所有行业而言，目前可以说还是数据科学方兴未艾的阶段，有着大量的机会。对于互联网从业人员来说，如何能够从自身的一些优势出发，走到其他行业中去，恐怕是接下来一个阶段大家需要思考的问题。&lt;/p&gt;
</description>
        <pubDate>Thu, 02 Mar 2017 00:00:00 -0500</pubDate>
        <link>http://column.hongliangjie.com/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/2017/03/02/san_diego/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/2017/03/02/san_diego/</guid>
        
        
        <category>数据科学</category>
        
      </item>
    
      <item>
        <title>只有偏执狂才能生存</title>
        <description>&lt;p&gt;今年初，Intel传奇领导人物&lt;a href=&quot;https://en.wikipedia.org/wiki/Andrew_Grove&quot;&gt;安德鲁格罗夫（Andrew Grove）&lt;/a&gt;病逝。格罗夫的很多思想在90年代WinTel时代曾对中国的早期IT产业带来巨大启发。他所领导的Intel几乎是个人电脑时代的代名词。而他所著的&lt;a href=&quot;https://www.amazon.com/Only-Paranoid-Survive-Exploit-Challenge/dp/0385483821&quot;&gt;《只有偏执狂才能生存》&lt;/a&gt;作为危机管理的经典著作，影响了好几代人。最近买了这本书的原版来阅读，感触良多，在这篇文章中和大家分享一些读书心得。&lt;/p&gt;

&lt;h2 id=&quot;战略拐点&quot;&gt;战略拐点&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/andrew_grove.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;整本书都是围绕这一个叫“战略拐点”的概念展开的。格罗夫详细阐述了，什么是“战略拐点”，怎么识别它，怎么度过它，等一系列的问题。以及这个“战略拐点”对于公司存亡的重要性。那么，“战略拐点”的特征是什么呢？书中讲了很多内容，但是核心观点就是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;过去成功的经验现在不太适用了，未来可能更不适用。&lt;/li&gt;
  &lt;li&gt;未来的成功模式是和过去大不相同的，也许是一个全新的领域。&lt;/li&gt;
  &lt;li&gt;对过去越留恋，就越无法过度到未来的胜利彼岸。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;格罗夫反复强调，过去越成功，就越会成为战胜“战略拐点”的阻碍。因为管理者在困难和危机面前，最喜欢做的就是依靠过去的经验，使用曾经赖以成功的法宝。另一方面，也是比较容易忽视的则是管理者的感情寄托，也就是对于曾经的辉煌所付诸的情感投资。这是格罗夫在这本书中的亮点。很多时候，管理者并不是不知道应该去适应变化，去接受“战略拐点”的挑战，而是没法抛弃多年来成功所带来的职业生涯的满足感以及因此而产生的情感。这里的例子，包括Intel自身在1984-1986年时需要从存储器向微处理器全面转型的时候，格罗夫和摩尔两位管理者大师的不情愿、犹豫不决，也包括IBM当年不愿意从大型机的业务转移到蓬勃发展的个人电脑的市场。格罗夫在书中指出，因为需要消除情感依赖而对高层管理人员进行调整，往往成为了在“战略拐点”时期公司所不得不面临的抉择。&lt;/p&gt;

&lt;p&gt;在1996年出版之后到今天整整20年时间，格罗夫在这本书中提出的关于“战略拐点”的种种论述依然经受住了时间的检验，并且为这段时间出现的很多“新案例”提供了理论框架。例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;苹果公司自2001这十多年推出的iPod、iPhone以及iPad已经成为了其成功度过多个“战略拐点”的重要奠基石。今天的苹果公司已经不是在格罗夫1996年书里的那个WinTel大军下的失败者，而是在乔布斯带领下的革新者，一个新时代的领军人。乔布斯在个人电脑这个战场上没有占到先机，却洞察到消费电子产品时代的到来以及智能手机的曙光，于是带领苹果公司度过了“战略拐点”，来到了新的高地。&lt;/li&gt;
  &lt;li&gt;与苹果相映成的则是诺基亚和摩托罗拉在这十多年的境况。在模拟手机和数字手机时代如日中天的两个巨头，都没有把握住智能手机的“战略拐点”。重要原因，其实就是过去成功的包袱，经验也罢，情感也罢。令人瞠目结舌的恐怕在于两巨头倒下的速度和程度，令人唏嘘不已。&lt;/li&gt;
  &lt;li&gt;格罗夫在书中专门用一章来讲互联网的挑战。1996年，互联网的泡沫还没有完全到来，而第一个互联网时代的代表公司雅虎则才从斯坦福走出来不过两年。20年后，雅虎在成功成为第一代互联网巨头之后，没有抓住后面的好几次“战略拐点”（包括搜索、社交、移动等），于2016年被Verizon收购。&lt;/li&gt;
  &lt;li&gt;在第二个互联网时代风云驰骋的谷歌公司，面对Facebook的社交网络的挑战时，并没有完全体会到“战略拐点”的内涵。虽然高层下重金推广Google Plus，以期与Facebook一决高下，但实际上却因为丢不了自己的搜索老本行，并没有给Facebook带来多大的挑战。谷歌的搜索优势没有成为其转进到社交媒体这一“战略拐点”的武器。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;类似的例子还有很多，数不胜数。不过令人遗憾的是，尽管格罗夫的书里提供了丰富的指导思想，大多数过去曾经成功的公司在面对“战略拐点”的时候都深陷自己辉煌过去的泥潭，无法自拔。&lt;/p&gt;

&lt;h2 id=&quot;直面现实&quot;&gt;直面现实&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/reality.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在“战略拐点”面前，格罗夫描绘的，其实是非常惨淡的现实。其中有这么几点值得重视：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;伤亡&lt;/strong&gt;：也就是有人要做牺牲，普通员工和管理人员，底层、中层、高层。每一个人都有可能在这个转变中不在公司继续下去。必须要接受这样的伤亡。而且，书中讲得非常清楚，从公司最高层，高管，就必须要认识到。今天开会的高管们，其中有一些人是无法继续留下去的。不管这些人员过去有多成功。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;混沌&lt;/strong&gt;：最开始的时候，甚至在一段时间内，整个公司，包括管理层，是看不清楚前面的路的。这也就是所谓的“摸着石头过河”。大家要能够适应这样的混沌。更重要的是要坦诚大家不知道前面的路，谁也不清楚知道。不要不懂装懂。因为这个时候如果不愿面对自己的无知，又会让过去的经验来指导自己如何前行。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;学习&lt;/strong&gt;：在面对拐点的情况下，一定是面对一个不熟悉的环境。从高层到底层都需要用新的视野，新的技能来武装之自己。于是，学习就是必不可少的一个环节。千万不要以为能够用以前的知识来顺应变化。拐点的本质在于以前的知识现在不适用了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了这些需要主动关注的因素以外，还有一些，作为人，需要被动注意的点。比如，书中提到，管理层在遇到战略拐点的时候，犹如普通人遇到了人生的重大挫折，往往的第一反应是拒绝（Denial）。拒绝承认，觉得不可能。在1984年左右，日本半导体业的内存做得越来越好、价格越来越低的时候，格罗夫说，作为Intel，特别是作为内存的发明者，首先是拒绝承认这样的现实。在这个拒绝的过程中，甚至是动用了很多测试的方法和流程，才最终不得不认可日本的产品要优于Intel自己的产品。&lt;/p&gt;

&lt;p&gt;紧接着拒绝的举动，就是，“装作自己很忙”。很多管理层会使用各种方法，让自己忙起来，这样看上去就是在为公司的未来和转型做打算，把自己的日程安排的慢慢的。抑或是像普通人一样，突然爱好起“购物”，也就是收购公司。在采购的过程中精疲力尽。也就是说，管理层突然热衷收购其他公司，妄想通过收购来达到度过战略拐点的目的。而这个时候，公司往往还没有真正形成新的战略。公司的管理层，从思维到行为，都还和过去一样，于是，这些收购自然也不会真正有效果。收购本身无非是让管理层和普通员工感知到大家很忙，虽然没有忙对地方。这方面比较显著的例子，就是&lt;a href=&quot;https://en.wikipedia.org/wiki/Marissa_Mayer&quot;&gt;Marissa Mayer&lt;/a&gt;在2012年执掌雅虎以后，最初的日子里，战略并没有成形，却开始大肆收购。最终证明大多数这些收购并没有真正帮助到雅虎的战略转型。&lt;/p&gt;

&lt;p&gt;战略拐点的核心思想在于管理层是否能够在这样混沌的犹如过茫茫沙漠一般的“死亡之谷”的过程中，有一套方法论支撑下来。格罗夫的这本书其实就是这样的一个著作。&lt;/p&gt;

&lt;h2 id=&quot;大鸣大放与专注唯一&quot;&gt;大鸣大放与专注唯一&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/chaos.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;格罗夫在这本书中还提到了一个比较有意思的观点，那就是混沌（Chaos）和专注（Focus）的辩证关系。普通的观点可能是，一个公司，特别是大公司高速运转，最需要的就是组织内部的协调和思想的统一。有时候，这样的能力被称作是“专注力”。那么，在这本书中，格罗夫反而深刻阐述了“混沌”的必要性。也就是在公司转型的时期内，需要的反而是“大鸣大放”，需要某种程度的混乱。&lt;/p&gt;

&lt;p&gt;认识到“混沌”的重要性是格罗夫关于战略转型期的创造性认识。其实，这一观点能够从我们前面提到的“直面现实”中推演出来。因为，包括公司管理者可能都在最开始的时候，无法预测公司的未来。甚至也不能够知道接下来的战略转型是不是正确的。即便是正确的，也没有人能够保证各种决策的有效性。这个时候，其实非常难以让所有人都统一到一个方向上。各种人会有各种质疑。格罗夫认为，减少质疑的方法，不是禁止“混沌”，而是要让大家在公开的、有价值的、坦诚的讨论甚至是争论中进步，得到提升，能够为形成共识创造条件。这里，有一点，“真理越辩越明”的感觉。&lt;/p&gt;

&lt;p&gt;在大鸣大放的过程中，观点和方向逐渐清晰，那么这个时候，需要做的就是专注起来，把公司的思想和资源都统一到一个点上。整个的转型战略就是这一个点。注意，是一个点，而不是一个线或是一个面。格罗夫认为，在经历了“混沌”之后，公司已经精疲力尽，很难在一个面，或者一条线上组织起有效的力量。于是，在这种情况下，唯一能做的，是有效得组织一个点上的爆发。&lt;/p&gt;

&lt;p&gt;从“混沌”到“专注”，格罗夫认为这两者需要在公司内部动态、有机得组织起来。能够真正理解这两者的转换和每一个部分的特点，才是在转型期领导人的必须职责。&lt;/p&gt;

&lt;h2 id=&quot;历史与今天&quot;&gt;历史与今天&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/history.jpg&quot; alt=&quot;&quot; /&gt;
《只有偏执狂才能生存》成书于20年前的1996年。自然，在书中用到的例子，都是来自于上个世纪70年代到90年代这一个时期。从20年后的今天来看，很多例子非常有意思。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;苹果&lt;/strong&gt;： 在书中，苹果基本上是作为负面例子出现的。书中讲，大型机到PC机的转变中，整个工业界的形态从一家公司的“大包大揽”纵向布局，也就是从硬件到软件全包的一条龙服务，过度到了横向布局，也就是一家公司专注于某个领域（例如硬件，或者软件），整个行业分工协作。在这个过程中，崛起了Intel和微软，也崛起了组装厂商Dell和HP。苹果在PC这个战场上，可以说是“起个大早赶个晚集”。格罗夫认为乔布斯过于固守苹果自己要做纵向的布局，从而在横向的竞争中，无法保持公司的先进性。90年代的苹果，也在起起伏伏中，前途未卜。然而，同样是乔布斯，同样是纵向布局思维，在10年后的2000年代，iPhone和iPad所引领的移动时代则取得了巨大成功。而在这个新的战场上，Intel和微软被抛完全被抛弃。这20多年的动态变化，不仅充满了戏剧性，而且让人深思。当然，苹果现在的成功，也恰恰说明了，没有不变的战略，在战略拐点面前，过去的经验对未来不一定具有预见性，甚至是过去失败的教训，未来也未必就一定是错的。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;电动车&lt;/strong&gt;： 格罗夫在书中提到的，所谓“已经被证明是空想”的想法中，举了电动车的例子。书中并没有展开说，为什么这是一个“彻底的失败”（Complete Failure）。不过，从今天看，最有未来前瞻性，也是最可能在不远的将来带动一个革命性变化的行业，就是Tesla引领的电动车的浪潮。今天，整个硅谷，除了Google、百度、Tesla在投身到电动车外加自动驾驶车的研发中以外，传统车行业的各个厂商也摩拳擦掌，生怕自己在这轮竞争中被淘汰。20年前，电动车也许的确是一个失败的概念，但时至今日，在经历了20年的蛰伏，电动车已经进入了千家万户。这也是一个深刻的观点，那就是过去失败的想法，未必是未来成功的阻碍。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;互联网&lt;/strong&gt;：格罗夫在书中给了互联网高度的评价，并且预测互联网能够颠覆广告业。想想这是20年前，在Google、Facebook彻底推动广告业之前能有这样的预测，足可以见到格罗夫对行业的分析能力。不过，这也从侧面说明了，即便是正确的预测，一个行业也许需要很多年时间才能够成熟。如果能够在这样的间隙内找到机会，才是所有人都需要思考的问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;《只有偏执狂才能生存》这本书值得细细品味的地方当然远远不止这些。这篇文章只是试图给大家展示几个这本书中的关键点，希望能够起到抛砖引玉的作用。&lt;/p&gt;
</description>
        <pubDate>Tue, 09 Aug 2016 00:00:00 -0400</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2016/08/09/intel/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2016/08/09/intel/</guid>
        
        
        <category>读书笔记,管理</category>
        
      </item>
    
  </channel>
</rss>
