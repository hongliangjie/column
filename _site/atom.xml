<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>期望最大化（洪亮劼的专栏）</title>
 <link href="http://column.hongliangjie.com/atom.xml" rel="self"/>
 <link href="http://column.hongliangjie.com/"/>
 <updated>2017-06-10T14:21:04-04:00</updated>
 <id>http://column.hongliangjie.com</id>
 <author>
   <name>洪亮劼</name>
   <email>hongliangjie@gmail.com</email>
 </author>

 
 <entry>
   <title>AIStats 2017文章精读（一）</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/10/aistats2017-rank1-bandits/"/>
   <updated>2017-06-10T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/10/aistats2017-rank1-bandits</id>
   <content type="html">&lt;p&gt;我们在这里对&lt;a href=&quot;http://www.aistats.org/&quot;&gt;AIStats 2017&lt;/a&gt;文章Stochastic Rank-1 Bandits进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/katariya17a/katariya17a.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/katariya17a/katariya17a-supp.pdf&quot;&gt;文章附加信息&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自于几个大学和Adobe Research。作者群中的Branislav Kveton和Zheng Wen在过去几年中发表过多篇关于Bandits的文章，值得关注。&lt;/p&gt;

&lt;p&gt;这篇文章解决的问题是一个在应用中经常遇到的问题，那就是每一步Agent是从一对Row和Column的Arms中选择，并且得到他们的外积（Outer Product）作为Reward。这个设置从搜索中的Position-based Model以及从广告的推广中都有应用。&lt;/p&gt;

&lt;p&gt;具体的设置是这样的，先假设我们有K行，L列。在每一个时间T步骤中有一个行（Row）向量u，从一个分布中抽取（Draw）出来，同时有一个列（Column）向量v，从另外一个分布中抽取出来。这两个抽取的动作是完全独立的。在这样的情况下， Agent在时间T，需要选择一个综合的Arm，也就是一个两维的坐标，i和j，从而在u和v的外积（Outer Product）这个矩阵中得到坐标为i和j的回报（Reward）。&lt;/p&gt;

&lt;p&gt;文章指出，这个设置可以被当做是有K乘以L那么多个Arm的简单的Multi-armed Bandit。那么当然可以用UCB1或者是LinUCB去解。然而文章中分析了这样做的不现实性，最主要的难点在K和L都比较大的情况下，把这个场景的算法当做原始的Multi-armed Bandit就会有过大的Regret。&lt;/p&gt;

&lt;p&gt;这篇文章提出了一个叫做Rank1Elim的算法来有效的解决这个问题。我们这里不提这个算法的细节。总体说来，这个算法的核心思想，就是减少行和列的数量，使得需要Explore的数量大大减少。这也就是算法中所谓Elimination的来历。那么，怎么来减少行列的数量呢？虽然作者们没有直接指出，不过这里采用和核心思想就是Clustering。也就是说，有相似回报（Reward）的行与列都归并在一起，并且只留下一个。这样，就能大大减少整个搜索空间。&lt;/p&gt;

&lt;p&gt;文章主要的篇幅用在了证明上，这里就不去复述了。文章在MovenLens的数据集上做了一组实验，并且显示了比UCB1的Regret有非常大的提高。&lt;/p&gt;

&lt;p&gt;这篇文章适合对推荐系统的Exploitation和Exploration有研究的学者泛读。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>WWW 2017文章精读（七）</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/30/www2017-slice/"/>
   <updated>2017-04-30T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/30/www2017-slice</id>
   <content type="html">&lt;p&gt;我们在这里对WWW 2017文章Monetary Discount Strategies for Real-Time Promotion Campaign进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://oak.cs.ucla.edu/~chucheng/publication/www17.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的来自于一批来自台湾国立成功大学的学者和一个叫Slice Technologies的公司。这篇文章要解决的是一个非常实际的在E-Commerce会遇到的问题，那就是如何进行实时的促销（Promotion Campaign）使得可以吸引用户而同时也可以达到利润最大化的目的。&lt;/p&gt;

&lt;p&gt;作者们在这篇文章提出了一个叫做Real-Time Promotion（RTP）的概念，类比于广告里面经常提到的Real-Time Bidding。同时，这个RTP是一个针对某一个特定用户的一次性Deal。也就是说，这里面有了个性化的成分，使得能够对用户有一定的吸引力。然而，这个问题的难点是，如果能够做到在做RTP的同时，不影响到或者尽可能小的影响到用户对于品牌的一个认知，不至于让用户有负面的感觉。&lt;/p&gt;

&lt;p&gt;这篇文章的数据来源于这个叫Slice的公司。具体说来，Slice就是对百万用户的Receipts进行分析，从而对用户进行建模。这里面有一个基本的假设就是，如果一个用户已经以一定的价格（Price）购买了某种商品，那么，比这个价格低的价格，用户也一般愿意接受。而相反，用户可能不会接受比当前这个价格更高的价格。&lt;/p&gt;

&lt;p&gt;首先，作者们定义了这个所谓Discount-Giving Strategy的问题。那就是在给定的Discount预算（Budget）的情况下，如何最大化利润。文章指出，这个问题很类似传统的背包问题（Knapsack）。当然，与背包问题的最大不同的就是在于，这个问题中的很多参数是未知的，比如顾客是否愿意购买，再比如当前的折扣价格。&lt;/p&gt;

&lt;p&gt;在假设知道当前客户购买一个商品的价格分布的情况下，我们是可以得到最大化利润的一个表达的。然而遗憾的是，我们并不知道这个价格分布。于是在这篇文章里，作者们就提出了使用Kernel Density Estimation（KDE）来对价格分布进行估计。而得知了这个分布以后，我们就能够对每一个商品的所谓Cut-off Price进行一个准确的估计。这里的细节建议大家看文章。有了这些组成部分以后，作者们在这篇文章中提出了一个基于Thompson Sampling的办法，这样做的好处是可以对实时变化的数据进行很好的估计，同时也可以让整个优化过程更加Robust。&lt;/p&gt;

&lt;p&gt;实验就是在Slice过去手机的Receipts来进行的Simulation。应该说，实验的结果还是证明了动态的实时优化对于曾家利润是有帮助的。&lt;/p&gt;

&lt;p&gt;这篇文章的具体技术比较繁复，很难看出能够直接在这个基础上再扩展算法。然而这篇文章提出的问题的确比较新颖，也是电商或者网络运营商（比如Uber、DiDi）等经常遇到的问题，所以，值得对相关技术有兴趣的读者泛读。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>WWW 2017文章精读（六）</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/28/www2017-personal-search/"/>
   <updated>2017-04-28T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/28/www2017-personal-search</id>
   <content type="html">&lt;p&gt;我们在这里对WWW 2017文章Situational Context for Ranking in Personal Search进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1268&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自于University of Massachusetts Amherst（UMASS）以及Google。UMASS因为W. Bruce Croft（Information Retrieval领域的学术权威）的原因 ，一直以来是培养IR学者的重要学校。文章做这种的Michael Bendersky以及Xuanhua Wang都是Bruce Croft过去的学生。这篇文章想要讨论的是如何在个人搜索（Personal Search）这个领域根据用户的场景和情况（Situational Context）来训练有效的排序模型（Ranking Model）。&lt;/p&gt;

&lt;p&gt;这篇文章的核心思想其实非常直观：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;场景信息对于个人搜索来说很重要，比如时间，地点，Device，因此试图采用这些信息到排序算法中，是非常显而易见的。&lt;/li&gt;
  &lt;li&gt;作者们尝试采用Deep Neural Networks来学习Query以及Document之间的Matching。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;具体说来，作者们提出了两个排序模型来解决这两个设计问题。第一个模型应该说是第二个模型的简化版。&lt;/p&gt;

&lt;p&gt;第一个模型是把Query，Context，以及Document当做不同的模块元素，首先对于每一个模块分别学习一个Embedding向量。与之前的一些工作不同的是，这个Embedding不是事先学习好的（Pre-Trained）而是通过数据End-to-End学习出来的。有了各个模块的Embedding向量，作者们做了这么一个特殊的处理，那就是对于不同的Context（比如，时间、地点）学习到的Embedding，在最后进入Matching之前，不同Context的Embedding又组合成为一个统一的Context Embedding（这里的目的是学习到例如对时间、地点这组信息的统一规律），然后这个最终的Context Embedding和Query的，以及Document的Embedding，这三个模块进行Matching产生Relevance Score。&lt;/p&gt;

&lt;p&gt;那么，第二个模型是建立在第一个模型的基础上的。思路就是把最近的一个所谓叫Wide and Deep Neural Networks（Wide and Deep）的工作给延展到了这里。Wide and Deep的具体思想很简单。那就是说，一些Google的研究人员发现，单靠简单的DNN并不能很好的学习到过去的一些非常具体的经验。原因当然是DNN的主要优势和目的就是学习数据的抽象表达，而因为中间的Hidden Layer的原因，对于具体的一些Feature也好无法“记忆”。而在有一些应用中，能够完整记忆一些具体的Feature是非常有必要的。于是Wide and Deep其实就是把一个Logistic Regression和DNN硬拼凑在一起，用Logistic Regression的部分达到记忆具体数据，而用DNN的部分来进行抽象学习。这第二个模型也就采用了这个思路。在第一个模型之上，第二个模型直接把不同Context信息又和已经学到的各种Embedding放在一起，成为了最后产生Relevance Score的一部分。这样的话，在一些场景下出现的结果，就被这个线性模型部分给记忆住了。&lt;/p&gt;

&lt;p&gt;在实验的部分来说，文章当然是采用了Google的个人搜索实验数据，因此数据部分是没有公开的。从实验效果上来说，文章主要是比较了单纯的用CTR作为Feature，进行记忆的简单模型。总体说来，这篇文章提出的模型都能够对Baseline提出不小的提升，特别是第二个模型仍然能够对第一个模型有一个小部分但具有意义的提升。&lt;/p&gt;

&lt;p&gt;这篇文章对于研究如何用深度学习来做文档查询或者搜索的研究者和实践者而言，有不小的借鉴意义，值得精读。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>WWW 2017文章精读（五）</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/27/www2017-stream/"/>
   <updated>2017-04-27T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/27/www2017-stream</id>
   <content type="html">&lt;p&gt;我们在这里对WWW 2017文章Streaming Recommender Systems进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.yichang-cs.com/yahoo/WWW17_StreamingRec.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自雅虎研究院和University of Illinois at Urbana-Champaign。第一作者&lt;a href=&quot;http://www.ifp.illinois.edu/~chang87&quot;&gt;Shiyu Chang&lt;/a&gt;，是今年来一位学术新星，目前在IBM华生研究院工作。这篇文章的核心思想是想提出一个完全基于流（Stream）信息的推荐系统框架。&lt;/p&gt;

&lt;p&gt;作者们认为，流信息和普通的静态数据有很大的区别：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;大量的数据流入系统，系统必须对这些数据进行实时的反应。比如用户和某一个物品进行了交互；比如有新的物品产生需要被系统识别到并且能够查询等等。&lt;/li&gt;
  &lt;li&gt;流入系统的数据的量是未知的。这部分信息无法在产生系统之前拿到。&lt;/li&gt;
  &lt;li&gt;随着时间的推移，数据会产生所谓的“概念漂移”（Concept Shift）的现象。用户的喜好也会随着时间的推移而发生变化。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;于是，这篇文章就是希望从根本上来解决这些问题，提出一个基于信息流的推荐系统框架。&lt;/p&gt;

&lt;p&gt;文章提出的模型是一个具有时间信息的概率图模型（Probabilistic Graphical Model）。核心思想就是所有的元素都有时间的概念。举例来说，用户对于某一个物品的喜爱也仅仅是一个时间点的信息，并不代表之后的时间点的信息。这一点来说，就给了用户喜好发生变化的可能性。模型的核心还是基于用户向量（User Vector）和物品向量（Item Vector）的点积。不过，这里的用户向量和物品向量都是某一个时间点的估计。这些向量都随着时间发生变化。具体说来，作者们定义了一个基于布朗随机运动（Brownian Motion）的变化过程来对用户向量随着时间变化的改变来建模。也就是说，下一个时间点的用户向量是一个基于上一个时间点的用户向量的高斯分布。同样的建模手段也用到了物品向量上。整个模型可以说还是比较直观的，从概念上来说，提出的这个框架其实非常类似用卡曼滤波（Kalman Filtering）来进行时间维度的建模。而用卡曼滤波建模也是过去在概率图模型里经常使用的技巧。&lt;/p&gt;

&lt;p&gt;这个模型的难点是做模型的在线预测（Online Prediction）和离线模型参数估计（Offline Parameter Estimation）。对于在线预测的部分，作者们提出了一个叫Recursive Mean-field Approximation的技术。对于离线模型参数估计来说，作者们使用了标准的EM算法。总体来说，整个学习流程其实是比较复杂的。这也和其他使用类似卡曼滤波的方法类似。这也是概率图模型对时间信息处理的通病。&lt;/p&gt;

&lt;p&gt;文章实验的部分还是非常详尽的。文章在MovieLens的比较小的以及比较大的数据集上都做了实验，并且还加上了经典的Netflix的数据集。从Baseline的比较上来说，文章比较了传统的Probabilistic Matrix Factorization，经典的Time-SVD++算法（赢得Netflix大赛的算法）以及比较先进的Gaussian Process Factorization Machines。从实验的效果上来看，文章提出的方法在三个数据集上都有不错的效果。&lt;/p&gt;

&lt;p&gt;这篇文章提出的方法因为其算法复杂性，很难应用在生产中。而且要想在这个模型上做进一步的扩展，只能使得算法的复杂性进一步提升。这篇文章适合对于推荐系统有研究的学者和实践者泛读。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>WWW 2017文章精读（四）</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/26/www2017-ec/"/>
   <updated>2017-04-26T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/26/www2017-ec</id>
   <content type="html">&lt;p&gt;我们在这里对WWW 2017文章Modeling Consumer Preferences and Price Sensitivities from Large-Scale Grocery Shopping Transaction Logs进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cseweb.ucsd.edu/~m5wan/paper/www17_mwan.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自加州大学圣地亚哥分校（University of California at San Diego）和微软研究院。最后一个作者Julian McAuley在加州大学圣地亚哥分校长期从事推荐系统以及用户模型的研究工作。建议对推荐系统有研究的朋友经常看看他又有什么新的研究成果这篇文章的特色在于希望把推荐系统的用户喜好建模和经济学里的对于价格的研究结合起来。作者们认为，在推荐系统领域，对于用户喜好建模已经是比较成熟的研究领域了，而对于价格，特别是价格的敏感度（Sensitivity）的研究还并不是很多。于是这篇文章就是要弥补这么一个研究缺失（Gap）。&lt;/p&gt;

&lt;p&gt;作者们首先提出了一个分三阶段（Three Stage）的概率模型，用来刻画用户选择购买商品时候的选择过程。具体来说，这篇文章把用户的行为分为了这么三个阶段：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;类别选择（Category Purchase），也就是说，用户首先选择要购买哪个类别的商品。&lt;/li&gt;
  &lt;li&gt;产品选择（Product Choice），这里面就是在已经选定了一个类别以后，用户如何在这个类别里面选择商品。&lt;/li&gt;
  &lt;li&gt;数量购买（Purchase Quantity），选择要购买多少商品。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有了这三个阶段以后，用户的购买需求就成为了这三种概率的联合分布。&lt;/p&gt;

&lt;p&gt;为了对这三种行为有效建模，作者们首先提出了一个所谓的Feature-Based Matrix Factorization（FMF）的框架。总的说来，这是之前的LinkedIn提出的所谓的Generalized Linear Mixed Model（GLMix）变种。读者可以仔细参考原论文看看FMF的细节。这个FMF结合了全局特征（Global Features），物品特征，用户特征，以及用户和物品的隐含特征（Latent Features）。可以说是一个比较完善的框架体系。&lt;/p&gt;

&lt;p&gt;有了FMF这个工具，我们再回到刚才的三个阶段的建模。作者们的思路就是用FMF的不同表达形式为三个阶段进行分别的建模。具体说来，类别选择的部分，采用了FMF的Logistic表达形式，也就是对每个类别进行简单的“是”还是“不是”的购买选择。产品选择的部分则采用了Multinomial Regression的形式，也就是在所有同类商品里面进行选择。第三部分数量购买则采用了Poisson Regression的形式。然而核心这三部分采用的是同样的一套思路。因为这三个部分的独立性，使得模型的学习可以把这三部分分来，有利于能够并行化。在整体的模型学习上，作者们还加上了AUC Optimization的“作料”。&lt;/p&gt;

&lt;p&gt;接下来，作者们介绍了这篇文章的一个重点，那就是把价格因素引入到了整体框架中。其实思路还是很简单，就是直接把价格（在模型中用了Log Transformation）当做一个Feature，进行参数学习。这样做的好处还有直接可以计算所谓的价格敏感度，也就是购买一个东西的可能性的变化和价格变化的比值。这个数量可以用来描述价格的变化敏感度，可以让我们对价格做进一步的分析。&lt;/p&gt;

&lt;p&gt;作者们在一个非公开的西雅图的商店数据集上，和公开的Dunnhumby数据集上做了实验。实验结果是三个阶段的模型都有不错的表现。并且作者们还利用价格敏感度进行了数据的进一步分析。这里就不复述了。&lt;/p&gt;

&lt;p&gt;这篇文章值得对推荐系统有研究的学者和实践者精读。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>WWW 2017文章精读（三）</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/19/www2017-cloud/"/>
   <updated>2017-04-19T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/19/www2017-cloud</id>
   <content type="html">&lt;p&gt;我们在这里对WWW 2017文章Usage Patterns and the Economics of the Public Cloud进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://vita.mcafee.cc/PDF/EconPublicCloud.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自微软研究院和Uber。作者之一的R. Preston McAfee是著名的经济学家，曾在雅虎担任副总裁和首席经济学家，2012年以后到Google的Strategic Technology担任总监，2014年之后到微软担任首席经济学家。这篇文章是探讨现在第三方云计算平台（比如Amazon的AWS或是微软的Azure）是否能采用动态价格（Dynamic Pricing）的计价模式，特别是在所谓的“巅峰负载”（Peak-Load）的时候。&lt;/p&gt;

&lt;p&gt;首先，这篇文章对“云服务”模式进行了一个简单的介绍。这部分内容还是有很强的科普意义。这里面有一点可能比较容易忽视的科普点是，客户公司（Firm）需要对服务和软件进行重写才能使用云服务商提供的Auto-Scaling等方便的服务。如果客户公司仅仅是简单得把运行在传统数据中心上的服务给部署到云服务商的设施上面的话，则很难能够真正利用云服务的“易伸缩性”（Elastic）。&lt;/p&gt;

&lt;p&gt;紧接着，作者们对于其他工业怎么采用动态价格进行了简单的介绍。动态价格有两个条件，那就是Capacity在短期内是恒定的（Fixed）并且恒定的一部分陈本（Cost）是总成本不小的一部分。当然这都是对于服务商而言。目前我们对于动态价格的主要认识，来源于电力、航空和酒店这些行业。云服务如果按照刚才那个条件来说，是具备动态价格的一些先决条件的。因此，作者们认为应该对云服务的供需进行研究来看如何设计动态价格的策略，也就是说，作者们想看一看现在的云服务的使用率是不是不够优化，为动态服务提供了可操作的空间。&lt;/p&gt;

&lt;p&gt;这篇文章能够被WWW录取的一个重要原因可能是因为结果比较出人意料。作者们通过对微软的云服务数据（虽然在文中没有明说）进行分析得出，当前的云服务使用率（主要是从VM这个角度来说）的差别度（Variation） ，不管是看单个客户还是整体数据中心这个级别，都在5%以下。意思就是说，从云服务商这个整体来说，并没有出现特别大的服务需求起落。作者们的确从单个客户的数据中看到了使用率的震荡（Fluctuation），但是在云服务商这个层级，这样的震荡随着不同的客户数据，从而达到了整体“抵消”（Average Out）的效果。&lt;/p&gt;

&lt;p&gt;作者们认为这样的现实数据为现在的计费模型，也就是恒定的价格（Static Price）提供了一定的基础。同时，目前的可以预测的使用率也为服务商充分利用资源提供了保证。这一点与电力系统不同，电力系统为在巅峰时刻的用电一般必须调用额外的设备。当然，作者们也认为这样的使用数据，以及计费模型，是现在多数客户都简单把原来的软件系统给搬运到云计算平台上，而并没有充分利用云服务的Auto-Scaling有关系。&lt;/p&gt;

&lt;p&gt;为了对以后的可能性进行探索，作者们又从CPU的使用率这个级别进行分析。与VM的使用率不同的是，CPU的使用率看出了比较大的幅度。平均的最高CPU使用率比巅峰时期CPU使用率要小40%左右。因此，如果服务商能够通过CPU使用率来进行计价，或者VM资源能够在不使用的时候自动关闭，则为动态价格提供了一种可能性。作者们的与测试，这可能是未来的一种模式。&lt;/p&gt;

&lt;p&gt;总体来说，这篇文章算是科普性质的一篇文章。对于动态价格，以及云服务商的计价模式有兴趣的读者可以泛读本文。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>WWW 2017文章精读（二）</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/16/www2017-cml/"/>
   <updated>2017-04-16T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/16/www2017-cml</id>
   <content type="html">&lt;p&gt;我们在这里对WWW 2017文章Collaborative Metric Learning进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cs.cornell.edu/~ylongqi/paper/HsiehYCLBE17.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.cs.cornell.edu/~ylongqi/publication/www17b/&quot;&gt;论文的项目页面&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自于加州大学洛杉矶分校（University of California at Los Angeles）以及康奈尔科技大学（Cornell Tech）。 文章的核心思想是如何把Metric Learning和Collaborative Filtering（CF）结合起来从而达到更好的推荐效果。&lt;/p&gt;

&lt;p&gt;那么这篇文章为什么会想到把Metric Learning结合到CF上面呢？文章做了比较详细的交代。这里面的重点来自于传统的基于Matrix Factorization的CF模型都使用了Dot-Product来衡量用户向量（User Vector）和物品向量（Item Vector）的距离。也就是说，如果Dot-Product的值大， 就代表两个向量相近，值小就代表距离远。对于Dot-Product的默认使用已经让广大研究人员和实践者都没有怎么去质疑过其合理性。文章这里指出，Dot-Product并不是一个合理的距离测度，因此可能会带来对于相似度的学习不准确的问题。&lt;/p&gt;

&lt;p&gt;这里简单说一下什么是一个合理的距离测度。一个距离测度需要满足一些条件，而其中比较普遍的条件是所谓的“三角不等式”。所谓的“三角不等式”关系其实也就是说，距离的大小是有传递性的。举例来说，就是如果X与Y和Z都相近，那么Y和Z也应该相近。也就是说，相似度是可以传播的，在使用一个合理的距离测度的情况下。然而，文章指出Dot-Product并不具备这样的相似传递性，因此在实践中常常会不能有效得学习到数据中全部的信息。&lt;/p&gt;

&lt;p&gt;Metric Learning就是如何在一定的假设下，进行有效距离测度学习的工具。文章使用了一种Relaxed Version的Metric Learning，叫做Large-Margin Nearest Neighbor（LMNN）来学习数据之间的相似度。LMNN简单说来，就是同一个类型的数据应该更加紧密聚集在一起（通过Euclidean Distance），而不同类的数据应该远离。同时，同类的数据和不同类的数据之间保持一个Margin（模型的一个参数）的安全距离。&lt;/p&gt;

&lt;p&gt;作者们把这个概念拿过来，应用在CF的场景下，做了进一步的简化，那就是把“相同类数据聚合”这个部分去掉了，仅仅留下了“不同类远离”这个部分。作者们认为，一个物品可能被多个人喜欢，那么在这样的含义下，很难说清楚，到底怎么聚类比较有意义。具体说来，一个用户所喜欢的物品要远离这个用户所不喜欢的物品，同时这个距离会被一个与Rank（这里所说的Rank是指物品的排序）有关Weight所控制。也就是Rank越大，所产生的Penalty就越大。文章具体采用了一个叫Weighted Approximate Rank Pairwise Loss（WARP）的Loss来对Rank进行Penalty。这个WARP是早几年的时候还在Google的Weston等人提出的，目的是要对排在Rank比较大的正样本（Positive Instance）做比较大的Penalty。这里就不复述WARP的细节了。&lt;/p&gt;

&lt;p&gt;除了外加WARP的Metric learning，这篇文章还为整个模型的目标函数加了不少“作料”。“作料一”就是使用了Deep Learning来学习从物品的Feature到物品的Latent Vector的映射。这解决了Cold-start的问题。“作料二”则是对物品和用户的Latent Vector都做了正则化，使得学习起来更加Robust。&lt;/p&gt;

&lt;p&gt;文章简单描述了一下整个模型的训练过程。整个模型的目标函数由三个部分组成：Metric Learning的部分，加Deep Learning的部分，外加正则化的部分。比较意外的是，文章并没有提及模型在训练好以后如何在Test数据上进行Inference。&lt;/p&gt;

&lt;p&gt;文章在一系列标准数据集上做了测试，对比的Baseline也比较完整。总体说来，提出的模型都能达到最好的效果，有些在目前比较好的模型基础上能够提高10%以上，这比较令人吃惊。比较遗憾的是，文章并没有很好的展示这个模型的三个模块究竟是不是都必须。值得一提的是，文章指出使用了WARP的任何模型（包括本文章提出的模型）都要好于其他的模型。&lt;/p&gt;

&lt;p&gt;这篇文章总的来说还是可以参考。虽然有一些细节很值得推敲，但是，提出把Metric Learning引入到CF里来说，还是有一定价值的。&lt;/p&gt;

&lt;p&gt;建议对推荐系统正在研究的学者精读，对推荐系统有兴趣的实践者泛读。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>WWW 2017文章精读（一）</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/13/www2017-beyond-globally-optimal/"/>
   <updated>2017-04-13T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/13/www2017-beyond-globally-optimal</id>
   <content type="html">&lt;p&gt;我们在这里对WWW 2017文章Beyond Globally Optimal: Focused Learning for Improved Recommendations进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://alexbeutel.com/papers/www2017_focused_learning.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章来自一群前CMU的学者，目前在Google和Pinterest。那么这篇文章试图解决什么问题呢？具体说来，就是作者们发现，传统的推荐系统，基于优化一个全局的目标函数，通常情况下往往只能给出一个非常有“偏差”（Skewed）的预测分布。也就是说，传统的推荐系统追求的是平均表现情况，在很多情况下的预测其实是十分不准确的。这个情况在评价指标是Root Mean Squared Error（RMSE）的时候，就显得尤为明显。&lt;/p&gt;

&lt;p&gt;这篇文章的作者是这么定义了一个叫做Focused Learning的问题，那就是如果让模型在一个局部的数据上能够表现出色。那么，为什么需要模型在一个局部的数据上表现出色呢？作者们做了这么一件事情，那就是对每个用户，以及每一个物品的预测误差（Error）进行了分析统计，发现有不小比例的用户的预测误差比较大，也有不小比例的物品的预测误差比较大。作者们发现模型在一些数据上存在着系统性的误差较大的问题，而不是偶然发生的情况。&lt;/p&gt;

&lt;p&gt;作者们又从理论上进行了对这个问题一番讨论。这里的讨论十分巧妙，大概的思路就是，假定现在在全局最优的情况下，模型的参数的梯度已经为0了，但模型的Loss依然不为0（这种情况很常见）。那么，就一定存在部分数据的参数梯度不为0，因为某一部分数据的Loss不为0。这也就证明了部分数据的模型参数在这些数据上的表现一定不是最优的。值得注意的是，这个证明非常普遍，和具体的模型是什么类型没有关系。&lt;/p&gt;

&lt;p&gt;在有了这么一番讨论之后，那么作者们如何解决这个问题呢？这篇文章走了Hyper-parameter Optimization的道路。文章展示了这在普通的Matrix Factorization里面是如何做到。具体说来，就是对于某个Focused Set做Hyper-parameter的调优，使得当前的Hyper-parameter能够在Focused Set上能够有最好表现。而这组参数自然是针对不同的Focused Set有不同的选择。文章提到的另外一个思路，则是对Focused Set以及非Focused Set的Hyper-parameter进行区分对待，这样有助于最后的模型能够有一个比较Flexible的表达。&lt;/p&gt;

&lt;p&gt;文章在实验的部分针对几种不同的Focused Set进行了比较实验。比如，针对Cold-Start的物品，针对Outlier的物品，以及更加复杂的libFM模型都进行了实验。我们在这里就不去复述了。总体来说，Focused Learning在不同的数据集上都得到了比较好的提升效果。同时，作者们还针对为什么Focused Learning能够Work进行了一番探讨，总体看来，Focused Learning既照顾了Global的信息，同时又通过附加的Hyper-parameter调优对某一个局部的数据进行优化，所以往往好于Global的模型以及也好于单独的Local模型。&lt;/p&gt;

&lt;p&gt;本文非常适合对推荐系统有兴趣的学者和工程人员精读。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>论互联网公司与研究院</title>
   <link href="http://column.hongliangjie.com/%E7%AE%A1%E7%90%86/2017/04/09/research-labs/"/>
   <updated>2017-04-09T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E7%AE%A1%E7%90%86/2017/04/09/research-labs</id>
   <content type="html">&lt;p&gt;随着吴恩达离开百度研究院，关于互联网公司设立研究院的话题又被推到了风口浪尖。一时间，大家对互联网公司到底该不该设立研究院、研究院在公司内部又该起到怎样的作用、怎么能够设置一个有效的研究院架构、怎么来衡量研究院是否成功等问题展开了激烈的讨论。我打算在这篇专栏文章里，以本人在雅虎研究院的经历为基础，来剖析一下现代高科技企业尤其是互联网公司如何设置一个成功的研究院，研究院究竟该如何运作。这篇文章是在公开领域少有的论述研究院的系统性文章，值得大家精读。&lt;/p&gt;

&lt;h2 id=&quot;什么是研究院&quot;&gt;什么是研究院&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/andrew_ng.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在我们讨论其他话题之前，我们首先来看看目前互联网公司的各种研究院有什么特征。怎样的团队就算是一个“研究院类型”的团队（因为有一些公司并不直接单独称这些团队为“研究院”）。我们这里总结下面这么一些特征:&lt;/p&gt;

&lt;h3 id=&quot;特征一以博士为核心组成的团队&quot;&gt;特征一：以博士为核心组成的团队&lt;/h3&gt;
&lt;p&gt;大多数研究院的核心人员，甚至是全部研发人员都具有博士或以上（含博士后、有教职经验）研究经历。这个特征是因为很多研究院需要解决的问题或者研究的方向是产业的前沿，的确需要有掌握高级知识的人才进行研发工作。然而这个特征也直接导致了很多其他问题，那就是一个以博士为核心组成的团队和其他团队来比较，有一些其他团队所不具备的特点，为管理工作带来了额外的挑战。比如，很多博士习惯做长期项目（三个月以上甚至更长）。这些研发人员很不习惯更换项目，而且博士对于项目就像是研究课题，有个人的归属感和荣誉观，这是好事也是坏事。再比如，博士希望有比较长期的职业规划，对于自己的研究方向希望能够有所延续，能够参加学术会议，能够发表论文。这些需求都是其他一般的研发团队一般不具有的。如果一个研究院的管理层不能正视这些需求，则很难形成一个有很强创新力和执行力的团队。&lt;/p&gt;

&lt;h3 id=&quot;特征二相对比较独立的运作环境&quot;&gt;特征二：相对比较独立的运作环境&lt;/h3&gt;
&lt;p&gt;尽管我们后面要提到，很多研究院都和产品部门有或多或少的联系，有时候甚至和产品部门有密切的合作，但绝大多数研究院，都需要有一个相对比较独立的运作环境。比如，研究院是一个独立的团队，有自己部门的领导（而不是工程部门的兼任），有自己部门的单独预算，有自己部门的Key Performance Indicator（KPI)，有自己部门的组织结构和运作模式等等。这些都是建立一个研究院独立的形象。而且，也由于我们刚才提到的第一个特征，也就是研究院以博士为核心的特点，一个相对独立的运作环境有助于管理这一个可能和公司其他部门组成结构非常不一样的人群（因为这个人群的需求可能很不一样）。&lt;/p&gt;

&lt;h3 id=&quot;特征三研究院不是产品部门&quot;&gt;特征三：研究院不是产品部门&lt;/h3&gt;
&lt;p&gt;绝大多数研究院作为一个独立的运行实体都不直接掌管（Ownership）产品线。研究院可以作为产品部门的协作单位，但大多数成熟的研究院均不直接运作产品线。一个简单的原因是，产品线的研发和运作与研究院的目标是不完全一致的。那么这一点特征，可能会带来研究院在管理和定位上出现问题。我们下面会提到研究院的目标中就要来分析一下，在不掌管产品线的情况下，研究院如何能够保持其在公司内的影响力。&lt;/p&gt;

&lt;p&gt;上面三个特征只是研究院诸多特征中的代表。然而我们已经可以看出，研究院在现代互联网公司中的一个比较特殊的地位：人员构成、运作模式、需要为产品做贡献但又不是产品部门。正是因为有这些特点，成功运行一个研究院对于现代高科技企业来说，是一个巨大的管理挑战。&lt;/p&gt;

&lt;h2 id=&quot;研究院的目标&quot;&gt;研究院的目标&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/moonshot.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;什么样的公司需要研究院呢？要回答这个问题，我们必须要来看，什么样的产品需要研究院的支持。有两类产品很适合搭配研究院：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;比较成熟的产品&lt;/li&gt;
  &lt;li&gt;和公司现在产品线没有太大关系的前沿产品，有时候也叫“打月亮”（Moonshot）产品。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;我们先来说说为什么“比较成熟的产品”适合搭配研究院。成熟的产品，已经有了比较成熟的数据链条（Data Pipeline)，能够使得基于数据（Data-Driven)的研究工作有了可能性。而目前几乎所有的前沿研究，包括机器学习（Machine Learning)、人工智能（Artificial Intelligence）、数据科学（Data Science）等都无一例外非常强烈依赖于大量的数据。没有数据，绝大多数这类研究都没法进行。早期的产品并不具备这样的条件。比如，产品部门需要推出一款新的手机应用（App），而如何这个应用有比较多的功能之前并没有在公司其他产品中存在过，那么研究部门很难进行基于数据的研究工作。成熟的产品，也有相对比较成熟的衡量指标（Metrics）。这一点对于数据驱动的研究来说额外重要。因为有了衡量指标，就能够围绕这个指标展开特定的研究工作，设计相应的模型和算法，提出合理的优化解决方案。比如，当前的产品是搜索引擎，那么研究院就可以针对搜索引擎的成功衡量指标进行建模，更新搜索排序算法等等。早期的产品一般也没有固定、和合理的衡量指标，这会让大多数的研究工作一筹莫展。当然，研究院可以帮助产品部门建立衡量指标。不过这也是一个需要一定时间的过程。在这个过程结束前，其他的研究工作很难进行。&lt;/p&gt;

&lt;p&gt;我们再来说说为什么和现有产品线没有太大关系的前沿产品也是比较适合搭配研究院的原因。我们刚才提到研究院的特点的时候说到，绝大多数研究院都是相对比较独立运行的团队或者机构。这个特点就非常利于研发前沿产品。前沿产品因为其高失败率的特点并不适合普通的已经有成熟产品运维压力的产品部门进行研发。同时，前沿产品的“前沿”特点也使得研究院成为这种类型产品研发当仍不让的选择。另外，前沿产品一般并没有一个特定的产品公布时间表。这和前面所说的“非成熟”或者早期产品不一样。早期产品，尽管没有数据，没有成功指标，但往往有惊人的产品公布时间表，产品上线压力很大。而前沿产品，虽然也没有数据，也没有成功指标，但一般没有上线压力。这也就给了研究院自由空间去收集数据（比如Google的无人驾驶车），定义成功指标，进行迭代。当然，从这个角度来看，这也直接导致了，前沿产品的研发周期非常长，而且也很难去定义其上线的时间，于是成为其失败率高的部分原因。&lt;/p&gt;

&lt;p&gt;在我们了解了什么样的产品比较容易搭配研究院以后，我们再回到最开始的那个问题，“什么样的公司需要研究院”。如果一个公司的产品线相对还不稳定，很多产品处于快速迭代的状态下，这个时候，这样的公司其实并不太适合建立研究院。因为绝大多数产品线都没法真正“享受”到研究院的成果。如果一个公司并没有足够稳定的内部环境和财务基础，那么这个公司也就没有研发前沿产品的基础。那自然这样的情况下，配置一个以研发前沿产品为导向的研究院就更加显得没有必要。基于这样两个原因，绝对多数的初创公司，或者其实说，在上市前的初创公司都并不真正具备配置研究院的内外部环境。只有相对比较稳定的公司才有对研究院真正的需求。&lt;/p&gt;

&lt;p&gt;值得注意的是，我们也可以从这里关于研究院和产品线的讨论引申得到这么一个结论。因为研究院最大的功效是在对成熟产品的优化和改进上，以及对前沿产品的研发上，要想依赖研究院对一个公司的商业模式进行创新，或者寄希望研究院对快速迭代的产品产生贡献使得公司进入高速增长期都是不可能完成的任务。这些不切合实际的初衷往往给研究院的定位和发展带来困境。从另一个角度来说，那就是研究院可能对公司的长期商业运行可能会有比较大的影响（比如一些前沿产品如何研发成功），但在中短期来看，影响是相对比较有限的、是渐进式（Incremental）的（主要来自于对成熟产品的优化）。&lt;/p&gt;

&lt;h2 id=&quot;研究院的架构和运行&quot;&gt;研究院的架构和运行&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/research_lab.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在我们了解了什么样的产品需要研究院，什么样的公司需要配备研究院以后，我们现在就来探讨一下研究院的架构问题。&lt;/p&gt;

&lt;p&gt;我们上面提到了研究院在公司内部需要有一定的独立性。但是，现代高科技公司，毕竟从根本上来说还是追逐利润的企业，如何来确保研究院能够从长期上是符合公司发展的利益呢？这一点，是研究院生存的根本。&lt;/p&gt;

&lt;p&gt;从历史上来说，早期研究院很多都是这么一种运作模式：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;研究院的科学家针对某个技术难题（这个技术难题有可能是来自产品工程部门，也有可能是研究院的科学家自己发现）找到了一种解决方案， 形成一个研究成果。&lt;/li&gt;
  &lt;li&gt;根据不同的研究院的情况，科学家可能会选择发表研究成果，形成论文，或者是申请形成专利。&lt;/li&gt;
  &lt;li&gt;科学家根据这个研究成果做出一个解决方案的原型（Prototype）。&lt;/li&gt;
  &lt;li&gt;研究院团队根据解决方案的原型，到产品工程部门进行游说。产品工程部门根据自身的需求和产品周期，决定是否要把目前的原型重新在工程中实现，从而在下一代产品中使用上这个新成果。&lt;/li&gt;
  &lt;li&gt;产品工程团队和科学家一起把原型在工程代码中重新实现。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这个模式看似有一定道理，但也存在一些非常关键的问题。&lt;/p&gt;

&lt;p&gt;首先，第（1）步中就直接存在可能导致第（4）和第（5）没法发生的诱因。我们假设研究院的科学家拿到的技术难题是来自产品工程部门的。从现代产品的角度来说，一般的产品工程迭代都非常快。现在的技术难题可能几个星期后就有了能够解决80%问题的解决方案。也就是说，研究院拿到的技术难题有可能是有时效性的。这并不代表这些技术难题随着时间都有可能被解决，而是说，随着时间进程，很多技术难题可以出现多种解决方案。科学家能够找到的比较完美的解决方案（姑且假设能够100%解决问题）需要（2）-（5）这些步骤进入产品，这必然导致产品部门必须在科学家方案推出之前找到可以运行但很粗犷的方案。然而这种方案一旦进入产品，就会成为日后科学家的完美方案进驻的强大阻力。因为产品工程部门会觉得，在产品已经进一步迭代的情况下，是不是有精力和时间去改进一个已经可以运行的方案为更加完美的方案，其实是一个很棘手的问题。这也就会导致步骤（4）常常非常政治化（Political），成为各个团队扯皮的重要原因。刚才说的，还只是假设研究院的科学家拿到的技术难题是来自产品部门的，还有很多情况是，科学家或者研究院自身认为某些技术难题需要得到解决。这样发展出来的研究成果或者产品原型往往就更加难以通过第（4）和第（5）步得到产品化。&lt;/p&gt;

&lt;p&gt;因为第（4）和第（5）步的不确定性，很多研究院在发展过程中，往往把第（2）和第（3）步作为绩效评定的重要结果。这也就导致了很多研究院的成果只能完成第（1）步到第（3）步这个流程。而第（4）步成为了研究院成果产品化的不可逾越的鸿沟。&lt;/p&gt;

&lt;p&gt;那么如何运作研究院能够跨过这个鸿沟呢？雅虎研究院在过去10年的时间里对这个问题有着不错的实践经验。这里的核心问题就是如何把研究院的目标和一般产品工程团队的目标统一起来，使得大家对于产品的开发和运作是同步的。我们这里要提到这么一个概念，那就是“共享目标”。什么意思呢？那就是研究院和产品工程团队虽然从行政上隶属不同的部门，但在项目开发上，两个团队必须组成一个“虚拟团队”，有统一的领导和统一的进程管理，并且执行统一的、共享的目标。研究院和产品工程团队只是在这么一个共享的、统一的目标下分工不一样，责任不同而已。&lt;/p&gt;

&lt;p&gt;具体说来，以笔者参与过的雅虎首页推荐系统为例。产品工程团队每个季度都会和研究院的研究团队一起指定目标。这个目标是一个 综合性目标，有产品的部分（比如提高多少用户访问、提高多少用户点击），有纯工程的部分（比如如何加快代码部署），有研究的部分（比如应该采用什么模型来达到用户访问的提高、比如应该怎么加快模型的训练速度）。那么，“虚拟团队”就会根据这个综合性的目标来分配资源，确保整个团队的工作量和各个方面的目标达到一个不错的平衡。目标共享以后，研究院的研究周期得到了明确，也就是每个季度。同时，研究院的“成果落地”得到了保证，那就是直接和产品对接，每一个季度都需要“上线”。这种模式下的研究院团队，也不会去做“天马行空”的项目，而是仅仅围绕产品工程，做很多“增量式”的创新工作。&lt;/p&gt;

&lt;p&gt;“共享目标”对于雅虎的很多产品决策过程以及运作过程产生了深远的影响。首先，那就是采用“共享目标”架构的产品全责更加清晰，工程负责什么，研究院负责什么，设计师负责什么，每个季度这几个方面一目了然。另一个非常显著的改变，那就是这些产品第一次把AI（这也就是研究院往往负责的部分）、工程以及设计三个方面作为一个产品每个季度推进的三个主要方面。也就是让AI成为了产品的目标的一类公民。&lt;/p&gt;

&lt;p&gt;那么，“共享目标”是不是就解决了研究院的运作问题了呢？答案是，不完全是。首先，“共享目标”听上去容易，但在实际运作中难度其实还是很大。这里面最重要的是信任问题。从公司结构上来说，产品工程团队往往对产品有“所有权”（Ownership），自然希望能够对产品的方方面面有所把握。然而在“共享目标”的框架下，实质上发生的则是，研究院对于产品的部分方面有了一定的决策权和执行权，这势必需要产品工程团队的领导和人员对于这方面有足够的认识和预期。实际上，从另外一种角度来说，这种“共享目标”其实就是产品工程部门把部分产品开发方面长期外包给了研究院的团队。雅虎的产品工程团队能够和研究院针对某些产品这么做，是因为研究院长期以来能够对这些产品持续做出不俗的贡献，赢得了信任。但并不是所有的产品都能够在这样的框架下运作。&lt;/p&gt;

&lt;p&gt;同时，因为和产品工程达成“共享目标”，这势必也就造成了研究院的研究目标和成果相对比较“短视化”，常常迎合了产品周期。这也就呼应了我们之前提到的，比较适应研究院的一类产品，那就是成熟产品。实际上，“共享目标”的模式很好的契合了成熟产品的迭代。&lt;/p&gt;

&lt;p&gt;对于前沿产品来说，这样的架构显然不太适用。因为这个时候产品和工程组可能都还不存在。对于这样的项目来说，最好以研究院的科学家为核心，然后辅以工程师作为支持。从某种意义上来说，这依然是一种“共享目标”，不过则是之前谈到的相反的结构。&lt;/p&gt;

&lt;h2 id=&quot;研究院的成功&quot;&gt;研究院的成功&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/research_leaders.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;之前已经讨论了研究院的架构和运作，那么，我们怎么能够保证研究院的成功呢？我们这里谈两个比较显著的问题。&lt;/p&gt;

&lt;p&gt;第一个方面那就是研究院需要怎么样的领导。这个问题看似很简单，其实需要相当认真的思考。因为研究院需要负责招聘大量的博士层次的候选人。因此一个有声望的、在学术圈有一定地位的人担任研究院的领导势必会对招聘起到很大的帮助作用。同时，因为对于具有博士文凭的研究人员的背景更加熟悉，有学术背景的领导往往更加能够制定人性化的管理方案，让这些博士觉得能够放心工作（比如对于参加学术会议的鼓励，比如对于发表论人的支持等等）。相反，如果这个领导只有工程背景或者是产品背景，即便是以前公司内部的高管，因为背景的差异，除了在招聘方面可能会遇到困难以外，在日常的管理上也可能无法往往都很难胜任研究院领军人这个职务。&lt;/p&gt;

&lt;p&gt;然而这方面的反面，则是从学术圈里直接挖来一些知名教授，来领导研究院。这里面有一些公司希望能够通过教授名气来吸引眼球的目的，而另一方面，也是希望知名教授能够带来招聘上的便利。不过，这样的行为往往忽视了这些知名教授在学术圈的日常运作和公司运作的巨大区别。就算是知名教授，不少人也很难直接管理超过十个学生，而在大公司，特别是研究院这个级别的组织中，管理超过几十人甚至上百人，并且有可能管理其他的中层领导，那么丝毫没有经验的人往往没法胜任这样的复杂协作分工管理。同时，没有公司经验的教授也往往无法在很短时间内领会到现代企业文化（比如晋升、比如公司政治、比如资源协调），能够为自己的团队在众多的团队的合作与竞争中谋取相应的利益。&lt;/p&gt;

&lt;p&gt;因此，比较合适的研究院的领导是至少有一定工业界经验，但可能早年在学术圈或者学校任职的优秀科技管理者。比如雅虎研究院的第一任领导Prabhakar Raghavan，就是这样一位人物。首先本人就是知名的学者，出版过知名教科书《Randomized Algorithms》和《Introduction to Information Retrieval》，并且是ACM，IEEE的院士，也是美国工程院院士。同时，其在加入雅虎之前，已经在IBM研究院以及Verity任职多年，特别是IBM的经历，让他对企业文化和工业界的研究机构有了很深的了解。可以说Prabhakar到雅虎之后很快就能建立起一个非常有效的团队，吸引了一大批的知名学者诸如Andrei Broder、Ricardo Baeza-Yates、Alex Smola等的加入，这和Prabhakar本人的背景可以说息息相关。同时，我们之前提到的关于研究院的运作规律，这其中有很多都是Prabhakar总结了他在多个组织的任职经验以后，在雅虎慢慢发展成熟起来的。&lt;/p&gt;

&lt;p&gt;第二个问题就是公司上下一定要对研究院究竟能给公司带来什么样的价值有一个清晰的判断。从我们刚才的一系列论述来看，研究院虽然在很多产品的研发中占有举足轻重的地位，但总体说来在公司是还是一个合作者的角色，是一个锦上添花，而非雪中送炭的角色。从这一点说来，整个公司的管理者和运行者要十分清楚。不过我们也要防止把研究院的价值庸俗化或者完全以产品成果为唯一的衡量标准。比如Google收购了位于伦敦的DeepMind团队来做深度学习的研究工作。DeepMind最近几年的研究成果，外加炒作的沸沸扬扬的AlphaGo究竟直接为Google的线上产品带来了多大收益恐怕很难直接衡量。但是DeepMind引领的这股深度学习的风潮，让Google在吸引这方面的人才这一方面则形成了巨大优势。这部分为Google节约的公关广告成本或者招聘陈本应该很容易就能覆盖对DeepMind的运营陈本。同时，DeepMind的成果，虽然很多不能直接应用到Google的现有产品上，但是Google的领导人借着这股风潮，让公司更多的工程师和产品人员开始深度介入深度学习领域，在内部进行了很多培训和推广工作，也是利用DeepMind这个研究团队来达到了原本不容易达到的目的。当然，从长远来看，研究院还是需要从产品和视角（Vision）上为公司带来价值，而且这些价值是普通研发团队所不能带来的。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;我们在这篇文章里详细讨论了什么样的互联网公司需要研究院，研究院又适合在什么样的产品线上发挥作用。我们还在这篇文章中深入剖析了研究院的研发团队如何和一般的产品工程团队合作，能够为现在成熟的产品线或者是前沿的产品的研发提供有力的支援。最后我们谈了一下制约研究院成功的两个关键的因素。本篇文章是第一篇比较完整得系统性阐述互联网公司以及研究院制度的文章，希望能够起到抛砖引玉的作用，让大家更加深入思考如何让研究机构在现代企业，特别是高新技术企业中生根发芽。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>数据科学发展的一些感悟</title>
   <link href="http://column.hongliangjie.com/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/2017/03/02/san_diego/"/>
   <updated>2017-03-02T00:00:00-05:00</updated>
   <id>http://column.hongliangjie.com/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/2017/03/02/san_diego</id>
   <content type="html">&lt;p&gt;上个星期，我参加了位于San Diego召开的一个工业界数据科学会议Predictive Analytics Innovation Summit。在这里分享一些参会后对于数据科学在工业界发展状况及前景的感悟。&lt;/p&gt;

&lt;h2 id=&quot;感悟一数据科学的思潮席卷各个行业&quot;&gt;感悟一：数据科学的思潮席卷各个行业&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/san_diego.jpg&quot; alt=&quot;&quot; /&gt;
参加会议的代表来自各行各业，有互联网公司的数据佼佼者诸如Google、Bing、Netflix、Etsy（我所代表的公司）、Groupon；也有传统的金融产业公司Bloomberg、American Express、Visa；电信公司Verizon；保险公司Zurich；还有更传统的生产行业公司Bosch、Honeywell、Ford、GE Digital；以及一些你可能通常意义下不会认为是数据公司的代表诸如Weather.Com。除了这些有演讲内容的公司以外，还有不少医药行业的公司包括FDA的代表，以及很多其他行业的与会人员。总之从整体上看，对于数据科学的热衷已经席卷了各行各业。每一个行业都开设了诸如Chief Data Scientist、VP of Data Science的高端职位以及开始招聘各类数据科学家（Data Scientist）团队。每一个行业都在介绍自己是如何希望能够建立“数据驱动”（Data-Driven）的文化以及自己如何从数据中获益。每一个行业又是那么急切想从互联网公司、特别是已经在数据的使用和文化上有所建树的公司上得到启发和灵感。&lt;/p&gt;

&lt;h2 id=&quot;感悟二数据科学到底是什么大家并不清楚&quot;&gt;感悟二：数据科学到底是什么，大家并不清楚&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/san_diego2.jpg&quot; alt=&quot;&quot; /&gt;
虽然数据科学的浪潮已经深入各个行业，但大家对于到底什么是“数据科学”，甚至什么是“机器学习”、“深度学习”抑或“人工智能”，其实都有一种“雾里看花”的感觉。很多公司其实并不太清楚这些感念之间的区别或者异同。比较传统的一些公司，甚至是把以前存在过的Business Analysis或者是Business Intelligence部门直接转换成为数据科学部门，感觉有一种为了抓住这个目前的浪潮不惜偷梁换柱的意味。而且究竟数据科学，甚至是人工智能的标签，能为各个企业带来什么根本的变化，大家其实可能心里有不太一样的期待，或者是并没有真正去了解自己的期望究竟是什么。比如有些企业其实只是把数据科学认知为简单的数据分析、有的企业其实也没有太多太大的数据需要真正复杂的数据科学流程和高端的数据科学人才。&lt;/p&gt;

&lt;h2 id=&quot;感悟三数据科学人才极度匮乏&quot;&gt;感悟三：数据科学人才极度匮乏&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/bootcamp.jpg&quot; alt=&quot;&quot; /&gt;
尽管不同行业的各个企业可能还没有搞清楚数据科学到底意味着什么，但有一个共同的趋势，那就是各个行业的企业都发现了相关人才的极度匮乏。一方面，因为大家对数据科学的不确定性造成了其实各个企业并不是特别清楚自己需要的人才究竟是什么样的，也就造成了无法从现在的人才市场里清晰分别优质人才。另一方面，相对于几年前的“数据分析”人才而言，那时候公司还比较能够清晰得从统计背景的候选人中挑选，时至今日，数据科学或者人工智能人才需要全方面的背景，这使得入行门槛急剧增加。于是，目前造成的短期困境就是很多企业有大量职位空缺，但是从候选人池中很难找到如意的从事数据科学的相关人选。&lt;/p&gt;

&lt;h2 id=&quot;感悟四公司之间的巨大鸿沟&quot;&gt;感悟四：公司之间的巨大鸿沟&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/gap.jpg&quot; alt=&quot;&quot; /&gt;
因为对于数据科学认识的匮乏和以及对于公司如何来利用数据科学的混沌，以及由于人才的匮乏这两个显著的特征所带来的另外一个目前一个比较明显的现象就是，传统行业或者互联网的中小企业和目前利用数据科学的佼佼者甚至是人工智能的领军企业只有有非常大的鸿沟。从数据驱动文化上，到如何利用数据上，到具体的技术链条上，到人才的管理和挖掘上，领先的企业已经把大部分的其他玩家给远远抛在脑后。行业与行业之间的鸿沟也非常明显。互联网企业已经建立起了一整套的数据工具、规范和流程以及人才池的培养，紧跟其后的是金融企业（这也是最近一段时间以来大家所宣扬的FinTech带来的结果），然后其他大部分行业都要远远落后。这里面也需要注意的是，从各行各业的对于数据的需求来看，并不是盲目地照搬互联网企业的所谓的成功经验就能够轻而易举地搭上这个数据及智能的快车。其实这也可能表明，很可能没有一个普世的数据策略，每个行业需要摸索最适合自己发展的行业数据科学文化和标准。&lt;/p&gt;

&lt;h2 id=&quot;感悟五数据浪潮方兴未艾&quot;&gt;感悟五：数据浪潮方兴未艾&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/wave.jpg&quot; alt=&quot;&quot; /&gt;
如果我们长期只看少部分互联网尖端企业而言，那么我们很容易陷入当前阶段已经达到人工智能高峰的假象。当然，也不能说这就是假象，只是说少部分企业在他们所在的领域有着巨大的优势。但是如果我们放眼所有行业而言，目前可以说还是数据科学方兴未艾的阶段，有着大量的机会。对于互联网从业人员来说，如何能够从自身的一些优势出发，走到其他行业中去，恐怕是接下来一个阶段大家需要思考的问题。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>只有偏执狂才能生存</title>
   <link href="http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2016/08/09/intel/"/>
   <updated>2016-08-09T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2016/08/09/intel</id>
   <content type="html">&lt;p&gt;今年初，Intel传奇领导人物&lt;a href=&quot;https://en.wikipedia.org/wiki/Andrew_Grove&quot;&gt;安德鲁格罗夫（Andrew Grove）&lt;/a&gt;病逝。格罗夫的很多思想在90年代WinTel时代曾对中国的早期IT产业带来巨大启发。他所领导的Intel几乎是个人电脑时代的代名词。而他所著的&lt;a href=&quot;https://www.amazon.com/Only-Paranoid-Survive-Exploit-Challenge/dp/0385483821&quot;&gt;《只有偏执狂才能生存》&lt;/a&gt;作为危机管理的经典著作，影响了好几代人。最近买了这本书的原版来阅读，感触良多，在这篇文章中和大家分享一些读书心得。&lt;/p&gt;

&lt;h2 id=&quot;战略拐点&quot;&gt;战略拐点&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/andrew_grove.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;整本书都是围绕这一个叫“战略拐点”的概念展开的。格罗夫详细阐述了，什么是“战略拐点”，怎么识别它，怎么度过它，等一系列的问题。以及这个“战略拐点”对于公司存亡的重要性。那么，“战略拐点”的特征是什么呢？书中讲了很多内容，但是核心观点就是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;过去成功的经验现在不太适用了，未来可能更不适用。&lt;/li&gt;
  &lt;li&gt;未来的成功模式是和过去大不相同的，也许是一个全新的领域。&lt;/li&gt;
  &lt;li&gt;对过去越留恋，就越无法过度到未来的胜利彼岸。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;格罗夫反复强调，过去越成功，就越会成为战胜“战略拐点”的阻碍。因为管理者在困难和危机面前，最喜欢做的就是依靠过去的经验，使用曾经赖以成功的法宝。另一方面，也是比较容易忽视的则是管理者的感情寄托，也就是对于曾经的辉煌所付诸的情感投资。这是格罗夫在这本书中的亮点。很多时候，管理者并不是不知道应该去适应变化，去接受“战略拐点”的挑战，而是没法抛弃多年来成功所带来的职业生涯的满足感以及因此而产生的情感。这里的例子，包括Intel自身在1984-1986年时需要从存储器向微处理器全面转型的时候，格罗夫和摩尔两位管理者大师的不情愿、犹豫不决，也包括IBM当年不愿意从大型机的业务转移到蓬勃发展的个人电脑的市场。格罗夫在书中指出，因为需要消除情感依赖而对高层管理人员进行调整，往往成为了在“战略拐点”时期公司所不得不面临的抉择。&lt;/p&gt;

&lt;p&gt;在1996年出版之后到今天整整20年时间，格罗夫在这本书中提出的关于“战略拐点”的种种论述依然经受住了时间的检验，并且为这段时间出现的很多“新案例”提供了理论框架。例如：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;苹果公司自2001这十多年推出的iPod、iPhone以及iPad已经成为了其成功度过多个“战略拐点”的重要奠基石。今天的苹果公司已经不是在格罗夫1996年书里的那个WinTel大军下的失败者，而是在乔布斯带领下的革新者，一个新时代的领军人。乔布斯在个人电脑这个战场上没有占到先机，却洞察到消费电子产品时代的到来以及智能手机的曙光，于是带领苹果公司度过了“战略拐点”，来到了新的高地。&lt;/li&gt;
  &lt;li&gt;与苹果相映成的则是诺基亚和摩托罗拉在这十多年的境况。在模拟手机和数字手机时代如日中天的两个巨头，都没有把握住智能手机的“战略拐点”。重要原因，其实就是过去成功的包袱，经验也罢，情感也罢。令人瞠目结舌的恐怕在于两巨头倒下的速度和程度，令人唏嘘不已。&lt;/li&gt;
  &lt;li&gt;格罗夫在书中专门用一章来讲互联网的挑战。1996年，互联网的泡沫还没有完全到来，而第一个互联网时代的代表公司雅虎则才从斯坦福走出来不过两年。20年后，雅虎在成功成为第一代互联网巨头之后，没有抓住后面的好几次“战略拐点”（包括搜索、社交、移动等），于2016年被Verizon收购。&lt;/li&gt;
  &lt;li&gt;在第二个互联网时代风云驰骋的谷歌公司，面对Facebook的社交网络的挑战时，并没有完全体会到“战略拐点”的内涵。虽然高层下重金推广Google Plus，以期与Facebook一决高下，但实际上却因为丢不了自己的搜索老本行，并没有给Facebook带来多大的挑战。谷歌的搜索优势没有成为其转进到社交媒体这一“战略拐点”的武器。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;类似的例子还有很多，数不胜数。不过令人遗憾的是，尽管格罗夫的书里提供了丰富的指导思想，大多数过去曾经成功的公司在面对“战略拐点”的时候都深陷自己辉煌过去的泥潭，无法自拔。&lt;/p&gt;

&lt;h2 id=&quot;直面现实&quot;&gt;直面现实&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/reality.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在“战略拐点”面前，格罗夫描绘的，其实是非常惨淡的现实。其中有这么几点值得重视：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;伤亡&lt;/strong&gt;：也就是有人要做牺牲，普通员工和管理人员，底层、中层、高层。每一个人都有可能在这个转变中不在公司继续下去。必须要接受这样的伤亡。而且，书中讲得非常清楚，从公司最高层，高管，就必须要认识到。今天开会的高管们，其中有一些人是无法继续留下去的。不管这些人员过去有多成功。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;混沌&lt;/strong&gt;：最开始的时候，甚至在一段时间内，整个公司，包括管理层，是看不清楚前面的路的。这也就是所谓的“摸着石头过河”。大家要能够适应这样的混沌。更重要的是要坦诚大家不知道前面的路，谁也不清楚知道。不要不懂装懂。因为这个时候如果不愿面对自己的无知，又会让过去的经验来指导自己如何前行。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;学习&lt;/strong&gt;：在面对拐点的情况下，一定是面对一个不熟悉的环境。从高层到底层都需要用新的视野，新的技能来武装之自己。于是，学习就是必不可少的一个环节。千万不要以为能够用以前的知识来顺应变化。拐点的本质在于以前的知识现在不适用了。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了这些需要主动关注的因素以外，还有一些，作为人，需要被动注意的点。比如，书中提到，管理层在遇到战略拐点的时候，犹如普通人遇到了人生的重大挫折，往往的第一反应是拒绝（Denial）。拒绝承认，觉得不可能。在1984年左右，日本半导体业的内存做得越来越好、价格越来越低的时候，格罗夫说，作为Intel，特别是作为内存的发明者，首先是拒绝承认这样的现实。在这个拒绝的过程中，甚至是动用了很多测试的方法和流程，才最终不得不认可日本的产品要优于Intel自己的产品。&lt;/p&gt;

&lt;p&gt;紧接着拒绝的举动，就是，“装作自己很忙”。很多管理层会使用各种方法，让自己忙起来，这样看上去就是在为公司的未来和转型做打算，把自己的日程安排的慢慢的。抑或是像普通人一样，突然爱好起“购物”，也就是收购公司。在采购的过程中精疲力尽。也就是说，管理层突然热衷收购其他公司，妄想通过收购来达到度过战略拐点的目的。而这个时候，公司往往还没有真正形成新的战略。公司的管理层，从思维到行为，都还和过去一样，于是，这些收购自然也不会真正有效果。收购本身无非是让管理层和普通员工感知到大家很忙，虽然没有忙对地方。这方面比较显著的例子，就是&lt;a href=&quot;https://en.wikipedia.org/wiki/Marissa_Mayer&quot;&gt;Marissa Mayer&lt;/a&gt;在2012年执掌雅虎以后，最初的日子里，战略并没有成形，却开始大肆收购。最终证明大多数这些收购并没有真正帮助到雅虎的战略转型。&lt;/p&gt;

&lt;p&gt;战略拐点的核心思想在于管理层是否能够在这样混沌的犹如过茫茫沙漠一般的“死亡之谷”的过程中，有一套方法论支撑下来。格罗夫的这本书其实就是这样的一个著作。&lt;/p&gt;

&lt;h2 id=&quot;大鸣大放与专注唯一&quot;&gt;大鸣大放与专注唯一&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/chaos.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;格罗夫在这本书中还提到了一个比较有意思的观点，那就是混沌（Chaos）和专注（Focus）的辩证关系。普通的观点可能是，一个公司，特别是大公司高速运转，最需要的就是组织内部的协调和思想的统一。有时候，这样的能力被称作是“专注力”。那么，在这本书中，格罗夫反而深刻阐述了“混沌”的必要性。也就是在公司转型的时期内，需要的反而是“大鸣大放”，需要某种程度的混乱。&lt;/p&gt;

&lt;p&gt;认识到“混沌”的重要性是格罗夫关于战略转型期的创造性认识。其实，这一观点能够从我们前面提到的“直面现实”中推演出来。因为，包括公司管理者可能都在最开始的时候，无法预测公司的未来。甚至也不能够知道接下来的战略转型是不是正确的。即便是正确的，也没有人能够保证各种决策的有效性。这个时候，其实非常难以让所有人都统一到一个方向上。各种人会有各种质疑。格罗夫认为，减少质疑的方法，不是禁止“混沌”，而是要让大家在公开的、有价值的、坦诚的讨论甚至是争论中进步，得到提升，能够为形成共识创造条件。这里，有一点，“真理越辩越明”的感觉。&lt;/p&gt;

&lt;p&gt;在大鸣大放的过程中，观点和方向逐渐清晰，那么这个时候，需要做的就是专注起来，把公司的思想和资源都统一到一个点上。整个的转型战略就是这一个点。注意，是一个点，而不是一个线或是一个面。格罗夫认为，在经历了“混沌”之后，公司已经精疲力尽，很难在一个面，或者一条线上组织起有效的力量。于是，在这种情况下，唯一能做的，是有效得组织一个点上的爆发。&lt;/p&gt;

&lt;p&gt;从“混沌”到“专注”，格罗夫认为这两者需要在公司内部动态、有机得组织起来。能够真正理解这两者的转换和每一个部分的特点，才是在转型期领导人的必须职责。&lt;/p&gt;

&lt;h2 id=&quot;历史与今天&quot;&gt;历史与今天&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/history.jpg&quot; alt=&quot;&quot; /&gt;
《只有偏执狂才能生存》成书于20年前的1996年。自然，在书中用到的例子，都是来自于上个世纪70年代到90年代这一个时期。从20年后的今天来看，很多例子非常有意思。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;苹果&lt;/strong&gt;： 在书中，苹果基本上是作为负面例子出现的。书中讲，大型机到PC机的转变中，整个工业界的形态从一家公司的“大包大揽”纵向布局，也就是从硬件到软件全包的一条龙服务，过度到了横向布局，也就是一家公司专注于某个领域（例如硬件，或者软件），整个行业分工协作。在这个过程中，崛起了Intel和微软，也崛起了组装厂商Dell和HP。苹果在PC这个战场上，可以说是“起个大早赶个晚集”。格罗夫认为乔布斯过于固守苹果自己要做纵向的布局，从而在横向的竞争中，无法保持公司的先进性。90年代的苹果，也在起起伏伏中，前途未卜。然而，同样是乔布斯，同样是纵向布局思维，在10年后的2000年代，iPhone和iPad所引领的移动时代则取得了巨大成功。而在这个新的战场上，Intel和微软被抛完全被抛弃。这20多年的动态变化，不仅充满了戏剧性，而且让人深思。当然，苹果现在的成功，也恰恰说明了，没有不变的战略，在战略拐点面前，过去的经验对未来不一定具有预见性，甚至是过去失败的教训，未来也未必就一定是错的。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;电动车&lt;/strong&gt;： 格罗夫在书中提到的，所谓“已经被证明是空想”的想法中，举了电动车的例子。书中并没有展开说，为什么这是一个“彻底的失败”（Complete Failure）。不过，从今天看，最有未来前瞻性，也是最可能在不远的将来带动一个革命性变化的行业，就是Tesla引领的电动车的浪潮。今天，整个硅谷，除了Google、百度、Tesla在投身到电动车外加自动驾驶车的研发中以外，传统车行业的各个厂商也摩拳擦掌，生怕自己在这轮竞争中被淘汰。20年前，电动车也许的确是一个失败的概念，但时至今日，在经历了20年的蛰伏，电动车已经进入了千家万户。这也是一个深刻的观点，那就是过去失败的想法，未必是未来成功的阻碍。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;互联网&lt;/strong&gt;：格罗夫在书中给了互联网高度的评价，并且预测互联网能够颠覆广告业。想想这是20年前，在Google、Facebook彻底推动广告业之前能有这样的预测，足可以见到格罗夫对行业的分析能力。不过，这也从侧面说明了，即便是正确的预测，一个行业也许需要很多年时间才能够成熟。如果能够在这样的间隙内找到机会，才是所有人都需要思考的问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;《只有偏执狂才能生存》这本书值得细细品味的地方当然远远不止这些。这篇文章只是试图给大家展示几个这本书中的关键点，希望能够起到抛砖引玉的作用。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>怎样招聘一名科学家</title>
   <link href="http://column.hongliangjie.com/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/2016/05/14/hire/"/>
   <updated>2016-05-14T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/2016/05/14/hire</id>
   <content type="html">&lt;p&gt;看了&lt;a href=&quot;https://zhuanlan.zhihu.com/p/20865434&quot;&gt;韩春雨&lt;/a&gt;的事迹以后，很是感动，我于是在微博上谈论一下&lt;a href=&quot;http://weibo.com/3193816967/DuGAd9tmD&quot;&gt;简历背景是否等于一个人的成就和水平&lt;/a&gt;，里面谈及了一些在招聘科学家过程中的遇到的经历和水平的问题。后来，我感觉需要系统得总结一下招聘科学家的流程，一是为了记录下在招聘过程中的一些思考，另一方面也是为了帮助年轻学者或者博士生，能够提高自身的水平。当然，一个高水平的流程，也是对自己的一种鞭策。我时常也会想，在这样的流程里，我是否能够体现自己的能力和水平。&lt;/p&gt;

&lt;h2 id=&quot;面试的目的&quot;&gt;面试的目的&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/interview_1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在我们谈论如何建立一个快速有效的面试过程之前，我们一定要弄明白，我们究竟要招聘什么样的人才。面试的目的是让我们的需求和我们要招聘的人才之间建立一个统一。也就是说，我们的流程是为了招到我们想要的人才。对于一个科学家而言，我们关心如下这些素质：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;科研的基本水平：这里面包括如何查找相关文献；如何把一个工程问题或者是产品问题转化成科研问题，从而利用科研工具解决这个问题；如何完成完成的科研流程（比如提出解决方案，实现解决方案，做实验，写论文专利）；如何包装科研成果（比如作报告，向其他工程师讲授内容）等等方面。&lt;/li&gt;
  &lt;li&gt;工程的基本水平：虽然科学家并不是工程团队的工程师，但我们也要求我们的科学家能够理解现在公司的工程框架、代码库，能够在实现关键代码；能够做代码审核（Code Review），能够做非常接近于生产环境（Production）的原型系统（Prototype）。&lt;/li&gt;
  &lt;li&gt;交流沟通能力：能够清晰得阐述自己的观点；能够聆听别人的观点；能够起到科研成果、工程、产品之间的桥梁作用。
团队协作能力：能够在一个科研团队里能够发挥自己的作用，能够帮助团队成功，而不是只关注自己。
好奇心：能够学习新东西，有很强的自我要求。能够在短时间内学习大量的新知识。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;面试的目的是要检测出候选人在上述这些方面的一个综合表现。我们后面还会说到面试的各个环节如何考察候选人的这些素质。&lt;/p&gt;

&lt;p&gt;除了考察基本素质之外，作为招聘方，还有一个方面需要考虑的是，我们是要招一个“通才”（Generalists）还是一个“专才”（Specialist）。作为很多公司（特别是中小型公司）而言，项目、产品可能会发生反复变化，对于科学家而言，可能需要在短时间里，适应不同的项目不同的方向，这就需要招“通才”。而如果是一个成型的公司，需要在现有的基础上提高产品质量，就需要招“专才”。招聘这两种类型的人才考察的侧重点是不一样的。比如，考察“通才”重点是要看候选人是否能够对于陌生的领域问题有无好奇心、能否利用自己学习的知识分析陌生领域问题。而考察“专才”重点是要看，候选人是否在专注的领域有过硬的基础和深入的理解。&lt;/p&gt;

&lt;p&gt;说了这些细节的方针，一个总的原则是，考察候选人的&lt;strong&gt;强项&lt;/strong&gt;，看候选人&lt;strong&gt;能干什么&lt;/strong&gt;。因为很多领域都是非常广的（比如机器学习），我们其实无法要求候选人什么都懂，所以我们不是要考察这个人不懂什么，因为有很多东西不懂是很正常的，而是要考察这个人究竟懂什么，他（她）说懂的东西是不是真的懂，他（她）能否运用懂的东西去解决新问题。&lt;/p&gt;

&lt;h2 id=&quot;筛选简历&quot;&gt;筛选简历&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/interview_2.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;筛选简历是一个很需要细心的过程。对于普通的博士毕业生，我们会很快速看两个方面的信息：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;是否有高水平的论文发表
    &lt;ul&gt;
      &lt;li&gt;是专注一个问题或者一个小领域还是很多领域都有论文&lt;/li&gt;
      &lt;li&gt;第几作者&lt;/li&gt;
      &lt;li&gt;论文发表频率，是否是所有工作都是一年做出来的&lt;/li&gt;
      &lt;li&gt;论文档次&lt;/li&gt;
      &lt;li&gt;引用数&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;是否有工业界实习经历
    &lt;ul&gt;
      &lt;li&gt;是否是研究实习还是工程实习&lt;/li&gt;
      &lt;li&gt;实习的公司&lt;/li&gt;
      &lt;li&gt;是否是同一家公司还是多个公司&lt;/li&gt;
      &lt;li&gt;如果是研究实习是否有相应论文发表&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在看了这两个因素之后，我们心中对于这个候选人就有一个很基本的认识。在通常需要高标准的情况下，一个博士毕业生如果没有3-4篇第一作者的高水平论文发表（在毕业的时候，引用数在70-100左右），没有1-2次工业界实习经验，我们就不会考虑这个候选人的其他方面了。除了这两个硬指标以外，我们还会关注：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;简历里是否有一些信息不完整的部分
    &lt;ul&gt;
      &lt;li&gt;比如有一些明显断档的经历&lt;/li&gt;
      &lt;li&gt;没有本科学校&lt;/li&gt;
      &lt;li&gt;没有说明博士生导师&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;会什么编程语言和开发工具
    &lt;ul&gt;
      &lt;li&gt;是否只熟悉Matlab或者R&lt;/li&gt;
      &lt;li&gt;是否有开源项目贡献&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;是否已经有审稿经验&lt;/li&gt;
  &lt;li&gt;是否已经有组织会议的经验&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;所有这些因素都没有明显问题之后，我们已经定位到了比较靠谱的候选人（通常，只有少数人能够通过上面这轮简历筛选）。我们可以根据实际情况来调整在筛选简历这里的标准线（Bar）从而让候选人能够和我们直接交流证明自己的实力。&lt;/p&gt;

&lt;p&gt;这里再说几个比较细的准则：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;博士生的论文中，非第一作者的一般不算数&lt;/li&gt;
  &lt;li&gt;已经发表的会议论文和同一内容的期刊文章算一篇&lt;/li&gt;
  &lt;li&gt;可以有非第一档次会议或者期刊的论文，但没有第一档次的是不行的&lt;/li&gt;
  &lt;li&gt;如果有单一作者的论文，是一个比较大的问题，电话面试的时候一定要问清楚原因&lt;/li&gt;
  &lt;li&gt;课程项目原则上也不算数&lt;/li&gt;
  &lt;li&gt;简历是LaTex生成还是Word&lt;/li&gt;
  &lt;li&gt;毕业学校和GPA，一般不是很侧重要考虑的问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;再说几个对于已经有工作经验的候选人的简历筛选要素：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;如果有教职经验或者博士后经验，原则上是一个大问题，需要电话面试问清楚&lt;/li&gt;
  &lt;li&gt;一两年左右频繁换公司是一个大问题，需要电话面试问清楚&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这里要多说一句的是，上面这些标准是对计算机相关专业比较适用的准则。而对于数学、应用数学、统计、物理等等专业的人来说，可能有些标准需要重新设定（比如发表论文的标准需要降低）。总之，这里说的是一些比较大的方向，不过在把握了这些原则之后，我们就可以安排少量的候选人电话面试了。&lt;/p&gt;

&lt;h2 id=&quot;电话面试&quot;&gt;电话面试&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/interview_3.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在经过筛简历的过程后，电话面试的目的是要看这个候选人是不是像简历里所说的那样有相应的经历。当然，有一些公司在电话面试的时候也会考察候选人解决问题的能力，这也是很经常发生的安排。一般对于科学家的职位，我们需要2-3轮电话面试，包括了解下面这些信息：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;了解候选人简历上的基本信息，如果简历上有疑点，需要在这个阶段问清楚&lt;/li&gt;
  &lt;li&gt;考察候选人是否能够有基本的专业知识和相关领域的见解，考察候选人是否有其他领域的知识&lt;/li&gt;
  &lt;li&gt;考察候选人是否有基本的专业相关的编写代码的能力&lt;/li&gt;
  &lt;li&gt;体会候选人的表达能力，英语水平&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在询问候选人的简历信息的时候，有这些内容是需要弄明白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对于候选人是第一作者的论文，候选人是否能够很清晰说出这些论文的解决问题、思路。在进一步的沟通里，候选人是否能够讲清楚模型细节甚至是公式细节。候选人能够把实验的目的、数据、比较算法讲清楚。当然，这需要面试官做提前准备。同时，询问候选人其他作者在这篇论文中的贡献。&lt;/li&gt;
  &lt;li&gt;对于候选人是非第一作者的论文，询问候选人在这个工作中起到了什么作用。看候选人是否诚实可信，也可以看出候选人的学术道德水平。&lt;/li&gt;
  &lt;li&gt;对于单一作者的文章，需要候选人解释为什么这个工作没有合作人，博士生导师为什么不是合作者，这个论文的研究时间如何而来。&lt;/li&gt;
  &lt;li&gt;对于有博士后经验或者教职经验的候选人，要询问候选人是否分得清楚工业界研究和学术界研究的区别，要询问候选人如果以后有机会，是否还考虑学术界教职。&lt;/li&gt;
  &lt;li&gt;对于有工作经验的候选人，要询问候选人反复换工作的原因，询问清楚候选人在项目里的具体贡献，要询问候选人的职业规划，看职业规划和简历经历是否能够吻合。对于在某一个公司待了很长时间没有升职的候选人，也需要询问一下为何在旧公司里没有其他机会。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在考察候选人专业知识的时候，有这些内容需要弄明白：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对于某一专业最基础的一些概念和知识，候选人是否能够清晰地讲解出来。这一条其实很多人很难做到。不少人能够做复杂的工作，却往往在最基础的内容上含混不清。而在一些跨领域的工作中，基础知识往往是一个科学家所能够依赖提供解决方案的最初的工具。所以，基础很重要。&lt;/li&gt;
  &lt;li&gt;候选人是否诚实说明自己懂什么，不懂什么。在广泛的领域里，科学家应该有足够的自信说自己的专长是什么，自己的局限在哪里。&lt;/li&gt;
  &lt;li&gt;候选人是否对跨领域知识一窍不通，还是略有知晓，界限在哪里。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;在考察编程水平方面，虽然很多公司已经有比较完备的方案考察软件工程师，但这些题目和考察目的其实不太适合科学家。这需要公司专门针对科学家制定一些考察题目。关于这方面的探讨，我以后还会专门写文章。&lt;/p&gt;

&lt;p&gt;在上述考察候选人各个方面的过程中，一个贯穿始终的主题就是要看候选人是不是能和面试人员进行有效的沟通。当然，也要考虑到，有人可能不太适应电话面试，而在面对面的交流时则毫无问题。&lt;/p&gt;

&lt;h2 id=&quot;现场面试&quot;&gt;现场面试&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/interview_4.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在经历了简历筛选的流程和电话面试之后，我们已经对候选人有了一个初步的了解：他（她）的背景、熟悉以及不熟悉的领域、编程能力和沟通能力。对于各方面都表现不错的候选人，我们一般就会安排到公司来进行现场面试。对于科学家岗位，现场面试一般包括下面这些环节：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;一场一个小时左右的学术报告会&lt;/li&gt;
  &lt;li&gt;和招聘经理讨论可能的项目方向&lt;/li&gt;
  &lt;li&gt;和其他科学家、工程师讨论技术和研究问题&lt;/li&gt;
  &lt;li&gt;和人事讨论职位的其他问题&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;学术报告会是考察候选人学术水平的一个非常重要的环节。因为简历和电话面试都无法系统得看出候选人的整个学术生涯的特征（是偏理论、偏应用，是到处蜻蜓点水似的研究，还是专注某几个问题）。一场报告会，候选人必须能够在逻辑上提供一个链条把自己的学术成果贯穿起来。好的候选人的整个学术生涯都有清晰明确的线条。同时，报告会还是观察候选人是否有清晰的语言组织能力和表达能力的很好机会。有一些候选人连自己的工作都讲不清楚。另外一个需要考察的就是，候选人是否能够在公开场合接受各种质疑和对自己工作的挑战，包括候选人是否能够承认自己工作的局限性和不足，候选人能否礼貌但“到点”（To-The-Point）地回答技术问题。&lt;/p&gt;

&lt;p&gt;对于和招聘经理讨论可能的项目方向，很多候选人显得很随意，觉得这就是闲聊。其实这也是观察候选人和考察候选人的一个很重要的机会。首先，招聘经理可以说一些公司的产品或是项目，看看候选人是否有兴趣，看看候选人是否能够通过一些简单的产品介绍，问出一些有科学价值的问题。会问问题，其实是一个非常重要的技能。招聘经理也可以在稍微深入得讨论一些产品的一两个具体的现实问题，看候选人能否快速说出一些解决方案或者是一些思路。在整个谈话中，可以体会出候选人是否只有学术的经验而没有任何产品和产业的“感觉”（Sense）。有一些候选人在这个阶段会显得没法把谈话进行下去，完全是倾听问不出任何问题。这就需要招聘经理仔细控制谈话来看候选人是否对新事物有好奇心，是否能够跟上思路，对新领域新问题有快速的思考。&lt;/p&gt;

&lt;p&gt;和参加面试的科学家以及工程师讨论研究问题，主要考察的是候选人在一个类似工作的环境里能否&lt;strong&gt;半&lt;/strong&gt;独立得完成科研解决方案的设计和实现。为什么说“半”，是因为这个环节里，沟通也是很重要的，很多条件、约束和限制都需要候选人和面试人员进行有效沟通来得以清晰化。因此，候选人面对的并不是完全“应用题”似的独立解决问题场景。这里的通常形式是，面试人员针对某个具体的问题，询问候选人如何提供一个有效的科学解决方案。这里面需要注意的环节有：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;候选人是否能够问出有效的问题，这些问题是不是在帮助候选人自己减少问题的不确定性，帮助候选人自己寻找答案，还是漫无目的地问各种问题。&lt;/li&gt;
  &lt;li&gt;候选人是不是不假思索得就提供一些思路，然后没有认真思考以后又更换思路，反反复复。这是候选人没有系统思维能力的一个体现。&lt;/li&gt;
  &lt;li&gt;候选人的整体思维模式是怎样的
    &lt;ol&gt;
      &lt;li&gt;先提出一个也许可以解决的多步骤的方案，然后看是否能够简化步骤，然后看能否提出比较规范的数学模型&lt;/li&gt;
      &lt;li&gt;先提出比较完整的数学模型，然后能够根据实际情况简化，提出更加快速的算法&lt;/li&gt;
    &lt;/ol&gt;

    &lt;p&gt;这两种思维模式都是行之有效的思维方式。但是也有候选人在两者之间踌躇，一方面提不出“丑陋一点”的解决方案，一方面完整的数学模型也写不出来。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;候选人能否在提出基本方案或者是数学模型之后，能够用自己掌握的方法把问题的细节算法写出来，并且能够分析算法的各方面特征。这考察的是候选人解决问题连贯性和独立性。有一些候选人的确能够漂亮的写出数学模型，但是可能完全没法把模型给算法化，写出来的程序惨不忍睹。&lt;/li&gt;
  &lt;li&gt;还有一个需要考察的维度就是，候选人遇到领域之外的问题，是如何思考的。有的候选人就彻底懵了，完全不能理性化得提出任何方案。而有的候选人则会小心翼翼利用基础知识去尝试解决问题；或者是把新领域的问题转化成自己熟悉的问题。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;值得注意的是，在这个环节中表现不好的候选人，不管过去的论文、学校、导师经历多么优秀，都要打一个大问号，而事实证明，往往在这个阶段不那么令人满意的候选人，在现实工作中也很难胜任实际的工作。&lt;/p&gt;

&lt;p&gt;对于有经验的候选人，这部分的考察重点除了刚才说的解决方案本身以外，还可以看候选人是否有&lt;strong&gt;全局观&lt;/strong&gt;，比如如何设计更加有效的数据通路；比如没有数据怎么办；比如上线以后系统表现不好怎么办。&lt;/p&gt;

&lt;p&gt;有一个需要观察的就是，候选人的表现是否在有压力或者劳累（毕竟一天的现场面试是很累的）的情况下有重大波动。优秀的候选人能够通过沟通来缓解自己的压力。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;本篇文章简单得总结了招聘科学家的流程，希望能够对于需要招聘科学家的公司有一个抛砖引玉的作用，也希望能够对于找工作的博士们或者已经有工作经验的人有帮助。招聘有时候就像恋爱，也讲感觉，也讲契合度。同时，一个规范的流程只是找到合适人才的一个部分，对于如何挖掘如何考察一个人的水平还有很多方面的工作要做。&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>新闻推荐，追逐卡戴珊的“屁股”</title>
   <link href="http://column.hongliangjie.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/23/news-recsys/"/>
   <updated>2016-04-23T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/23/news-recsys</id>
   <content type="html">&lt;p&gt;前一阵子，有一篇新闻文章叫&lt;a href=&quot;http://www.businessinsider.com/yahoo-reporters-frustrated-competing-against-kim-kardashians-ass-2016-4&quot;&gt;“雅虎记者的困扰：与卡戴珊的屁股竞争”&lt;/a&gt;，讲的是雅虎公司的一群高级记者所写的文章与推荐系统所推荐的文章相互竞争协调的事情，里面提到的现象可能很多做推荐系统开发的人都感同身受，似曾相识。那么今天，我们不谈具体的公司具体的案例，而来聊一下推荐系统开发中遇到“&lt;strong&gt;推荐结果和自己的直觉不相符合怎么办&lt;/strong&gt;”这个事情该怎么办。&lt;/p&gt;

&lt;h2 id=&quot;记者和编辑的抱怨&quot;&gt;记者和编辑的抱怨&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;你是一个内容平台（网站或者是App）的推荐系统工程师，在忙了好几个月之后，最新的个性化新闻推荐系统终于上线了。你满心欢喜得看着最新的系统推动着各类指标上扬，正在为自己的又一个成就而感到高兴。这时候，产品经理发来邮件，说公司的一些高级编辑对现在推荐结果非常不满意。具体说来，就是这些高薪聘请的编辑发现自己的文章没法占据推荐的头条了，于是认为新系统“不和谐”。下面一个步骤，往往是产品经理屈从于高级编辑的一些意见，希望推荐系统能够在编辑撰写的文章和算法推荐的文章中达到一个平衡。而你，作为工程师，觉得这是一种侮辱，不愿意这么做。&lt;/p&gt;

&lt;p&gt;很多做算法和模型的工程师，特别是推荐领域的，一般很难理解或者是很难推崇编辑的作用。一方面，这是因为工程师并不清楚编辑究竟能为系统带来什么，另一方面也在于专业训练中，模型基本上都是优化&lt;strong&gt;用户体验&lt;/strong&gt;的。显然，几个编辑，很难说就代表了广大用户群的需求。于是，工程师和编辑之间的矛盾自然就产生了。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/news_editor.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;说到底，这种矛盾主要还是是价值观的差别。编辑，从内容生产者（Producer）的角度来思考问题，长期持有的态度是&lt;strong&gt;我想要用户看什么&lt;/strong&gt;。特别是从比较强势的传统媒体培养起来的人，这样的观念尤为明显。在这样的价值观导向下，内容平台往往成为了某一些编辑的价值传输筒，因此选择的内容常常带有很强烈的主观色彩。工程师，则喜欢从&lt;strong&gt;用户想要看什么&lt;/strong&gt;的角度入手，从内容消费者（Consumer)的角度来看问题，优化广大用户的体验。工程师更相信数据、相信代码，不喜欢价值观导向。乍一看，现代的内容推荐系统应该尽量避免编辑的干扰，从指标优化的角度来把内容推荐完全看成是工程问题，减少主观因素。&lt;/p&gt;

&lt;p&gt;然而，现实中，这样做，对于一个推荐系统来说，可能有很差的实际效果。原因是这样的，现在用户喜欢的取决于你给用户之前看了什么，你没给用户看过的，用户因为不知道，所以没法给你反馈是否喜欢。这在之前的文章“&lt;a href=&quot;/%E4%B8%AA%E6%80%A7%E5%8C%96,%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/07/personalization-or-not/&quot;&gt;个性化推荐是不是伪命题&lt;/a&gt;”和“&lt;a href=&quot;/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/13/exploration/&quot;&gt;论推荐系统的Exploitation和Exploration&lt;/a&gt;”中都有详细的阐述。核心思想，就是要有一个机制，使得用户的现在喜好和系统的长期健康运行得到平衡。这方面，编辑的作用就可以得到体现了。比如，一个新闻网站，娱乐新闻一定是最吸引眼球的。那么，是不是只给用户看这类的新闻呢？即便作为工程师和产品经理，你知道显示这类的新闻，访问量会长期爆表，但这可能对网站的长期发展是不利的（下面会提到一个问题）。于是，你就想在牺牲流量的情况下，放一些其他的内容。这时候，编辑就是最适合寻找或者原创这样内容的人选。实际上，编辑选择的内容，可以很好得融合到Exploitation &amp;amp; Exploration策略的Prior Knowledge里面，使得Exploration不至于过于“荒腔走板”。&lt;/p&gt;

&lt;p&gt;编辑另一个很重要角色还在于处理突发事件的时候，比一个机器学习驱动的推荐系统要有效得多。在那个时候，数据中还没有很多的强信号，很难知道某个突发事件之后的流行程度。于是，编辑可以在第一时间，绕过现有的机器学习系统，为一些新闻的抢先报道，赢得时间。&lt;/p&gt;

&lt;h2 id=&quot;用户群和格调的错位&quot;&gt;用户群和格调的错位&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;当你开发了一款百万人亦或是千万人使用的新闻推荐系统之后，你一方面可能醉心于不断创新高的报表数据，另一方面，你可能会觉得推荐的文章充斥娱乐花边新闻庸俗不堪。有时候，作为产品经理，你甚至会对工程和算法团队产生深刻的质疑，希望产品“格调”能够有所提高。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/reading.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;前面一小节已经从&lt;em&gt;战术&lt;/em&gt;层面来探讨了这种情况下如何协调编辑和工程师。那么，作为产品经理来说，战略上怎么办呢？这里面最关键的点，是&lt;strong&gt;你产品的盈利模式所需要的人群和你产品目前的使用人群之间，究竟是否有错位&lt;/strong&gt;，如果有，会不会是致命的。&lt;/p&gt;

&lt;p&gt;举一个简单的例子，你的网站是一个依靠广告收入的媒体平台。通过后台数据分析，你知道，点击广告和对广告内容有转化（Conversion）的群体是年龄30-50岁的小城镇人口，并且在这个年龄段里，女性的点击率还要高于男性。然而，你网站的新闻则吸引的是18-30岁的大城市人口，其中20-25岁人的点击量是最多的。于是，这就产生了一组矛盾。一方面，你网站有很高的点击率，而且依靠推荐系统的推荐结果（学习用户行为）进一步强化了现在高频使用人群的行为。而另一方面，贡献你网站收入来源的群体则有可能会被推荐结果所忽视，甚至被赶走。&lt;/p&gt;

&lt;p&gt;所以这时，是一个很需要多个部门联合考虑的决策。有两个很显然的方向，第一，保持住现在的内容消费群体，尝试引入（Onboard）适合这个群体的广告商；第二，保持住现在的广告消费群体，尝试冷启动（Cold-Start）一些有可能对现在广告消费群体感兴趣的内容。&lt;/p&gt;

&lt;p&gt;决策一的不易之处是，广告商有时候是通过销售以及其他相对成本比较高的方式获得的，很难轻易更换。产品经理可以采取的方法是，开始接洽和寻找是否有可能扩展广告商群体。这是一个长期的过程。决策二的不易之处在于，如何能够找到广告消费用户所喜欢的内容，也许这些内容根本就在你的网站上不存在。于是，这里面存在要去获取（Acquire）内容的情况。这也很不容易，牵涉到“获取啥”和“到哪儿找”的问题。&lt;/p&gt;

&lt;p&gt;第三个维度，需要产品经理考虑的是，根据产品的原始定位，也许产品需要的目标人群和现在内容以及广告消费人群均有差距。那么，这个时候，需要内容策略和广告策略都要调整，而且还牵涉到用户群的获取问题（Acquisition），则决策更加不易。&lt;/p&gt;

&lt;p&gt;值得注意的是，这小节讨论的问题，都是&lt;strong&gt;用户群体&lt;/strong&gt;的错位问题，而不是产品经理或者工程师自己对产品结果的感官问题。因为产品经理或者工程师很可能既不是产品的内容消费群体也不是产品的广告消费群体，很容易这个时候主观代入，产生&lt;strong&gt;我认为内容应该什么样&lt;/strong&gt;的问题。&lt;/p&gt;

&lt;h2 id=&quot;个性化的重要性&quot;&gt;个性化的重要性&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;前面两节谈了比较&lt;em&gt;抽象&lt;/em&gt;的产品战术和战略的问题，这一节我们谈一点具体的技术问题。虽然在之前的文章“&lt;a href=&quot;/%E4%B8%AA%E6%80%A7%E5%8C%96,%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/07/personalization-or-not/&quot;&gt;个性化推荐是不是伪命题&lt;/a&gt;”中，我们已经谈论过，推荐结果“千篇一律”的问题。但“推荐结果不符合你的预期”依然有可能是建模和算法出了问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/personalized.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;比较常见的一个误区是，推荐系统通过学习用户行为能够&lt;em&gt;自动&lt;/em&gt;对用户做个性化推荐。比如流行模型Latent Factor Model&lt;sub&gt;[1]&lt;/sub&gt;，或者Factorization Machine&lt;sub&gt;[3]&lt;/sub&gt;，虽然能够对用户进行推荐，但是推荐结果很可能不是真正个性化的。这里面的一个问题是，这些模型都是通过优化一个&lt;strong&gt;平均情况&lt;/strong&gt;来学习模型参数的。也就是说，通常情况下，一个比较好的模型是能够“解释”大多数用户的行为，但不一定在某一些个别用户上有比较优异的表现。学习出来的模型往往是保住了“大部分”用户的准确度而牺牲了少部分用户。&lt;/p&gt;

&lt;p&gt;当然，上面这个解释其实有可能是非常不对的。因为模型有可能是对用户交互数据进行建模，而绝大多数的数据则可能是少部分用户产生了大部分数据（一些用户“狂”点某一部分内容），于是模型倾向于&lt;em&gt;过度&lt;/em&gt;解释这部分数据。而大多数用户并没有产生很多交互数据，于是模型就倾向于忽略这部分所可能产生的错误。所以，真实情况可能是，小部分人满意了，而大部分人被牺牲了。&lt;/p&gt;

&lt;p&gt;目前对于这方面的问题，学术圈和工业圈其实并没有比较标准的方案。去年NIPS Workshop中有一篇文章&lt;sub&gt;[2]&lt;/sub&gt;谈论了一些探索。不过，依然，如何衡量一个系统已经充分个性化，如何真正学习个性化模型，还是有待于解决的问题。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;本篇文章讨论了推荐系统中，推荐结果不满意的情况。文章展开说了编辑和工程师的关系，以及产品经理要在不满意的推荐结果面前做怎样的决策。最后，我们也分析了推荐模型的问题，提出了改进的方向。&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;
&lt;hr /&gt;
&lt;ol&gt;
  &lt;li&gt;Deepak Agarwal and Bee-Chung Chen. 2009. &lt;strong&gt;Regression-based latent factor models&lt;/strong&gt;. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, USA, 19-28.&lt;/li&gt;
  &lt;li&gt;Daniel Crankshaw, Xin Wang, Joseph Gonzalez and Michael Franklin. &lt;strong&gt;Scalable Training and Serving of Personalized Models&lt;/strong&gt;. NIPS Workshop 2015.&lt;/li&gt;
  &lt;li&gt;Steffen Rendle. &lt;strong&gt;Factorization Machines with libFM&lt;/strong&gt;. ACM Transactions on Intelligent Systems and Technology (TIST) 3, 3, Article 57 (May 2012), 22 pages.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>论推荐系统的Exploitation和Exploration</title>
   <link href="http://column.hongliangjie.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/13/exploration/"/>
   <updated>2016-04-13T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/13/exploration</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;/%E4%B8%AA%E6%80%A7%E5%8C%96,%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/07/personalization-or-not/&quot;&gt;上一篇文章&lt;/a&gt;讲到，一个推荐系统，如果片面优化用户的喜好，很可能导致千篇一律的推荐结果。文中曾经用了一节来讨论为什么使用Exploitation &amp;amp; Exploration (E &amp;amp; E)结果可能依然不能“免俗”。其实，E &amp;amp; E是推荐系统里很有意思，但也非常有争议的一个算法。一方面，大家都基本明白这类算法的目的，每年有很多相关论文发表。另一方面，这是工业界对于部署这类算法非常谨慎，有的产品经理甚至视之为“洪水猛兽”。这篇文章就是要分析一下导致这个现象的一些因素。&lt;/p&gt;

&lt;h2 id=&quot;走一步看一步的策略&quot;&gt;走一步看一步的策略&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;这里再简单阐述一下什么是E &amp;amp; E。简单来说，就是我们在优化某些目标函数的时候，从一个时间维度来看，当信息不足或者决策不确定性（Uncertainty）很大的时候，我们需要平衡两类决策：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;选择现在可能最佳的方案&lt;/li&gt;
  &lt;li&gt;选择现在不确定的一些方案，但未来可能会有高收益的方案&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在做这两类决策的过程中，我们也逐渐对所有决策的不确定性不断更新不断加以新的认识。于是，&lt;strong&gt;最终&lt;/strong&gt;，从时间的维度上来看，我们在不确定性的干扰下，依然能够去&lt;strong&gt;优化&lt;/strong&gt;目标函数。&lt;/p&gt;

&lt;p&gt;也就是说，E &amp;amp; E可以看做是一个&lt;em&gt;优化过程&lt;/em&gt;，需要多次迭代才能找到比较好的方案。&lt;/p&gt;

&lt;h2 id=&quot;e--e的应用历史&quot;&gt;E &amp;amp; E的应用历史&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;早期把E &amp;amp; E应用于新闻推荐系统的文章（比如&lt;sub&gt;[1,2,4]&lt;/sub&gt;）主要关注于Yahoo Today Module（下图中间的模块）这一产品，这也基本上是最早E &amp;amp; E出现在互联网应用的尝试，目的是为了优化点击率（CTR）。而更早一些的奠基性的文章（如&lt;sub&gt;[3]&lt;/sub&gt;）则是在广告的数据集上展示的实验结果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/yahoo_today.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Yahoo Today Module其实为E &amp;amp; E提供了一些很多学者和工业界人士忽视了的条件和成功因素。如果不考虑这些因素，鲁莽得使用这些文献相似的算法到其他场景，这可能产生很差的效果。那么是哪些因素呢？主要由两点：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;相对少量的优质资源&lt;/strong&gt;： Yahoo Today Module每天的Content Pool其实并不大。这里面都是网站编辑精选了的大概100篇文章。这些文章原本的质量就非常高。无论是这里面的任何一组，用户体验都没有明显变差。Content Pool每天都人为更换。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;非常大的用户量&lt;/strong&gt;：有亿万级的用户可能最终是从算法&lt;em&gt;随机&lt;/em&gt;产生的文章排序中选择了阅读的文章。然而，因为用户数量巨大，所以算法就相对比较容易Converge到稳定的方案。也就是前面讲的，优化CTR的状态。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;正因为有了（1）和（2），Deepak他们享受了在后来学者们所无法想象的“奢侈”，比如运行Epsilon-Greedy这种简单粗暴的E &amp;amp; E算法，甚至是&lt;strong&gt;完全随机&lt;/strong&gt;显示新闻，收集到了很多&lt;em&gt;无偏&lt;/em&gt;（Unbiased）的数据，为很多学术工作奠定了数据基础。时至今日，也有很多后续学者基于Yahoo Today Module的随机数据进行算法改进。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Deepak Agarwal，现任LinkedIn VP Of Engineering，主管Machine Learning和Relevance，是早年Yahoo推荐系统的缔造者之一，也是推荐系统的学术权威之一。其著作《Statistical Methods for Recommender Systems》是初学者必不可少的入门教材。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Bee-Chung Chen，现任LinkedIn Senior Staff Software Engineer，其PhD导师Raghu Ramakrishnan现在是微软的CTO for Data和Technical Fellow（此人是早期知识图谱Knowledge Graph概念的推崇者）。Bee-Chung是Deepak在Yahoo年代的老部下，并且追随其到LinkedIn。他们是很多工作的共同作者。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;Lihong Li，现任微软研究院资深研究员。其在Yahoo的一系列有关Contextual Multi-Armed Bandit以及Thompson Sampling的文章奠定了其在这个领域的权威位置。他在WSDM 2015做的关于如何连接线下和线上系统的评估的讲座&lt;sub&gt;[5]&lt;/sub&gt;，是非常有价值的学术资料。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;没有了这两条因素，Deepak的解决方案可能都没法在当时的Yahoo施行。原因很简单，如果资源良莠不齐，如果资源数量非常大，那么在仅有的几个展示位置，优质资源显示的可能性在短期内就会比较小（因为系统对于大多数的资源还有很高的不确定性，需要Explore）。而由于优质资源显示得少了，用户就会明显感受到体验的下降，直接可能就是更倾向于不点击甚至放弃使用产品。于是用户不Engage这样的行为又进一步减缓了系统学习资源的不确定性的速度。这时也许现在的亿万级用户数都没法满足学习所有资源的用户数量（毕竟所有用户只有一部分会落入Exploration）。&lt;/p&gt;

&lt;p&gt;Deepak后来在LinkedIn推了相似的思路&lt;sub&gt;[6]&lt;/sub&gt;，但是为了模拟Today Module的这些条件，则是对用户的内容流里的数据进行了大规模的过滤。这样只有少数的信息符合高质量的要求，并且能够在用户数允许的情况下Explore到合适的解决方案。&lt;/p&gt;

&lt;h2 id=&quot;e--e的产品部署难点&quot;&gt;E &amp;amp; E的产品部署难点&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;我们在上一节探讨了E &amp;amp; E的早期产品历史。这一节，我们来讲一下E &amp;amp; E的产品部署难点。这些难点是普遍高于具体E &amp;amp; E算法选择（比如选某一个UCB或者某一个Thompson Sampling)的产品工程解决方案的抉择。为了便于讨论，我们把文献里所有E &amp;amp; E算法整体叫做“Random”简称R算法，而把不做E &amp;amp; E的算法叫做“Deterministic”简称D算法。这里面的假设是，D算法比较静态，能够产生高质量&lt;strong&gt;一致性&lt;/strong&gt;的内容。这里的一致性是指用户在短时间内的用户体验比较稳定，不会有大幅度的界面和内容变化。相反，R算法整体来说是不确定性比较大，用户体验和产生的内容可能会有比较大的波动。&lt;/p&gt;

&lt;h3 id=&quot;难点一如何上线测试&quot;&gt;难点一：如何上线测试&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;这看上去不应该是难点，但实际上需要额外小心。传统E &amp;amp; E文献，只是把问题抽象为每一次访问需要做一个决策的选择。然而，文献却没有说，这些访问是否来自同一个用户。那么，理论上，E &amp;amp; E应该对所有的访问不加区别，不管其是否来自同一个用户。用我们这篇文章的术语来说，就是所有的流量都做R算法。虽然理论上这样没有问题，但实际上，用户体验会有很大的差别。特别是一些推荐网站，用户希望自己前后两次对网站的访问保持&lt;strong&gt;一致性&lt;/strong&gt;。如何不加区分得做R，很可能对于同一个用户来说，两次看见的内容迥异。这对用户熟悉产品界面，寻找喜爱的内容会产生非常大的障碍。&lt;/p&gt;

&lt;p&gt;那么，我们对绝大部分用户做D，对另外一（小）部分用户做R，这样会好一些吗？这其实就是用“牺牲”少部分用户的代价来换取绝大多数人的体验一致性。这样实现也是最直观的，因为很多在线系统的A/B测试系统是根据用户来进行逻辑分割的。也就是说，某一部分用户会进入一个Bucket，而另一批用户会进入另外一个Bucket。按用户来做D &amp;amp; R可以很容易和Bucket System一致起来，方便部署。当然，这样做也是有潜在风险的。那就是，这部分老做R的用户，在当了别人的小白鼠以后，很可能永远放弃使用产品。&lt;/p&gt;

&lt;p&gt;另外，我们还需要考虑“学习流程”（Learning Procedure）如何搭建。传统的E &amp;amp; E其实是把“学习流程”搭建在同一批流量上。也就是，模型更新所依赖的数据来自于同样一批流量。融合上面的讨论以后，我们可以总结出下面这些方案：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;全部流量做R，全部流量做学习。（方案A）&lt;/li&gt;
  &lt;li&gt;一部分用户做D，其他用户做R。更新D的数据来自D，更新R的数据来自R。（方案B）&lt;/li&gt;
  &lt;li&gt;一部分用户做D，其他用户做R。更新D的数据来自D+R，更新R的数据来自R。（方案C）&lt;/li&gt;
  &lt;li&gt;一部分用户做D，其他用户做R。更新D的数据来自D+R，更新R的数据来自D+R。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;最后一个方案其实是逻辑上不对的。因为R本身要求算法的回馈是来自R的决策，而使用D+R来学习模型，就产生了R的反馈信息被“污染”的现象。所以，合理的选择只能是前三种方案中的一种。&lt;/p&gt;

&lt;p&gt;如何选择一个好的部署模式，目前并没有公开的文献以及比较能够通用的方案。这方面其实是一个值得思考的研究课题。&lt;/p&gt;

&lt;h3 id=&quot;难点二如何评测&quot;&gt;难点二：如何评测&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;对现代推荐系统（以及很多类似系统）来说，在线系统的评测，也就是说如何衡量一个算法或者一个功能的好坏，往往依赖于复杂的A/B测试系统。这里的逻辑很简单，那就是，把一群人分为&lt;strong&gt;相等&lt;/strong&gt;的两份（可以扩展到多份），一部分看A系统结果，另一部分人看B系统结果，然后根据一些用户指标（比如点击率）来决定究竟是A系统好还是B系统。也就是说，A/B测试系统是按照人群来分的。对于同一个人来说，在某一段时间内，一般是只能看到A&lt;strong&gt;或者&lt;/strong&gt;B系统，但&lt;strong&gt;不&lt;/strong&gt;是&lt;strong&gt;都&lt;/strong&gt;能看见。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ab_testing.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;我们来讨论一下前一节的几个方案在评测方面的利弊。方案A要求全部流量做R，于是这个方案，依照定义，就没法和其他D作比较，只能两种不同的R相比。由于R对于用户体验上来说一般是有损失的，只能比较R和R，造成了没法量化整体系统的用户体验损失量，这可能是无法接受的一种局面。&lt;/p&gt;

&lt;p&gt;方案B的设置很自然，可以比较单组或者多组D和R的差别，互相没有影响。坏处当然就是所有D部分的用户都没有Exploration，而R的部分可能流失用户。方案C没法直接评测，因为一个Bucket的D受到了R的影响。两个Bucket不独立。我们至少需要四个Bucket。一组Bucket是D1+R1，另外一组Bucket是D2+R2。在比较Bucket Performance的时候，我们需要综合比较(D1+R1)和（D2+R2）。这当然对A/B Testing系统有了较高的要求。&lt;/p&gt;

&lt;p&gt;另一方面，对于方案B和方案C来说，R只运行在一部分用户上，模型可能需要很长的时间学习，甚至在规定的时间内没法完成学习。这就需要加大R的部分。然而加大R，则可能流失用户。于是，这里的决策核心就是D部分留住的老用户加上扩展的新用户，能否大大超过R部分流失的用户。&lt;/p&gt;

&lt;h3 id=&quot;难点三如何平衡产品&quot;&gt;难点三：如何平衡产品&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;通过前面两个难点可以看出，E &amp;amp; E&lt;strong&gt;几乎一定&lt;/strong&gt;会导致产品的用户体验下降，至少在短期内。如何弥补这一点，技术上其实比较困难。比如做Deepak那样的过滤是一种思路，那就是只在优质内容里Explore。当然，有人会说，这样其实也没有多大的意义。然而，一旦把质量的闸门打开了，那就会对用户体验带来很大的影响。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/pm.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;这也是很多产品经理对于E &amp;amp; E非常谨慎的原因。能不做就不做。而且，在牺牲了用户体验的结果后，E &amp;amp; E所带来的好处其实很难评测，这主要是线上产品的评测机制和评测原理所决定的。目前还没有比较统一的解决方案。如何能够做到“用户友好型”E &amp;amp; E呢？&lt;/p&gt;

&lt;p&gt;这里面可以有两种思路：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;不是所有人群的所有访问都适合做R。但是和传统的E &amp;amp; E不同的是，做“反向E &amp;amp; E”。也就是说，我们只针对非常Engaged的人做Exploration，而并不是新用户或者是还没有那么Engaged的人群。这个思路是和现在E &amp;amp; E完全相反，但是更加人性化。&lt;/li&gt;
  &lt;li&gt;夹带“私货”。也就是更改E &amp;amp; E的算法，使得高质量的内容和低质量的内容能够相伴产生，并且高质量的内容更有几率排在前面。这样用户体验的损失可控。这个思路我们在&lt;sub&gt;[7]&lt;/sub&gt;里有所尝试，效果不错。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;其实，E &amp;amp; E和产品的结合点应该是工程和研究的重点，但很遗憾的是，碍于数据和其他方面的因素，这方面的研究工作几乎没有。&lt;/p&gt;

&lt;h2 id=&quot;可以挖掘的问题&quot;&gt;可以挖掘的问题&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;前面说了E &amp;amp; E在工程部署以及产品上的难点。这里再提及一下E &amp;amp; E可以挖掘的方向：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;“收集数据”，作为Causal Inference中消除现在产品的“偏见”（Bias）的重要步骤&lt;sub&gt;[8,9]&lt;/sub&gt;，这方面的工作还比较少，还没有在推荐系统里广泛使用。&lt;/li&gt;
  &lt;li&gt;用户友好型的E &amp;amp; E方案（前面已经提及了），能够在尽可能少的情况下打扰用户，学到尽可能多的信息。这方面目前不是学术圈的重点，但却是工程产品方面非常需要的解决方案。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;本篇文章讨论了推荐系统中Exploitation和Exploration的使用，分享了这方面的历史，探讨了工程和产品的技术难点，希望这篇文章能够为相关方向抛砖引玉。&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;
&lt;hr /&gt;
&lt;ol&gt;
  &lt;li&gt;Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. &lt;a href=&quot;http://www.research.rutgers.edu/~lihong/pub/Li10Contextual.pdf&quot;&gt;&lt;strong&gt;A Contextual-Bandit Approach to Personalized News Article Recommendation&lt;/strong&gt;&lt;/a&gt;. In Proceedings of WWW 2010.&lt;/li&gt;
  &lt;li&gt;Deepak Agarwal, Bee-Chung Chen, Pradheep Elango. &lt;a href=&quot;http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;amp;arnumber=5360225&quot;&gt;&lt;strong&gt;Explore/Exploit Schemes for Web Content Optimization&lt;/strong&gt;&lt;/a&gt;. In Proceedings of ICDM 2009.&lt;/li&gt;
  &lt;li&gt;John Langford, Alexander Strehl, and Jennifer Wortman. &lt;a href=&quot;http://dl.acm.org/citation.cfm?doid=1390156.1390223&quot;&gt;&lt;strong&gt;Exploration Scavenging&lt;/strong&gt;&lt;/a&gt;. In Proceedings of ICML 2008.&lt;/li&gt;
  &lt;li&gt;Lihong Li, Wei Chu, John Langford, and Xuanhui Wang. &lt;a href=&quot;http://www.gatsby.ucl.ac.uk/~chuwei/paper/wsdm11.pdf&quot;&gt;&lt;strong&gt;Unbiased Offline Evaluation of Contextual-Bandit-Based News Article Recommendation Algorithms&lt;/strong&gt;&lt;/a&gt;. In Proceedings of WSDM 2011.&lt;/li&gt;
  &lt;li&gt;Lihong Li. &lt;a href=&quot;http://research.microsoft.com/pubs/240388/tutorial.pdf&quot;&gt;&lt;strong&gt;Offline Evaluation and Optimization for Interactive Systems&lt;/strong&gt;&lt;/a&gt;。 In Proceedings of WSDM 2015.&lt;/li&gt;
  &lt;li&gt;Deepak Agarwal. &lt;a href=&quot;http://www.ueo-workshop.com/wp-content/uploads/2013/10/UEO-Deepak.pdf&quot;&gt;&lt;strong&gt;Recommending Items to Users: An Explore/Exploit Perspective&lt;/strong&gt;&lt;/a&gt;. In Proceedings of the 1st Workshop on User Engagement Optimization at CIKM 2013.&lt;/li&gt;
  &lt;li&gt;Liangjie Hong and Adnan Boz. &lt;a href=&quot;http://arxiv.org/abs/1604.03506&quot;&gt;&lt;strong&gt;An Unbiased Data Collection and Content Exploitation/Exploration Strategy for Personalization&lt;/strong&gt;&lt;/a&gt;. ArXiv. 2016.&lt;/li&gt;
  &lt;li&gt;Lihong Li, Jin Young Kim, and Imed Zitouni. &lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2685311&quot;&gt;&lt;strong&gt;Toward Predicting the Outcome of an A/B Experiment for Search Relevance&lt;/strong&gt;&lt;/a&gt;. In Proceedings of WSDM 2015.&lt;/li&gt;
  &lt;li&gt;Tobias Schnabel, Adith Swaminathan, Ashudeep Singh, Navin Chandak, Thorsten Joachims.
&lt;a href=&quot;http://arxiv.org/abs/1602.05352&quot;&gt;&lt;strong&gt;Recommendations as Treatments: Debiasing Learning and Evaluation&lt;/strong&gt;&lt;/a&gt;. ArXiv. 2016.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>个性化推荐是不是伪命题</title>
   <link href="http://column.hongliangjie.com/%E4%B8%AA%E6%80%A7%E5%8C%96,%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/07/personalization-or-not/"/>
   <updated>2016-04-07T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E4%B8%AA%E6%80%A7%E5%8C%96,%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/2016/04/07/personalization-or-not</id>
   <content type="html">&lt;p&gt;最近，有一位网友在微博上说，&lt;a href=&quot;http://weibo.com/1830516311/Dp4Vs81ih?from=page_1005051830516311_profile&amp;amp;wvr=6&amp;amp;mod=weibotime&amp;amp;type=comment&quot;&gt;推荐是不是个伪命题？连续几天试用了据说很好的某头条，某资讯以及某快报，感觉逃脱不了看什么就是什么的套路&lt;/a&gt;。也有人说，这是Exploitation &amp;amp; Exploration出了问题，没有很好得Exploration导致的结果。那么，个性化推荐到底是不是伪命题呢？为什么很多推荐系统过了一段时间以后就老是推荐类似的东西呢？本篇文章就要尝试分析和探讨这个“千篇一律”的问题。&lt;/p&gt;

&lt;h2 id=&quot;推荐是为了预测用户喜好的物品吗&quot;&gt;推荐是为了预测用户喜好的物品吗&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;要知道个性化推荐是不是伪命题，我们就必须从个性化推荐的&lt;strong&gt;目的&lt;/strong&gt;说起。一个通常意义上的推荐系统，顾名思义，就是要给用户推荐可能会交互（包括购买、点击、点赞等等）并且可能喜爱的物品，比如Amazon的商品、Netflix的电影、LinkedIn的工作以及Yahoo的新闻等。当然，这只是一个非常肤浅的定义。我们等会儿会看到这个定义的问题。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/netflix.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;自从Netflix Prize以来，推荐系统的研究和生产实际，基于以上这个关于推荐的肤浅定义，把整个系统的模型简化成了——预测用户对于某个事物的喜爱，也就是人们常说的Rating Prediction的问题&lt;sub&gt;[3]&lt;/sub&gt;。Collaborative Filtering，特别是基于Matrix Factorization&lt;sub&gt;[2]&lt;/sub&gt;和Latent Factor Model&lt;sub&gt;[1]&lt;/sub&gt;的各种方法及其变种大行其道，一时间似乎成为了推荐系统的代名词。于是，很多实际系统的设计者和开发着，不管自己产品的真实定位究竟如何，都选择利用协同过滤来打造自己的推荐系统。&lt;/p&gt;

&lt;p&gt;协同过滤是否有效呢？答案是肯定的。当然，这有一个巨大的前提，那就是，如果我们的产品，真的采用这个推荐的肤浅定义，仅仅注重于推荐用户是否喜欢的东西。协同过滤，辅佐以Machine Learning的很多手段（比如Tree-based Models)，常常能够在Rating Prediction这个问题上有不俗的成绩。然而，往往用户在使用产品一段时间以后就会得出微博上那位网友的体验。产品经理也会常常陷入困境，不知道如何改进产品。&lt;/p&gt;

&lt;p&gt;注意，有一些Rating Prediction的变种问题，其实质还是在优化用户对某一类事物的喜爱。比如，不仅仅预测单个物品的评分，而是看用户在一个物品列表中选择了哪些物品（代表作&lt;sub&gt;[7]&lt;/sub&gt;）。也就是看用户是否更&lt;strong&gt;偏好&lt;/strong&gt;某些物品。尽管这样似乎更准确抓住了推荐问题的产品定义，但依然没有能够摆脱优化用户喜好所带来的问题。&lt;/p&gt;

&lt;p&gt;实际上，任何以用户喜好为目标的推荐系统，不管优化对象是简单的点击率（Click-Through-Rate）还是驻留时间（Dwell-Time）&lt;sub&gt;[4]&lt;/sub&gt;，抑或是上面提到的评分，都很难逃脱上述问题。那么为什么优化用户喜好就会带来上述问题呢？&lt;/p&gt;

&lt;p&gt;原因很直观，要想优化用户喜好，那就必然强调用户的历史行为。协同过滤或者是机器学习导向的算法，都试图充分挖掘单个用户以及群体用户的喜好，并且加以推崇到极致（Optimization)。打个比方，如果你才查看了Amazon上的某款最新的相机，一般的推荐系统就会显示很多相似的相机或者其他各种相机配套产品，并希望最大化这&lt;strong&gt;单次&lt;/strong&gt;点击（或者查询）的“收益”。在这些系统看来，既然你已经“表达了”对相机兴趣，那么系统就要抓住这么一个机会。如果你不单单是偶然看了一次相机，而是研究了一小会儿以后，推荐系统就会认为你已经表达了很“&lt;strong&gt;强烈&lt;/strong&gt;”的对相机的喜好，那好，让你的整个屏幕都充满相机吧。也许有人可能会想到Discount用户短期内的一些行为这种做法，而对用户长期的一些行为更加关注（比如&lt;sub&gt;[8]&lt;/sub&gt;）。这种方法也许可以缓解“满屏相机”的现象，但是很难从根本上解决问题，况且这个Discount的参数本身也很难调试。于是，长期优化用户喜好，在绝大多数情况下，用户就会产生Filtering Bubble的效果，也就是说，用户自己只能看见自己喜欢的东西，并且不断强化。而从整个系统来讲，很难跳出推荐的东西千篇一律的效果。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/filter_bubble.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当然，这里还有一个更加严重的问题，这也是新闻推荐经常容易出现的问题。那就是，一些“资深用户”（Engaged Users），因为比常人更多得和一个系统交互，看了各种各样的新闻，有时可能完全不是因为喜欢，而是消磨时间或者随便看着玩儿，强化优化用户喜好的推荐系统很可能无法分辨这样的行为。过度优化“喜好”，可能带来的结果就是系统误认为这些用户什么都喜欢。我们下面还会深入讨论这个问题。&lt;/p&gt;

&lt;p&gt;只优化用户喜好的&lt;strong&gt;根本问题&lt;/strong&gt;，其实是&lt;strong&gt;忽略了大视野&lt;/strong&gt;（Big Picture）。那么，什么是推荐系统的大视野呢？这里先卖一个关子，我们到文章的最后再来揭晓。&lt;/p&gt;

&lt;h2 id=&quot;看一步走一步的优化策略&quot;&gt;看一步走一步的优化策略&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;上一节我们剖析了优化用户喜好的问题。熟悉推荐系统的人可能会说，这有很成熟的解决方案啊，Exploitation &amp;amp; Exploration（E &amp;amp; E）就是专门干这个的。那么，E &amp;amp; E是不是就解决问题了呢？&lt;/p&gt;

&lt;p&gt;我们先来看看E &amp;amp; E究竟是干什么的。E &amp;amp; E的核心思想&lt;sub&gt;[5]&lt;/sub&gt;是，我们在优化某些目标函数的时候，从一个时间维度来看，当信息不足或者决策不确定性（Uncertainty）很大的时候，我们需要平衡两类决策：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;选择现在可能最佳的方案&lt;/li&gt;
  &lt;li&gt;选择现在不确定的一些方案，但未来可能会有高收益的方案&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在做这两类决策的过程中，我们也逐渐对所有决策的不确定性不断更新不断加以新的认识。于是，&lt;strong&gt;最终&lt;/strong&gt;，从时间的维度上来看，我们在不确定性的干扰下，依然能够去&lt;strong&gt;优化&lt;/strong&gt;目标函数。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/exploration.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;举个例子，比如一个用户看新闻，如果这个用户只点击娱乐类的新闻，作为推荐系统而言，虽然我们知道下面接着显示娱乐新闻可能是比较不错的选择，但是&lt;strong&gt;完全忽视&lt;/strong&gt;显示其他类别新闻则显得整个系统高估了自己对用户的认知。于是，一个比较现代的推荐系统，往往会兼顾一些其他类别，看看用户是否对其他类别是不是也有兴趣。这就是E &amp;amp; E的典型案例。&lt;/p&gt;

&lt;p&gt;然而，E &amp;amp; E并不能解决我们之前提到的“千篇一律”的问题。原因倒不是说E &amp;amp; E本身可能会有什么问题，原因的核心还是，我们是否&lt;strong&gt;优化用户喜好&lt;/strong&gt;。也就是说，即便有E &amp;amp; E，只要我们的目标函数是用户喜好及其变种，那么，整个系统依然会&lt;strong&gt;收敛&lt;/strong&gt;（Converge）到“满屏相机”的状态。因为，也许用户&lt;em&gt;就是&lt;/em&gt;对相机喜好最大。那系统在Explore了一些其他类别的东西之后，发现用户没有太大兴趣，于是就“安全”得觉得，可以放心现实用户喜欢的类别了。&lt;/p&gt;

&lt;p&gt;也就是说，E &amp;amp; E没有错，错的是我们要优化用户喜好这件事情。或者换句话说，我们如果知道，一个用户真心只喜欢相机，而且在尝试给用户看了各种其他类别以后，系统是不是就以非常大的概率显示相机呢，而基本或者完全忽略其他类型的物品呢？&lt;/p&gt;

&lt;p&gt;另外，E &amp;amp; E在真实产品中应用还有一些实际的难度。很多公司的产品经理并不一定愿意实现这个功能。当然，这是另外一个话题了。&lt;/p&gt;

&lt;h2 id=&quot;复杂的人类行为&quot;&gt;复杂的人类行为&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;我们在第一节提到了一点用户行为的不确定性和复杂性（短期行为和长期行为的区别）。这里我们再讨论一下因为复杂的人类行为给推荐系统所带来的麻烦。也就是说，推荐系统目前只能“千篇一律”也部分因为建模水平有限。&lt;/p&gt;

&lt;p&gt;还是以新闻推荐为例子，用户在使用产品的时候，显然是有一些潜在的&lt;em&gt;意图&lt;/em&gt;（Intents）和使用习惯。比如，有一些用户，习惯于阅读所有的排在重要版面的新闻，&lt;strong&gt;不管&lt;/strong&gt;这些新闻是否真的激起用户的兴趣。这类似于搜索问题（Search）中的&lt;em&gt;位置偏见&lt;/em&gt;（Position Bias）——用户以为排在前面的就是重要的，就是需要他们阅读的。盲目认为用户点击了的就是用户喜欢的，往往是导致“越来越富”（Rich-Get-Richer）现象的一个简单原因。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/user_behaviors.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;当然，简单尝试去除这种偏见，也需要注意到，的确是有用户是习惯&lt;strong&gt;读完所有重要新闻&lt;/strong&gt;的。也就是说即便是去除偏见，粗看，用户的行为依然杂乱无章，今天看伊朗问题，明天看世界杯，后天看巴西政府丑闻，大后天看Kim Kardashian，貌似喜欢所有的话题和类别。这里的核心问题还是，只对喜好建模，就无法检测到用户的行为在“目的性”这一维度的差异性，于是误判用户喜欢很多类别的事物。这类的例子其实有很多，比如在奥斯卡季，用户看了最新的一批奥斯卡获奖电影，涵盖很多类别，但这并不代表用户真的就喜欢这些类别。&lt;/p&gt;

&lt;p&gt;同样在“意图”上容易误判的是有突发事件的时候，比如四年一度的世界杯（或者其他时间）。很多用户在短期内阅读了大量足球信息，而大多数这类用户都是平时&lt;strong&gt;完全&lt;/strong&gt;对足球没有兴趣的人。这种在短时间内&lt;strong&gt;过度&lt;/strong&gt;对于某一个类别新闻进行信息消费（Content Consumption），会对以喜好为基础的推荐系统造成极大困扰。系统很难&lt;em&gt;忘却&lt;/em&gt;这些用户的行为，或者说系统很难甄别那些该被忘掉。&lt;/p&gt;

&lt;p&gt;要抓住用户的行为，理解用户的意图，那么就对推荐系统的构建提出了更高要求。即便是优化用户喜好，为了评测系统是否能够区分短期、长期喜好和不同的阅读习惯，对数据的采集，系统的评价体系以及最终模型的更新都提出了更高的要求。&lt;/p&gt;

&lt;p&gt;当然，这一节我们是要说明，“千篇一律”问题的复杂性在于，我们需要判断是否是现有模型和系统对于哪怕就是优化用户喜好也没有做好。&lt;/p&gt;

&lt;h2 id=&quot;巧妇难为无米之炊&quot;&gt;巧妇难为无米之炊&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;在最终讨论“满屏相机”问题的解决方案之前，我们再来看一个可以很容易侦测到的问题，这也是经常导致一个推荐结果“千篇一律”的罪魁祸首之一。那就是，系统的物品池（Item Pool）太小。换句话说，就是根本没什么东西可以推荐。&lt;/p&gt;

&lt;p&gt;这个问题虽然说起来非常容易理解，但却是很多内容推荐平台（比如新闻推荐、视频推荐）的核心短板，也就是缺乏优质内容。比方说，用户喜欢看科幻文章，但遗憾的是，整个平台也许就只有几篇科幻文章，于是系统没法给用户提供更好的推荐。自然，用户也就只能反复看见剩下的东西在屏幕上占据显著的位置。&lt;/p&gt;

&lt;p&gt;然后这个问题说起来容易，真正要去着手解决却很麻烦。核心难点是，茫茫互联网，到哪里去获取优质内容。这个问题，我们留到以后再来探讨。&lt;/p&gt;

&lt;h2 id=&quot;推荐系统的大视野&quot;&gt;推荐系统的大视野&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;在卖了一个大关子以后，我们在最后这节讨论一下如何解决“千篇一律”的核心问题，那就是把握住推荐系统的&lt;em&gt;视野&lt;/em&gt;。&lt;/p&gt;

&lt;p&gt;推荐系统，或者说任何用户系统，的视野，就是如果把为用户提供服务（这里是推荐物品）作为&lt;strong&gt;一个环节&lt;/strong&gt;，&lt;strong&gt;和其他子系统协同来达到整个产品生态系统&lt;/strong&gt;的&lt;strong&gt;健康&lt;/strong&gt;。这里的核心的核心，是整个产品生态系统的健康。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/system_health.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;什么是推荐系统所在的整个生态系统的健康？以新闻平台来说，这里涉及：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;单个用户是否能够长期活跃，单个用户是否能在这里得到帮助，得到成长&lt;/li&gt;
  &lt;li&gt;用户族群（Community）是否得到保护，是否促进了不同形态的用户群的增长&lt;/li&gt;
  &lt;li&gt;信息提供商是否能够通过平台得到自己的收益（比如，投放的信息获得了广告收益；增加了知名度等）&lt;/li&gt;
  &lt;li&gt;信息提供商的多样性，良性的竞争关系。（比如不是单个信息来源占据了绝大多数的信息来源等）&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;还有很多很多。一旦把这些因素考虑进系统，并且加以量化，融合进目标函数（比如，一个简化版的代表作&lt;sub&gt;[6]&lt;/sub&gt;），我们就可以清晰得看到，优化这么一个目标，至少在理论上和实践中，都很难提供“千篇一律”的推荐结果，原因就是那样的结果，会最终流失用户、信息提供商，最终让产品僵化。&lt;/p&gt;

&lt;p&gt;也可以这么说，“千篇一律”的问题核心，简单说来就是，优化目标过于简单，没有把产品的健康考虑进去。&lt;/p&gt;

&lt;p&gt;说到这里，貌似这个问题已经“解决”了，其实不然，原因是，如何定义出一个健康指标，不仅仅是一个技术活儿，甚至是一个艺术活儿，这里就不仅仅是数据科学以及机器学习的范畴了，我们以后再讨论相关话题。&lt;/p&gt;

&lt;h2 id=&quot;结论&quot;&gt;结论&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;本篇文章讨论了个性化推荐不是伪问题，而是一个非常深的产品问题，我们需要考虑时时刻刻优化产品的全局健康。&lt;/p&gt;

&lt;h2 id=&quot;参考文献&quot;&gt;参考文献&lt;/h2&gt;
&lt;hr /&gt;
&lt;ol&gt;
  &lt;li&gt;Deepak Agarwal and Bee-Chung Chen. 2009. &lt;strong&gt;Regression-based latent factor models&lt;/strong&gt;. In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, USA, 19-28.&lt;/li&gt;
  &lt;li&gt;Yehuda Koren. 2010. &lt;strong&gt;Factor in the neighbors: Scalable and accurate collaborative filtering&lt;/strong&gt;. ACM Transactions on Knowledge Discovery from Data 4, 1, Article 1 (January 2010), 24 pages.&lt;/li&gt;
  &lt;li&gt;Robert M. Bell and Yehuda Koren. 2007. &lt;strong&gt;Lessons from the Netflix prize challenge&lt;/strong&gt;. ACM SIGKDD Explorations Newsletter - Special Issue on Visual Analytics 9, 2 (December 2007), 75-79.&lt;/li&gt;
  &lt;li&gt;Xing Yi, Liangjie Hong, Erheng Zhong, Nanthan Nan Liu, and Suju Rajan. 2014. &lt;strong&gt;Beyond clicks: dwell time for personalization&lt;/strong&gt;. In Proceedings of the 8th ACM Conference on Recommender Systems. ACM, New York, NY, USA, 113-120.&lt;/li&gt;
  &lt;li&gt;Lihong Li, Wei Chu, John Langford, and Robert E. Schapire. 2010. &lt;strong&gt;A contextual-bandit approach to personalized news article recommendation&lt;/strong&gt;. In Proceedings of the 19th International Conference on World Wide Web. ACM, New York, NY, USA, 661-670.&lt;/li&gt;
  &lt;li&gt;Deepak Agarwal, Bee-Chung Chen, Pradheep Elango, and Xuanhui Wang. 2011. &lt;strong&gt;Click shaping to optimize multiple objectives&lt;/strong&gt;. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, USA, 132-140.&lt;/li&gt;
  &lt;li&gt;Alexandros Karatzoglou, Linas Baltrunas, and Yue Shi. 2013. &lt;strong&gt;Learning to rank for recommender systems&lt;/strong&gt;. In Proceedings of the 7th ACM Conference on Recommender Systems. ACM, New York, NY, USA, 493-494.&lt;/li&gt;
  &lt;li&gt;Amr Ahmed, Yucheng Low, Mohamed Aly, Vanja Josifovski, and Alexander J. Smola. 2011. &lt;strong&gt;Scalable distributed inference of dynamic user interests for behavioral targeting&lt;/strong&gt;. In Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, USA, 114-122.&lt;/li&gt;
&lt;/ol&gt;
</content>
 </entry>
 
 <entry>
   <title>我为什么开设这个专栏</title>
   <link href="http://column.hongliangjie.com/%E7%AB%99%E5%8A%A1/2016/04/05/start-column/"/>
   <updated>2016-04-05T00:00:00-04:00</updated>
   <id>http://column.hongliangjie.com/%E7%AB%99%E5%8A%A1/2016/04/05/start-column</id>
   <content type="html">&lt;p&gt;经过一段时间的思考，我决定开一个技术、管理和团队的专栏，分享和探讨关于大数据、人工智能（AI）及机器学习（Machine Learning）的话题，以及这些相关技术的行业思考。在已经有不少优质内容（包括博客、微信公众号）的情况下，我希望这个专栏能够更加专注、专业，少一些关注个别技术的细节，多一些对数据在一个生态系统中的把握以及行业动态的分析。&lt;/p&gt;

&lt;p&gt;在接下来的文章中，我准备着重分享和探讨如下这些方面的内容：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;机器学习、人工智能和大数据相关领域的核心技术，如何应用这些核心技术到生产实践中。解析从单一算法到产品流程的距离和取舍（Compromise）。&lt;/li&gt;
  &lt;li&gt;什么是数据驱动(Data-Driven)的团队，如何构建具有核心竞争力的大数据团队。&lt;/li&gt;
  &lt;li&gt;如何设计和开发智能型数据驱动产品，作为产品经理，如何在产品功能和数据驱动之间寻求动态平衡。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;正如前面提及的一样，第一方面已经有不少优秀内容涵盖。这个专栏的特色则是寻求如何在学术圈的最新研究成果（State-of-the-Art）和工业界的标准流程中建立桥梁，在浩如烟海的相关文献中，找到最适合的算法和模型。&lt;/p&gt;

&lt;p&gt;第二和第三方面则是这个专栏重点想提及的部分。那就是如何转变现有的团队建设和产品开发思维，能够从数据驱动的角度，能够从数据工程的角度来看待问题。现代产品为什么失败，其中有一个原因就是没法和数据很好衔接。这里说的衔接，指的是产品功能上的衔接，数据链条的衔接以及产品经理的理念的衔接。这个专栏希望起到抛砖引玉的作用，能够真正引发对于数据产品的思考，推进产品的质量。&lt;/p&gt;

&lt;p&gt;最后，为什么这个专栏叫“期望最大化”，这源自于一个机器学习里有名的算法：Expectation Maximization，不断在现有参数下更新模型对周围的认知然后又不断更新模型的参数，最终能够达到一个局部最优解。这个专栏也希望像这个算法一样，不断提升自己的认识，不求最完美，但求能够促进业界的分享和交流。&lt;/p&gt;
</content>
 </entry>
 

</feed>
