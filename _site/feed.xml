<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>期望最大化（洪亮劼的专栏）</title>
    <description>LinkedIn工程总监、前Etsy工程总监、雅虎研究院高级研发经理，长期从事机器学习、大数据分析、个性化系统架构的研究；这是一个分享技术、管理、团队和业界思考的专栏。</description>
    <link>http://column.hongliangjie.com/</link>
    <atom:link href="http://column.hongliangjie.com/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 10 Feb 2020 21:13:18 -0800</pubDate>
    <lastBuildDate>Mon, 10 Feb 2020 21:13:18 -0800</lastBuildDate>
    <generator>Jekyll v3.7.4</generator>
    
      <item>
        <title>《经理人之路——技术领袖启航成长与变化的参考书》总结</title>
        <description>&lt;p&gt;今天我们要来总结技术管理书籍&lt;a href=&quot;https://www.amazon.com/Managers-Path-Leaders-Navigating-Growth/dp/1491973897&quot;&gt;The Manager’s Path – A Guide for Tech Leaders Navigating Growth &amp;amp; Change&lt;/a&gt;。这本书的作者是&lt;a href=&quot;https://en.wikipedia.org/wiki/Camille_Fournier&quot;&gt;卡米尔福尔聂尔（Camille Fournier）&lt;/a&gt;，其在技术管理领域有丰富的经验。全书是针对技术管理人在职场发展不同阶段所需技能以及面对诸多管理场景的经验总结，是技术管理领域不可多得的参考书籍。&lt;/p&gt;

&lt;h2 id=&quot;作者简介&quot;&gt;作者简介&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/cf.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Camille_Fournier&quot;&gt;卡米尔福尔聂尔（Camille Fournier）&lt;/a&gt;从2017年起在对冲基金&lt;a href=&quot;https://en.wikipedia.org/wiki/Two_Sigma&quot;&gt;Two Sigma&lt;/a&gt;担任“董事总经理”（Managing Director）。之前在&lt;a href=&quot;https://en.wikipedia.org/wiki/Rent_the_Runway&quot;&gt;Rent The Runway&lt;/a&gt;历任总监、高级副总裁以及首席科技官等职务。其早年从卡内基梅隆大学毕业或计算机科学学士，毕业后在微软以及高盛任职。&lt;/p&gt;

&lt;h2 id=&quot;全书结构&quot;&gt;全书结构&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;全书大体上可以分为以下这么四部分内容:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;第一部分，是对从“个人岗位”（Individual Contributor）向“管理岗位”（Managerial Contributor）转换过程的经验总结，面向的对象主要是有一定经验的技术人员，内容涵盖了“导师”（Mentor）和“技术负责人”（Tech Lead）。这部分内容是“技术管理”（Technical Management）的重要准备。在书中大体对应第二章、第三章和一部分第四章的内容。&lt;/li&gt;
  &lt;li&gt;第二部分，是对“初级经理人”（Entry-Level Manager）的经验总结，面向的对象主要是“经理”（Manager）这一级别的职务。这一部分是“技术管理”的奠基石。在书中大体对应一部分第四章的内容和第五章的内容。&lt;/li&gt;
  &lt;li&gt;第三部分，是对“中层经理人”（Manager of Managers）的经验总结。面向的对象主要是“资深经理”和“总监”这一级别的职务。这一部分是技术管理的重要进阶。在书中大体对应第六章和第七章的内容。&lt;/li&gt;
  &lt;li&gt;第四部分，是对“高级经理人”（Senior Leaders）的经验总结，面向的对象主要是“首席科技官”（CTO）和“高级副总裁”（SVP）这一级别的职务。这一部分是技术管理的高级阶段。在书中大体对应第八章的内容。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;除了这四部分的主要内容以外，这本书的第一章主要是从“被管理”的角度讲如何和自己的经理打交道，可以说是非常有用的经验总结。而第九章，也就是最后一章，则讲了讲对于塑造团队和企业技术文化的一些经验之谈。&lt;/p&gt;

&lt;h2 id=&quot;内容剖析&quot;&gt;内容剖析&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;我们接下来就针对书中的四个重点内容为大家进行剖析。&lt;/p&gt;

&lt;h3 id=&quot;技术管理的准备&quot;&gt;技术管理的准备&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/mentor.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;要想胜任技术管理的岗位往往不是一蹴而就。从个人岗位到管理岗位有时候有着不可逾越的鸿沟。现实中的技术人员，特别是资深技术人员，通常情况下都在自身技术水平不断得到提升的基础上，希望能够对自己的管理能力也进行扩展，从而来试探自己是否有朝一日能够走上管理岗位。于是，在非管理岗位进行技术管理的技能培养和训练就显得尤其重要。&lt;/p&gt;

&lt;p&gt;本书对于技术管理的准备阶段着重从“导师”和“技术负责人”这两个重要“角色”（Role）入手，来引导资深技术人员来理解“人员管理”（People Management）的入门技能。&lt;/p&gt;

&lt;p&gt;另一方面，从中层经理人的角度来说，“导师”和“技术负责人”这两个角色也是考察资深技术人员是否具备转换为潜在“初级经理人”（所谓的内部提拔）的重要过度性角色。也就是说，把有一定资质的技术人员放在这样的角色上是相对风险较低得考察一个技术人员是否能够适应管理工作的重要方法。&lt;/p&gt;

&lt;p&gt;“导师”这个角色往往比较简单。书中涵盖了两种“导师”关系：实习生导师和新员工导师。在这些初级的技术管理角色中，技术人员需要开始学习和掌握三种重要的管理技能（Skill）：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;聆听&lt;/strong&gt;（Listen）：“聆听”可以说是从简单技术岗位到管理岗位转换中非常难以驾驭的一个技能。同时，聆听是建立“共情”（Empathy），也就是另一个重要的管理技能，的重要步骤，或者说是第一步。培养“聆听”技能的核心在于“专注”。也就是说，“聆听”需要你专注于你所聆听对象目前在表达的事情。“聆听”的目的是了解对方所希望表达的内容和观点，而不是迅速切换到你自己的回应。另外，“聆听”的难点在于很多人并不善于表达自己的观点。于是，在“聆听”的过程中去真正理解对方的意图就变得尤为重要。这种时候，通过反复问问题的方式来调整对于意图和内容的理解是一种有效的手段。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;沟通&lt;/strong&gt;（Communication）：“沟通”是指对于沟通对象明确表达或者明确传达某种信息。沟通最忌讳预设立场。也就是说，不要预期沟通对象在没有沟通的情况下依然知道或者能够猜测到你所希望表达的信息。“沟通”的目的是明确表达出你对于对方的期待。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;调整&lt;/strong&gt;（Calibration）：“调整”是指通过“聆听”和“沟通”来针对目前的状况调整计划。有很多情况是你实现意料不到的：你的指导对象也许比你想象得要慢；或许项目的进行不如你的预期；或许你的指导对象完全依靠自己完成了任务，等等。在这些意料之外的情况发生的时候，都需要你针对这些情况进行调整，并且能够和你的指导对象进行沟通。这种调整往往有一定周期性，比如每天或者每周。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;相较于“导师”，“技术负责人”则更像一个完整的“初级经理人”。在很多公司，“技术负责人”往往承担起很多经理的职责。值得注意的是，很多“技术负责人”也为团队中的年轻技术人员提供指导工作，起到“导师”的作用。&lt;/p&gt;

&lt;p&gt;然而，“技术负责人”往往需要具备一些相较于“导师”而言更加高阶的技能：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;平衡&lt;/strong&gt;（Balance）：“技术负责人”要开始学会在诸多完全不同的任务之间平衡自己的精力和时间。在最开始的一些时间里，人们往往倾向于做自己熟悉的任务（例如编写代码）。然而要想能够在技术管理的路上前行，“技术负责人”要开始学习新的技能并且在自己并不是那么熟悉的领域（例如组织会议、指导更多的年轻技术人员）多花时间。于是，“平衡”就成为了一种重要的技能。另外一个通常需要平衡的关系就是自己写代码解决复杂问题和如何调动团队来合作解决问题。&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;项目管理&lt;/strong&gt;（Project Management）：理解和掌握项目管理的精髓并不需要你成为“项目经理”（Project Manager）。这里所说的项目管理指的是如何把一个复杂的技术问题转换成为细致的多种任务同时能够对这些任务进行简单的分配和管理。更加高阶一些的项目管理技能需要“技术负责人”能够收集项目需求（Requirements）同时能够对项目的长度进行有效的估计。一个好的“技术负责人”更是能够发现目前项目进度的主要挑战（Challenge），并且能够带领团队进行技术攻坚。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;不管是“导师”还是“技术负责人”，作为一个资深技术人员，这两种角色都是让你能够开始学习和锻炼管理技能的重要过度角色。你可以审视自己是否喜欢这样的角色，是否真正愿意在技术管理的道路上继续前行。&lt;/p&gt;

&lt;h3 id=&quot;初级经理人&quot;&gt;初级经理人&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/junior.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在绝大多数科技公司，“初级经理人”一般指的是管理单一团队的技术经理人。单一团队的人数通常在三到十人不等。&lt;/p&gt;

&lt;p&gt;从“初级经理人”开始，技术管理的一些重要技能开始把个人岗位和管理岗位完全地区分开：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;开始一段新的汇报关系：在之后的技术管理工作中，经常会产生新的汇报关系。如何对待这些新出现的汇报关系则成为了技术管理中的重要技能。书中提到了一系列重要手段。例如和新的汇报对象逐渐建立&lt;strong&gt;互信&lt;/strong&gt;。说到底好的管理还是建立在人与人的关系上的，而在西方管理学中一个核心的内容就是人与人的互信。再例如就是建立一个30天60天90天的计划从而为新的汇报关系之间提供一个清晰的预期。同时，在确立新的汇报关系的过程中，“聆听”和“沟通”技能也起着至关重要的作用。这些技能是为了和新的汇报关系慢慢建立一个反馈机制。&lt;/li&gt;
  &lt;li&gt;一对一会议（1-1）：在这本书中，“一对一会议”的重要性被作者反复强调。“一对一会议”的安排（例如每周）和内容以及如何在这些会议中和汇报对象建立起稳健的反馈机制都是初级经理人需要掌握的重要人事管理的技能。书中还列举了不同类型的“一对一会议”诸如解决问题型、反馈型或者最新进展型。显然，要想在不同的情况下和汇报对象建立长久的关系，在不同类型的“一对一会议”之间熟练切换就成为了重要的手段。&lt;/li&gt;
  &lt;li&gt;绩效反馈评定：对汇报关系进行绩效反馈以及评定是技术管理的核心组成部分。这项技能是之前提及的“初级经理人”有别于之前提及的“技术负责人”的重要标杆。书中提及了一系列实际的技巧，例如“使用实际的事例”、“还需要加强的领域需要专注”等。
“初级经理人”一个非常重要的职责就是关注和协助团队成员的职业发展。很明显，不同公司不同行业的职级（Level）有区别。作为一线的“初级经理人”，你需要对团队中不同成员的晋升负责并且和他们一起提供一个完整的路线图。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;另外一个“初级经理人”需要开始学习的职责，就是管理员工的“离职”。“离职”分“主动离职”和“被动离职”（也就是俗称的“解雇”）。对于很多“初级经理人”而言，管理汇报对象的“离职”往往比想象中的要困难。这里关键的步骤是有效得建立起绩效的反馈机制以及比较详细的记录，从而为“离职”进行材料准备。&lt;/p&gt;

&lt;p&gt;“初级经理人”的相对比较高阶的话题还包括：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;观察和调试（Debug）团队：因为“技术经理人”不再是技术人员，需要利用新的技能和流程来对团队的整体绩效进行有效的评估。这里面包括的场景有团队的产出下降、团队有“人事混乱”（People Drama）、团队有合作问题等等。这里面的每一个场景都需要你建立一整套的机制来获取、筛选和处理信息，从而能够达到调试团队的目的。&lt;/li&gt;
  &lt;li&gt;矛盾和分歧的处理：很快，“初级经理人”就会发现其周围充满了矛盾和分歧。这些矛盾和分歧有来自于团队内部的，有来自其他合作团队的，有来自于上层的，等等。如何在复杂的环境下处理这些矛盾和分歧就成为了“初级经理人”所要学习的技能。这些技能会在“高级经理人”的阶段变得更加关键。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;成为一个有效的“初级经理人”还需要对项目管理有更加高阶的提升，包括你要开始针对团队的短期和长期的任务有一个比较完整的理解以及理解公司的运作周期（每个季度的时间安排），从而使得你对项目的分配以及团队的产出和合作都有一个全新的更高层次的认知。&lt;/p&gt;

&lt;h3 id=&quot;中层经理人&quot;&gt;中层经理人&lt;/h3&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/middle.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在绝大多数科技公司，“中层经理人”一般指的是管理多个团队的技术经理人。这个时候，“中层经理人”所管理的多个子团队本身往往有一线的“初级经理人”。而“中层经理人”的职责则转移到如何管理好这些初级经理人以及通过这些“初级经理人”来对所有的多个团队进行间接的管理。管理多个团队是技术管理人从初级阶段向更加复杂的管理场景提升的重要标志。&lt;/p&gt;

&lt;p&gt;书中认为“中层经理人”一项非常的技能是如何更加合理得管理自己的时间。的确，对于一个“中层经理人”来说，在某一个瞬间，都有太多的事情可以聚焦，那么如何专注在最需要的事情上就变得尤为重要。书中介绍了一种经典的时间管理方法，那就是把事情按照重要与否和紧急与否两个维度分为如下的四种类别：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;重要而且紧急：一件事情如果是重要且紧急，那么这明显是当前需要专注的工作。尽管这样的分类方法有一定道理，作者提醒我们要注意在日常工作中把“显然”（Obvious）的工作当做是“紧急”（Urgent）的。例如，一个在日历上的会议邀请并不意味着这个会议就一定是紧急的事件。有时候，分清楚什么事情是否重要或者紧急并不是那么显然的事情。&lt;/li&gt;
  &lt;li&gt;重要但不紧急：很多事情都可以归为这个类别。例如，写一份新的“职位描述”（Job Description），抑或是思考一个新的招聘计划。这类事情的一个特点就是如果一点不花时间去做，那么长期积累下来就会对你的工作产生负面影响。一个“中层经理人”需要利用“平衡”等技能来找到时间花在重要但不紧急的事情上。&lt;/li&gt;
  &lt;li&gt;不重要且不紧急：这是很明显需要避免的一个类别。&lt;/li&gt;
  &lt;li&gt;不重要但紧急：作者认为这个类别的事情都是潜在的“分心”（Distraction）。例如，很多会议都显得很紧急，但作为一个“中层经理人”是否需要参与这些会议是需要仔细拿捏的意见事情。还有类似电子邮件或者聊天工具（Slack）上面的信息，会显得很紧急。但这些事情并不一定需要你现在就去处理。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;在管理时间的基础上，作者提到了第二个“中层经理人”的重要技能“决策”（Decision）和“代理”（Delegation）。这个技能是中级经理人需要获取和发展的。类似于时间管理，作者按照经常与否和复杂与否两个维度，把事情的决策和代理分为了以下四个类别：&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;简单且不经常：这类事情的典型代表如运行一些每个季度需要的报表，或订会议的票等，一般需要你自己去做。主要的原因是这类事情不具备利用来培养团队“初级经理人”的目的。&lt;/li&gt;
  &lt;li&gt;简单且经常：这类事情的典型代表如团队每日的例会、团队的进度报告等，一般需要你代理别人去做。一般来说，团队中的技术负责人或者一些资深技术人员都可以胜任这样的任务。&lt;/li&gt;
  &lt;li&gt;复杂且经常：这类事情的典型代表如项目计划、系统设计或者是在“事故”（Outage）的处理中担任核心的任务，一般需要你小心得去代理给团队。这些任务可以认为是发展团队中核心成员的重要手段和工具。然而因为这些事情相对都比较复杂，因此在代理的过程中需要注意方式方法和速度。简单来说，就是不能贸然把这类事物都不假思索得代理给团队。&lt;/li&gt;
  &lt;li&gt;复杂且不经常：这类事情的典型代表是写绩效评定、或者是建立一个新的招聘计划，一般来说需要你自己去做，但是也可以慢慢来代理给团队中未来的领袖。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;学会如何平衡所有事物的决策和代理权是一个动态并且需要慢慢体会的技能。&lt;/p&gt;

&lt;p&gt;对于“中层经理人”来说，第三个重要的技能就是需要策略性地说“不”。对于多团队管理来说，有太多的场景需要你来斟酌并且表达否定的决策。然而，这里面的问题是，很多时候，简单说“不”并不能解决问题，尤其是有矛盾和分歧的时候。书中介绍了一系列的“说不”的技巧。总结说来，这些技巧都是要在“说不”的情况下提供更多的“上下文”（Context）以及尝试创造一个“说不”以后的计划，而不是简单的“说不”。&lt;/p&gt;

&lt;p&gt;我们在前面总结“初级经理人”的时候提及了“一对一会议”的重要性。当一个“中层经理人”开始管理多个团队时，与所有团队所有人进行“一对一会议”已经不现实，然而，书中还是强调了在这种新形势下的“一对一会议”，也就是“隔层会议”（Skip-Level Meetings）的必要性。总的来说，“隔层会议”是让你保持和一线员工有稳固联系的重要手段。通过这些“隔层会议”，你可以发现团队运行存在问题的蛛丝马迹。&lt;/p&gt;

&lt;p&gt;最后，“中层经理人”还需要有效管理起各个团队的“初级经理人”。这些“初级经理人”有可能是完全的新手，也有可能是富有经验的技术管理者。对于这些人的管理最重要的有两点，那就是如何建立有效的调试机制来得知他们管理的团队是否是高效运行还是存在不少潜在的问题，另外设置有效的预期以及提供反馈都是非常重要的中层管理手段。&lt;/p&gt;

&lt;p&gt;值得一提的是，“中层经理人”由于隔了一层“初级经理人”，因此对于团队的管控往往都是通过间接的手段，因此书中介绍的种种经验和技能都依赖于能够对初级经理人能够进行有效管理，因此“中层经理人”需要同时具备管理多个团队以及管理多个个人（也就是多个“初级经理人”）的技能和手段。这对经理人的要求明显高于初级经理人。&lt;/p&gt;

&lt;h2 id=&quot;高级经理人&quot;&gt;高级经理人&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/senior.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;书中的“高级经理人”指的是“工程副总裁”（VP of Engineering）或者“首席技术官”（CTO）这样的职位。很显然，“高级经理人”需要相比于“中级经理人”和“初级经理人”而言完全不同的一整套技能。&lt;/p&gt;

&lt;p&gt;书中提及的第一个重要技能就是如何对待“变化的优先级”（Changing Priorities）。这里提及的场景主要是指公司高层，例如CEO突然觉得公司应该专注于新的事情或者目前事情的优先级发生了变化。这些变化有可能并不是深思熟虑的结果。那么，如何带领一个复杂的机构（这时候已经不是单单几个团队了）来应对优先级的变化就是高级经理人往往需要掌握的技能。优先级的改变有可能对团队产生极大负面的效果。每个团队都潜在有一个常常的任务列表。很多项目之间还有依赖关系。因此，转变一个机构的优先级，并且能够有一个匹配的计划就变得尤为关键。另外，“沟通”在这种场景下也是不可缺少的重要技能。&lt;/p&gt;

&lt;p&gt;作为“高级经理人”的第二个重要技能就是如何设置“战略”（Strategy）。向董事会成员、或者是管理高层讲述、汇报部门甚至是公司在某一个方面的战略思想将成为“高级经理人”的一项核心工作。那么，如果能够建立战略的思路以及如何表述这样的战略就成为了高级经理人阶段的新技能。再之前的中层以及初级经理人阶段，主要是强调在执行的层面。&lt;/p&gt;

&lt;p&gt;最后，作为“高级经理人”，一个非常重要也是一个新的技能领域，那就是如何与诸多“跨部门”（Cross-Functional）“高级经理人”协作。尽管在科技公司中，有不少项目是跨部门协作的，例如需要设计、前台、后台、算法的齐心协力，然而在“高级经理人”阶段，你往往代表了一整个职能部门（例如工程副总裁或者是首席科技官代表了整个工程研发团队）与其他职能部门，例如产品、法务、人事，在整个公司的层面上进行合作。这势必是对你沟通表达能力以及协作能力的全新考验。&lt;/p&gt;

&lt;h2 id=&quot;总结点评&quot;&gt;总结点评&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这本书可以说是作为技术管理人的“宝典”级别的职场参考书。因为作者卡米尔相对丰富的职业经理人晋升经历，因此这本书中提供的很多经验之谈都相当接地气并且有极高的参考价值。与更加通用的管理书籍相比，此书专注于科技公司的技术管理场景，因而对于有心于技术管理职场发展的各层级技术人员和技术管理人来说，这本书都能够提供不小的帮助。整本书的结构上来看，主要是相对比较松散组织起的四大块内容，以及穿插的各种技巧，因此可能在宏观上缺乏一定的架构，所以，本书可以作为可以反复阅读的经验总结之作。&lt;/p&gt;
</description>
        <pubDate>Wed, 25 Dec 2019 00:00:00 -0800</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2019/12/25/the-manager-path/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0,%E7%AE%A1%E7%90%86/2019/12/25/the-manager-path/</guid>
        
        
        <category>读书笔记,管理</category>
        
      </item>
    
      <item>
        <title>KDD 2019讲座 - “双次序实验”</title>
        <description>&lt;p&gt;今天我们要来分享一个叫&lt;a href=&quot;http://www.stat.cmu.edu/~aramdas/kdd19/&quot;&gt;Foundations of Large-scale “Doubly-Sequential” Experimentation&lt;/a&gt;的KDD 2019讲座（Tutorial)。这个讲座的作者是来自于时任卡内基梅隆大学（Carnegie Mellon University）助理教授的&lt;a href=&quot;http://www.stat.cmu.edu/~aramdas/&quot;&gt;Aaditya Ramdas&lt;/a&gt;。这个讲座清晰得梳理了基于单个实验的“内次序”（Inner Sequential Process）和基于多个实验的“外次序”（Outer Sequential Process），以及他们之间的关系。同时，这个讲座还涵盖了这方面的重要文献历史，是一份不可多的资料。&lt;/p&gt;

&lt;h2 id=&quot;讲座的基本设置&quot;&gt;讲座的基本设置&lt;/h2&gt;

&lt;p&gt;讲座的第一部分是对简单的A/B实验进行了回顾。诚如讲座里面讲的，这部分内容已经在最近几年的各大会议的很多其他类似讲座中已经有所涵盖。因此该讲座并没有再对基础知识进行重复。&lt;/p&gt;

&lt;p&gt;讲座的内容很快转移到核心的两块内容，那就是基于单个实验的“内次序”（Inner Sequential Process）以及基于多个实验的“外次序”（Outer Sequential Process）。简单得来说，不管是“内次序”还是“外次序”，该讲座的目的就是来探讨如何让实验的结论能够成立。也就是说，如果进行简单的“假设检验”（Hypothesis Testing），例如我们经常做的T-Test，或者其他基于“置信区间”（Confidence Interval）的检验有可能得到错误的结论。讲座的核心内容就是来对已有的方法已经扩展。&lt;/p&gt;

&lt;h2 id=&quot;内次序&quot;&gt;内次序&lt;/h2&gt;

&lt;p&gt;“内次序”主要是探究在一个实验里的结论是否正确的问题。当然，这里的“正确”并不是指绝对意义上的“控制组”（Control Group）要比“对照组”（Treatment Group）好，或者反之。而是从统计意义来说，如何来衡量控制组和对照组之间的差别。上面我们提到，这种统计推断的核心是进行“假设检验”。&lt;/p&gt;

&lt;p&gt;Aaditya首先指出，传统的假设检验的一个重大问题就是样本数量必须事先确定好。不管是p-value还是置信区间都依赖于这个&lt;strong&gt;事先确定好的&lt;/strong&gt;样本数量。这种静态的需求和很多平时在A/B实验中进行观测的行为是非常不同的。例如，一种非常普遍（并不是是正确）的观测实验的方式是，对一个实验的结果反复进行检查，看p-value是不是到达并且小于某个阈值$ \alpha $，一旦小于这个值，立马停止实验。利用这样的方法会得到“False Positive Rate”很可能远远大于事先的阈值$ \alpha $。换句话说，很多我们认为有作用的“对照组”其实很有可能并没有作用。&lt;/p&gt;

&lt;p&gt;那么，内次序的核心问题就是如何对这样的监控算法进行扩展和改进，使得我们能够随时监控实验并且还能够得到正确的统计推断结果。&lt;/p&gt;

&lt;p&gt;在该讲座中，Aaditya讲解了“Confidence Sequence”和“Sequential p-value”的概念，并且展示了如何利用这两种手段来进行单个实验的检测。同时，Aaditya还揭示了这两种概念之间的转化关系。&lt;/p&gt;

&lt;h2 id=&quot;外次序&quot;&gt;外次序&lt;/h2&gt;

&lt;p&gt;那么，如果我们能够很好得处理一个实验，是不是我们就可以放心大胆得进行多个实验来进行服务的改进了呢？答案是，对于多个实验，我们依然需要更加小心。&lt;/p&gt;

&lt;p&gt;这部分的内容可能一开始会让人觉得很震惊。但Aaditya在讲座中举了很直观的例子来说明，即便单个实验我们都依靠某个$ \alpha_{i} $来控制“False Positive Rate”，并不代表多个实验的总体的”False Discovery Proportion”(FDP)是小于或等于这些$ \alpha_{i} $。&lt;/p&gt;

&lt;p&gt;外次序的核心内容就是如何对多个实验进行监控，并且能够在“在线”（Online）的情况下进行统计推断。该讲座对几个最新的在线FDP算法进行讲解。细节可以参考讲座内容。&lt;/p&gt;

&lt;h2 id=&quot;双次序实验&quot;&gt;双次序实验&lt;/h2&gt;

&lt;p&gt;该讲座应该算是第一个把内次序和外次序都结合在一起的一个讲座。Aaditya在讲座内容中指出，这两个部分均可以进行“模块化”。意思是说，更好的内次序算法以及更好的外次序算法可以进行搭配使用。&lt;/p&gt;

&lt;h2 id=&quot;高级内容&quot;&gt;高级内容&lt;/h2&gt;

&lt;p&gt;Aaditya在该讲座也进行了部分高级内容的概括：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;在“内次序”中如何处理多个“对照组”。讲座提到了基于Multi-Armed Bandit（MAB）的算法。&lt;/li&gt;
  &lt;li&gt;如何对Quantile进行估计。&lt;/li&gt;
  &lt;li&gt;在“外次序”中，如何对过去远期的实验进行“忘却”（Forget）。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;历史信息&quot;&gt;历史信息&lt;/h2&gt;

&lt;p&gt;Aaditya在讲座中回顾了内外次序的重要历史文献。&lt;/p&gt;
</description>
        <pubDate>Mon, 02 Sep 2019 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2019/09/02/kdd-sequencial/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2019/09/02/kdd-sequencial/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>CIKM 2018论文精读（一）</title>
        <description>&lt;p&gt;今天我们要来分享一篇题目叫&lt;a href=&quot;https://drive.google.com/open?id=1m7-z2loy5iW-gcrGiT2XJTdr4LjQHf3H&quot;&gt;Collaborative Multi-objective Ranking&lt;/a&gt;的发表在&lt;a href=&quot;https://www.cikm2018.units.it/&quot;&gt;CIKM 2018&lt;/a&gt;上的论文。这篇论文的作者是来自于罗格斯大学（Rutgers University）的&lt;a href=&quot;https://sites.google.com/site/hujun1010/&quot;&gt;Jun Hu&lt;/a&gt;和&lt;a href=&quot;http://www.stat.rutgers.edu/home/pingli/&quot;&gt;Ping Li&lt;/a&gt;。文章的核心内容讲的是，传统的以矩阵分解为基础的“协同排序”（Collaborative Ranking）容易有无法有效学习“用户隐向量”（User Factor）和“物品隐向量”（Item Factor）的问题。这篇论文探究了这种问题的来源以及提出了一种“共同优化”（Joint Optimization）的策略来解决问题。&lt;/p&gt;

&lt;h2 id=&quot;文章的基本设置&quot;&gt;文章的基本设置&lt;/h2&gt;

&lt;p&gt;我们先来看一下文章的基本设置。首先，我们假设有一个评分矩阵$ \mathbf{R} \in \mathbb{R}^{M \times N} $，被一个用户矩阵$ \mathbf{U} \in \mathbb{R}^{M \times K} $和一个物品矩阵$ \mathbf{V} \in \mathbb{R}^{N \times K} $所表达$ \mathbf{R} = \mathbf{U} \times \mathbf{V} $。一个“单点”（Pointwise）目标函数常用来学习模型的参数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{\mathrm{pointwise}} = \sum_{u=1}^{M} \sum_{v=1}^{N} (r_{ui} - \hat{r_{ui}})^{2} + \sum_{u=1}^{M}\lambda_{U,u}|| \mathbf{U}_{u} ||^{2} + \sum_{v=1}^{N}\lambda_{V,v}|| \mathbf{V}_{v} ||^{2}&lt;/script&gt;

&lt;p&gt;这个目标函数的目的是希望能够学习到准确的用户隐向量和物品隐向量来逼近原有的评分矩阵。然而在真实的应用中，很多时候我们并不是在意&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}&lt;/script&gt;的绝对数值的准确性，而是它们之间的相对位置，也就是说“排序”。所以，这也就有了“协同排序”的出现。具体说来，“协同排序”就是希望利用“配对法”（Pairwise）的“排序学习”（Learning to Rank）确保物品的相对顺序得以保证。一个常见的针对顺序的损失目标函数是：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\varepsilon_{\mathrm{zero-one}} = - \sum_{(u, i_{1}, i_{2}) \in \Omega} \sigma \Bigr( \mathbf{U}_{u} \mathbf{V}_{v_{1}}^{T} - \mathbf{U}_{u} \mathbf{V}_{v_{2}}^{T}\Bigl)&lt;/script&gt;

&lt;p&gt;其中&lt;script type=&quot;math/tex&quot;&gt;\Omega = \{ (u, i_{1}, i_{2}) : r_{ui_{1}} &gt; r_{ui_{2}} \}&lt;/script&gt;是一个比较集合，&lt;script type=&quot;math/tex&quot;&gt;\sigma(x)&lt;/script&gt;是一个$0-1$ 损失函数：当$x &amp;gt; 1$的时候&lt;script type=&quot;math/tex&quot;&gt;\sigma(x) =1&lt;/script&gt;，其他时候为$0$。这个损失函数无法微分，因此一个替代的方案则是利用Sigmoid函数：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\varepsilon_{\mathrm{zero-one-approximate}} = - \sum_{(u, i_{1}, i_{2}) \in \Omega} \frac{1}{1+\exp\Bigr( -\mathbf{U}_{u} (\mathbf{V}_{v_{1}} - \mathbf{V}_{v_{2}})^{T}\Bigl)}&lt;/script&gt;

&lt;p&gt;我们有了上面的这个损失函数以后，在进行优化的过程中，往往会“保持住”（Fix）所有某个用户$u$所对应的&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}&lt;/script&gt;，然后更新&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;。&lt;/p&gt;

&lt;h2 id=&quot;文章的核心观点&quot;&gt;文章的核心观点&lt;/h2&gt;

&lt;p&gt;文章的作者们发现，在某些情况下在更新用户矩阵&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;的时候，算法不可能保持住所有用户所对应物品的顺序的。举例来说，我们有两组物品的比较顺序&lt;script type=&quot;math/tex&quot;&gt;\{ (u, a, b) : r_{ua} &gt; r_{ub} \} \in \Omega&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\{ (u, c, d) : r_{uc} &gt; r_{ud} \} \in \Omega&lt;/script&gt;。并且当前情况下，我们有这样的关系：&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}_{a} - \mathbf{V}_{b} =[0,-1]&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}_{c} - \mathbf{V}_{d} =[0,1]&lt;/script&gt;。这也就意味着无论如何更新&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;，我们都无法同时满足&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}(\mathbf{V}_{a} - \mathbf{V}_{b})&gt;0&lt;/script&gt;和&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}(\mathbf{V}_{c} - \mathbf{V}_{d})&gt;0&lt;/script&gt;，因为这两组乘积必定是一正一负，无法调和。也就是说，在更新了&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;之后，我们反而无法保证原有的顺序了。&lt;/p&gt;

&lt;p&gt;第二个作者们的发现来自于对于Sigmoid函数&lt;script type=&quot;math/tex&quot;&gt;\sigma(x) = \frac{1}{1+ \exp(-ax)}&lt;/script&gt;的认识。在这个函数中，&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;控制了曲线多么接近&lt;script type=&quot;math/tex&quot;&gt;0-1&lt;/script&gt;损失函数：值越大，越接近。然而，在矩阵分解中，任何对于&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;的更新（例如把其值增大两倍），都可以利用更改其对应的所有&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}_{i}&lt;/script&gt;来达到恢复其之前的状态（例如把其值除以一半）。这样，更新&lt;script type=&quot;math/tex&quot;&gt;\mathbf{U}_{u}&lt;/script&gt;并不一定逼近&lt;script type=&quot;math/tex&quot;&gt;0-1&lt;/script&gt;损失函数。换句话说，我们必须要对&lt;script type=&quot;math/tex&quot;&gt;\mathbf{V}&lt;/script&gt;进行限制，不能无限制得任其发展。&lt;/p&gt;

&lt;h2 id=&quot;文章提出的模型&quot;&gt;文章提出的模型&lt;/h2&gt;

&lt;p&gt;有了上面的铺垫，作者们提出了一种新的损失函数，那就是把单点损失函数，基于物品的配对损失函数以及基于用户的配对损失函数结合起来，形成一个三个损失函数的某种平衡。&lt;/p&gt;

&lt;p&gt;我们已经定义了单点损失函数，那这里就来看看一下基于物品的配对损失函数。作者们使用了一个叫Bradley-Terry模型来针对某个用户的两个物品进行比较的概率进行建模：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(r_{ui_{1}} &gt; r_{ui_{2}}) = \frac{\exp(\mathbf{U}_{u}\mathbf{V}_{i_{1}}^{T})}{\exp(\mathbf{U}_{u}\mathbf{V}_{i_{1}}^{T}) + \exp(\mathbf{U}_{u}\mathbf{V}_{i_{2}}^{T})}&lt;/script&gt;

&lt;p&gt;在有了这个概率之后，我们最小化其“负对数似然”（Negative Log Likelihood）:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{\mathrm{row-wise}} = - \sum_{(u, i_{1}, i_{2}) \in \Omega} \log P(r_{ui_{1}} &gt; r_{ui_{2}}) + \sum_{v} \lambda_{V,v}||\mathbf{V}_{v}||^{2}&lt;/script&gt;

&lt;p&gt;非常类似的，我们还可以定义基于用户的配对损失函数，得到：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{\mathrm{column-wise}} = - \sum_{(u_{1} u_{1}, i) \in \Psi} \log P(r_{u_{1}i} &gt; r_{u_{2}i}) + \sum_{u} \lambda_{U,u}||\mathbf{U}_{u}||^{2}&lt;/script&gt;

&lt;p&gt;于是我们可以定义最终的统一的损失函数为：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L = \alpha L_{\mathrm{row-wise}} + \beta L_{\mathrm{column-wise}} + (1-\alpha -\beta) L_{\mathrm{pointwise}}&lt;/script&gt;

&lt;p&gt;其中，$\alpha \in [0, 1]$和$\beta \in [0, 1]$，并且&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\alpha + \beta &lt;1 %]]&gt;&lt;/script&gt;。作者们认为，这个新的损失函数可以解决之前提出的问题。针对这个新的目标函数，文章提出了详细的优化算法，这里就不赘述了。作者们提出的模型在MovieLens、Netflix以及Amazon的数据集上都要优于不使用排序的纯矩阵分解模型以及一般的协同排序算法。&lt;/p&gt;
</description>
        <pubDate>Sat, 01 Dec 2018 00:00:00 -0800</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2018/12/01/cikm2018-pr/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2018/12/01/cikm2018-pr/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>AISTATS 2018论文导读</title>
        <description>&lt;p&gt;2018年的第21届人工智能和统计学大会（The 21st International Conference on Artificial Intelligence and Statistics）在加那利群岛（Canary Islands）召开。我们在这篇短文里提供一些论文的快速导读，起到抛砖引玉的作用。&lt;/p&gt;

&lt;h2 id=&quot;论文导读&quot;&gt;论文导读&lt;/h2&gt;
&lt;hr /&gt;

&lt;h3 id=&quot;boosting-variational-inference-an-optimization-perspective&quot;&gt;Boosting Variational Inference: an Optimization Perspective&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/locatello18a/locatello18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/locatello18a/locatello18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章主要是说最近提出的Boosting Variational Inference（BVI）是把Boosting的思想和Variational Inference相结合的一个新的研究方向，只不过这个方向目前并没有太多的理论支持。这篇论文通过和Frank-Wolfe算法建立联系从而对BVI的收敛性质进行了证明。本篇文章基本上是一个纯理论工作。&lt;/p&gt;

&lt;p&gt;之前的BVI的主要论文是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fangjian Guo, Xiangyu Wang, Kai Fan, Tamara Broderick, David B. Dunson:
&lt;a href=&quot;https://arxiv.org/abs/1611.05559&quot;&gt;Boosting Variational Inference&lt;/a&gt;. CoRR abs/1611.05559 (2016)&lt;/li&gt;
  &lt;li&gt;Andrew C. Miller, Nicholas J. Foti, Ryan P. Adams:
&lt;a href=&quot;http://proceedings.mlr.press/v70/miller17a.html&quot;&gt;Variational Boosting: Iteratively Refining Posterior Approximations&lt;/a&gt;. ICML 2017: 2420-2429&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;personalized-and-private-peer-to-peer-machine-learning&quot;&gt;Personalized and Private Peer-to-Peer Machine Learning&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/bellet18a/bellet18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/bellet18a/bellet18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章主要是把“隐私”（Privacy）领域和优化领域相结合，寻找一种可以保护每一个“个体”（Agent）的隐私但同时能够进行协作从而让最终的优化算法能够达到最优的情况。这方面的研究其实有很多现实的应用。例如说在手机应用中，传统的模式是让所有的手机把数据都集中到服务器上，然后在服务器端再进行机器学习。这种模式很明显具有最高的数据效率但是有可能对用户的数据隐私有侵害。而另一个极端则是把在每个手机上直接进行学习。然而，因为数据有限，这样往往无法学习到有用的模型。这篇文章就是提出了一种如何在这两个极端之间寻求平衡的“异步”（Asynchronous）分布式算法。&lt;/p&gt;

&lt;h3 id=&quot;fast-threshold-tests-for-detecting-discrimination&quot;&gt;Fast Threshold Tests for Detecting Discrimination&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/pierson18a/pierson18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/pierson18a/pierson18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章说的是“阈值测试”（Threshold Test）在过去被提出来用于检测在一些社会活动（比如租房、招聘、警察活动等）中可能存在的“歧视”或“偏差”（Bias)。这篇文章则是提出了快速计算方法使得这样的测试能够快速进行。文章在270万纽约市警察阻止路人的数据集上进行了评测。这篇文章主要是帮助大家扩宽眼界，对于社会性的偏差，目前在学术界已经出现了专门的方法论。&lt;/p&gt;

&lt;h3 id=&quot;batch-expansion-training-an-efficient-optimization-framework&quot;&gt;Batch-Expansion Training: An Efficient Optimization Framework&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/derezinski18b/derezinski18b.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/derezinski18b/derezinski18b-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章讲的是这样一种优化的场景，那就是一个不断增大的数据集，如何在这样的情况下进行“批量”（Batch）学习。这种场景和传统的“随机”（Stochastic）学习不同，因为可以更加有效得利用资源，减少磁盘的读取。这篇文章提出的方法可以和任意的其他优化算法结合，比如L-BFGS。文章展示了提出的方法的很强的收敛性质和以及在并行化下的效果。&lt;/p&gt;

&lt;h3 id=&quot;topic-compositional-neural-language-model&quot;&gt;Topic Compositional Neural Language Model&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/wang18a/wang18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/wang18a/wang18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;自从Neural Language Model（NLM）流行以来，期望能够把NLM和话题模型（Topic Model）进行结合的想法就屡见不鲜。这篇论文也是这个方向的一次尝试。NLM的主要优势是在句子以下的结构上对字句进行建模，而话题模型则往往能够在真个文档甚至更高的层次上对文本的语义进行建模。把这两者结合起来就是想利用这两方面的优势。在这篇文章里，话题模型通过Variational Autoencoder的框架来捕捉到文档的话题（Topic）隐变量。之后，这个变量成为了对不同的语言模型进行加权的权重，而语言文字的产生则利用了Mixture-of-Experts的框架来对不同的RNN语言模型进行整合。需要注意的是，在这篇文章提出的方法里，话题模型对文字的整体数据和语言模型对单独的字句都进行了建模，也就是说，一个文档分别有两个产生过程，一个针对全局文字，一个针对有顺序的字句。&lt;/p&gt;

&lt;h3 id=&quot;making-tree-ensembles-interpretable-a-bayesian-model-selection-approach&quot;&gt;Making Tree Ensembles Interpretable: A Bayesian Model Selection Approach&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/hara18a/hara18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/hara18a/hara18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;最近几年，机器学习的可解释性是一个新的研究领域，不少工作都围绕在如何能够让已经学习的模型或者在学习过程中产生容易被解释的模型。这篇文章针对的是“树集成”（Tree Ensembles）模型，希望通过贝叶斯模型选择（Bayesian Model Selection）的方法来对树模型进行简化从而达到能够可解释的目的。这篇文章的一个可以借鉴也可以精读的地方在于如何把树模型变为概率模型。传统上树模型的整套建模语言都是非概率的，那么如果要使用贝叶斯统计的方法，就一定需要做概率的转换。&lt;/p&gt;

&lt;h3 id=&quot;can-clustering-scale-sublinearly-with-its-clusters-a-variational-em-acceleration-of-gmms-and-k-means&quot;&gt;Can Clustering Scale Sublinearly with Its Clusters? A Variational EM Acceleration of GMMs and K-means&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/forster18a/forster18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/forster18a/forster18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;高斯混合模型（GMM）和K-means都是我们非常熟悉的聚类算法。然而传统上，这两个模型的解法都是和聚类数目C、数据点数N、以及数据的维度D呈线性关系。能不能在这个基础上再加速成为了很多实践者的疑问和困难。这篇文章是希望利用Variational EM来化简整个算法，使得其不依赖于C，而依赖于一个较小的参数G。这篇文章是典型的老树开新花的尝试。&lt;/p&gt;

&lt;h3 id=&quot;parallelised-bayesian-optimisation-via-thompson-sampling&quot;&gt;Parallelised Bayesian Optimisation via Thompson Sampling&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/kandasamy18a/kandasamy18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/kandasamy18a/kandasamy18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;贝叶斯优化（Bayesian Optimisation），或者简称BO，常常用来针对复杂而且昂贵（Expensive）的函数评价，例如超参数（Hyper-parameter）的调节。针对有一些可以并行化的情况下，这篇论文提出了使用“汤姆森采样”（Thompson Sampling）的方法来应对并行的场景有惊人好的效果，并且这篇文章最终提出了“异步并行化的汤姆森采样”。作者们认为这篇文章的一大亮点是给出了理论的结论，这在过去尝试把BO并行化的工作中并不多见。&lt;/p&gt;

&lt;h3 id=&quot;on-the-challenges-of-learning-with-inference-networks-on-sparse-high-dimensional-data&quot;&gt;On the challenges of learning with inference networks on sparse, high-dimensional data&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/krishnan18a/krishnan18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/krishnan18a/krishnan18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章其实是在针对Variational Autoencoder，或者简称VAE，在训练的时候的一个普遍问题，那就是作者们认为VAE在计算过程中并没有最优化Variational参数，而仅仅是找到了或者说是计算出了一组解。因此，作者们认为VAE存在Underfitting的情况，就是说模型的参数学习得不完全。而在传统的Stochastic Variational Learning的语境中，每一步都是根据当前的参数进行的最优化。于是，这篇文章就是把这种思路给应用到VAE上。&lt;/p&gt;

&lt;h3 id=&quot;scalable-generalized-dynamic-topic-models&quot;&gt;Scalable Generalized Dynamic Topic Models&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/jahnichen18a/jahnichen18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/jahnichen18a/jahnichen18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Dynamic Topic Model（DTM）相信作为对话题模型（Topic Model）研究者都会不陌生。这可以说是最有影响力的话题模型的扩展。DTM是把时间序列和话题模型结合在一起最直观的一种模型。这篇文章指出，其实DTM提出的模型仅仅是一种叫Weiner Processes（WP）的一个特殊情况。而把DTM给扩展到WP以后，作者们认为就可以使用各种不同的WP的Kernel来对时序建模，大大增强模型的效果。这篇文章还给出了大规模的Variational Inference的模型解法。&lt;/p&gt;

&lt;h3 id=&quot;direct-learning-to-rank-and-rerank&quot;&gt;Direct Learning to Rank And Rerank&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v84/rudin18a/rudin18a.pdf&quot;&gt;PDF&lt;/a&gt;
&lt;a href=&quot;http://proceedings.mlr.press/v84/rudin18a/rudin18a-supp.pdf&quot;&gt;Supplementary PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;“排序学习”（Learning to Rank）是不是一个已经完全被研究过的领域呢？答案当然不是。这篇论文就是尝试在一个似乎已经被反复研究过的领域里找到一些新的知识。这篇论文的看点主要是使用了一种目标函数对已有的排序指标例如AUC、NDCG、MAP、MRR等进行了高度总结。另外，这篇文章提出，传统上，我们在优化这些方法或者这些指标的时候，并不是直接去优化这些指标，而是优化这些指标的一些“代理”（Proxy），而就是这些代理可能出了问题，使得最后的结果有可能会有很大的偏差。于是，这篇文章提出了一种直接优化目标函数的方法。&lt;/p&gt;
</description>
        <pubDate>Fri, 25 May 2018 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2018/05/25/aistats2018/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2018/05/25/aistats2018/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>Facebook的应用机器学习平台</title>
        <description>&lt;p&gt;我们在这里对Facebook应用机器学习（Applied Machine Learning）组发布的文章&lt;a href=&quot;https://research.fb.com/publications/applied-machine-learning-at-facebook-a-datacenter-infrastructure-perspective/&quot;&gt;Applied Machine Learning at Facebook: A Datacenter Infrastructure Perspective&lt;/a&gt;进行一个简单的分析解读。这篇文章可以让我们对Facebook里机器学习平台以及各个产品应用这个平台的情况有一个很不错的了解。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://research.fb.com/wp-content/uploads/2017/12/hpca-2018-facebook.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自Facebook的17位工程师和科学家。这些人可能仅仅是整个平台的骨干成员。可以看出整个Facebook的机器学习平台是一个有非常多人协作搭建的复杂环境。&lt;/p&gt;

&lt;p&gt;这篇文章可以说是帮助外界解惑了很多迷思或者说是误解。同时，也给了大家一个学习大型互联网公司构建机器学习平台的机会。文章首先提出了一系列的重要观察：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Facebook有很多机器学习的应用场景。计算机视觉的应用仅仅是一个小部分。&lt;/li&gt;
  &lt;li&gt;Facebook有一个很丰富的机器学习库，包括Support Vector Machines、Logistic Regression、GBDT、MultiLayer Perceptron、CNN和RNN。&lt;/li&gt;
  &lt;li&gt;Facebook目前的机器学习场景同时利用GPU和CPU。在训练的时候，有很多是根据需要使用GPU和CPU，但是在Inference的时候，绝大多数还是使用CPU。&lt;/li&gt;
  &lt;li&gt;Facebook的机器学习架构很在乎分布式训练。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文章中列举了一些主要的Facebook机器学习应用场景包括我们熟知的News Feed、Ads和Search以外，还包括一些不那么为人知的应用，如Sigma（Facebook内部的Anomaly Detection的框架）、Lumos（看似是Image的Embedding和信息提取工具）、Facer（Facebook人脸识别框架）、Language Translation（顾名思义，就是一个语言翻译的平台）以及Speech Recognition（顾名思义，一个语音识别的平台）。由此可见，机器学习在Facebook里已经有了很广泛的应用。&lt;/p&gt;

&lt;p&gt;那么，这些应用究竟在使用什么模型呢？Facer在使用SVM。Sigma在使用GBDT。Ads、News Feed和Sigma都在使用MLP。而Lumos、Facer在使用CNN。Text Understanding、Translation、Speech Recognition在使用RNN。&lt;/p&gt;

&lt;p&gt;对于深度学习框架方面，目前Facebook支持两个框架：Caffe2和PyTorch。它们分别是生产环境和研究环境。作者们阐述了一下为什么要让这两个环境各不同。简而言之就是这两个环境的需求不用，一个要求稳定高效，一个要求能够灵活多变。当然，作者们也看到了多个深度学习框架带来的潜在问题。于是作者们提到了一个叫做Open Neural Network Exchange（ONNX）的交换格式。想来这个交换格式就是为了加快从一个框架到另外一个框架的转换速度。&lt;/p&gt;

&lt;p&gt;从模型训练的时效性来看，有些应用的训练是每天，比如News Feed，而Search是每个小时，而其他应用则有些是每个星期或者每好几个月。而在Inference来看，第一，作者们提到了，不同的应用有可能需要不同的Inference的架构（Architecture）。同时，作者们还提到了并不是一开始就需要最精确的预测，有时候可以先展现给用户看没那么精确的结果，然后更加精确的结果可以算好以后再推给用户。&lt;/p&gt;

&lt;p&gt;这篇文章还有很多细节的点值得关注。总之，如果你对机器学习在大型互联网公司的应用有兴趣，并且也想知道平台、软硬件的整体架构信息，这篇文章是一个不错的阅读材料。&lt;/p&gt;
</description>
        <pubDate>Fri, 22 Dec 2017 00:00:00 -0800</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/12/22/facebook-ml/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/12/22/facebook-ml/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>KDD 2017大会综述</title>
        <description>&lt;p&gt;每年，Association for Computing Machinery（ACM）旗下的Special Interest Group (SIG) on Knowledge Discovery and Data Mining（简称SIGKDD）都要举办年度的SIGKDD Conference on Knowledge Discovery and Data Mining（KDD）大会，为学术界和工业界的数据科学学者、研究人员、工程师以及学生提供一个交流、学习和发展的平台。今年，The 23rd SIGKDD Conference on Knowledge Discovery and Data Mining（KDD）于2017年8月13日到17日在加拿大的Halifax, Nova Scotia举行。&lt;/p&gt;

&lt;p&gt;KDD是数据挖掘以及数据科学领域的顶级会议。KDD最早从1989年开始的KDD 研讨班（Workshop）发展而来。当时的研讨班依托于IJCAI大会或者AAAI大会（另一个有影响力的人工智能大会），由Gregory Piatetsky-Shapiro创办。研讨班成功举办几届之后，1995年Usama Fayyad和Ramasamy (Sam) Uthurusamy把研讨班升级成为了会议，并且在加拿大的蒙特利尔举办了第一届的KDD大会。大会至今已经有20多年的历史。&lt;/p&gt;

&lt;h2 id=&quot;大会主要奖项&quot;&gt;大会主要奖项&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;今年的SIGKDD创新奖（ Innovation Award）授予了加拿大Simon Fraser University计算科学学院的教授Jian Pei。Jian是数据挖掘界的著名华人学者，是ACM和IEEE的双料院士。其发表过200多篇论文，引用量多达7万多次，Google H-Index达到74。他和Jiawei Han以及Micheline Kamber合著的数据挖掘教材《Data mining: Concepts And Techniques》已经成为经典读物，引用数就多于3万次。Jian还是IEEE 旗下的数据挖掘权威期刊Transactions of Knowledge and Data Engineering （TKDE）的主编，并且是清华大学以及浙江大学的客座教授。在此之前，Jian已经获得过2015年的SIGKDD服务奖（ Service Award）、 2014年 IEEE旗下数据挖掘会议 ICDM 的研究贡献奖（Research Contributions Award） ，以及2008年KDD 最佳应用论文奖（Best Application Paper Award）、2014年PAKDD 最佳论文奖（Best Paper Award）等。Jian是数据挖掘领域权威Jianwei Han的博士生（2002年毕业）。这次创新奖主要还提及了Jian在Sequential Pattern Mining（SPM）数据挖掘算法和研究领域的主要贡献，包括FP-Growth 和PrefixSpan算法。这两个算法都是著名的SPM算法，其中FP-Growth的论文（Mining Frequent Patterns without Candidate Generation）引用高达7千多次，而PrefixSpan的论文（PrefixSpan: Mining Sequential Patterns Efficiently by Prefix-Projected Pattern Growth）引用也多达2千多次。&lt;/p&gt;

&lt;p&gt;大会的另外一个重要奖项SIGKDD时间检验奖（Test of Time Award）授予了美国康奈尔大学信息科学系主任、计算机科学系教授Thorsten Joachims。这个时间检验奖主要是奖给过去10年左右的时间里在KDD的会议上发表的论文中最有影响力的工作（引用次数是其中一个指标）。Thorsten是机器学习界享有盛誉的学者，是ACM和AAAI的双料院士。所有论文超过4万次引用。他2001年在德国的多特蒙德大学博士毕业之后加入康奈尔大学从事机器学习的研究。在获得这个奖项之前，Thorsten获得过2017年ACM WSDM 的最佳论文奖（Best Paper Award）、2016年ACM SIGIR的时间检验奖（Test-of-Time Award）、2015年ACM KDD的时间检验奖、2009年ECML的最佳论文奖（Best Paper Award）、2009年ICML的10年最佳论文奖（Best 10-Year Paper Award）、2006年ACM KDD的最佳论文奖（Best Paper Award）、2005年ICML的最佳论文奖、2005年ICML的优秀学生论文奖、2005年ACM KDD的最佳学生论文奖等。这次时间检验奖授予Thorsten是为了表彰他的论文“Training Linear SVMs in Linear Time”。该论文也是2006年的KDD最佳论文，引用数超过1600多次。这篇文章解决的是大规模优化支持向量机（Support Vector Machines）的问题。在此之前的很多支持向量机的实现都无法达到线性的时间复杂度，因此也就无法应用到大规模的数据上。这篇文章是第一次提出了简单易行的支持向量机实现。算法对于分类问题（Classification）达到了O(SN)（其中S是非0的特征数目而N是数据点的个数），也就是实现了线性时间复杂度。算法本身简单、高效、易于实现，并且理论上可以扩展到Kernel的情况。Thorsten在他的软件包SVMLight中实现了该算法。这个软件包一度成为了支持向量机研究和开发的标准工具。&lt;/p&gt;

&lt;p&gt;大会还把今年的SIGKDD服务奖（Service Award）颁给了香港科技大学计算机系主任Qiang Yang教授，以表彰他在近几年推动SIGKDD的各种活动发展，特别是SIGKDD在中国的分部（China Chapter）所做的努力。Qiang本人是ACM杰出科学家、AAAI院士、IEEE院士。在他的领导下，2016年，SIGKDD中国分部开始运营。2016年一年，中国分部就举行了超过10场活动，并且吸引了超过500名会员。Qiang在中国还举行了多场研讨班和各类讲座，分享了关于Transfer Learning以及Recommendation Systems相关的很多研究成果。Qiang Yang本人的论文有超过3万次的引用。&lt;/p&gt;

&lt;p&gt;从会议论文的角度来看，这次会议的最佳研究类论文（Best Research Paper Award）授予了“ Accelerating Innovation Through Analogy Mining”，其作者群来自耶路撒冷希伯来大学以及卡内基梅隆大学。第二名则被“Toeplitz Inverse Covariance-Based Clustering of Multivariate Time Series”夺取，其作者群来自斯坦福大学。最佳应用数据科学论文（Best Applied Data Science Paper Award）被“HinDroid: An Intelligent Android Malware Detection System”取得，其作者群来自于西弗吉尼亚大学以及香港科技大学。第二名则被“DeepSD: Generating High Resolution Climate Change Projections”夺得，其作者群来自美国的东北大学以及美国NASA。&lt;/p&gt;

&lt;h2 id=&quot;大会参与概况&quot;&gt;大会参与概况&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;今年的大会是在美国本土外举办的最大的一届KDD会议。整个大会有1656名参会者，来自51个国家和地区。其中美国的参会者是最多、其次是中国、加拿大、印度。会议的赞助金额达到了54万美元，是在美国本土外举办的最高记录。为赞助学生旅行，大会总共奖励了高达15多万美元的金额，创下了大会的记录。论文的投稿数达到了1143篇，也是创下了最新的记录。大会最终录用了130篇文章，录用率在8%左右。可以说依然保持了非常高的会议水平。&lt;/p&gt;

&lt;p&gt;这次大会共有3个主题演讲（Keynote Speech）。64个报告演讲（Oral Presentation）和66个展板报告（Poster）。整个大会还有10个全天的研讨班（Workshop）和10个半天的闫天宝。大会包含了20个传统的讲座（Tutorial）以及8个实践（Hands-on）讲座。&lt;/p&gt;

&lt;h2 id=&quot;大会主题演讲&quot;&gt;大会主题演讲&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这次的大会主题演讲有一个特色，那就是三位女性科学家组成的主题演讲者群体。&lt;/p&gt;

&lt;p&gt;大会第一个主题演讲来自Bin Yu，加州大学伯克利分校（University of California at Berkeley
）统计学教授。Bin Yu是美国科学院院士（U.S. National Academy of Sciences）、美国艺术与科学学院院士（American Academy of Arts and Sciences），还是IEEE院士、IMS院士、 ASA院士以及 AAAS院士。她长期从事统计、机器学习方法的研究以及如何应用领域知识解决复杂问题。Bin还是微软和北京大学统计和信息科学联合实验室的创始人。Bin的演讲主题是“Three Principles of Data Science: Predictability, Stability, and Computability”，主要试图讲解的是Stability对于Predictability以及Interpretability的重要性。Bin认为自己提出的这三个要素是统计学习的根本思想之一，他们之间的联系尤为重要。紧接着，她通过如何应用深度模型（特别是卷积神经网CNN）对神经元的活动进行观测这一个项目解释了这三个要素在具体事例中的呈现。她在演讲的第二部分讲解了如何利用隐变量模型（Latent Variable Models）以及基于LASSO的模型来分析政治性的电视广告中的语气和政党倾向性。这两个项目都展现了Bin所谓的稳定性（Stability）对于预测性（Predictability）的重要性。&lt;/p&gt;

&lt;p&gt;第二个主题演讲来自Cynthia Dwork，哈佛大学教授、微软研究院杰出科学家（Distinguished Scientist）。Cynthia是美国科学院院士（National Academy of Sciences）、美国工程院院士（National Academy of Engineering）、美国艺术与科学学院院士（American Academy of Arts and Sciences）、美国哲学学会院士（American Philosophical Society）以及ACM院士。Cynthia长期致力于基于隐私的数据分析（Privacy-Preserving Data Analysis）的工作，并且是著名的Differential Privacy思想的提出者之一。2015年获得理论计算机界的哥德尔奖。Cynthia演讲的主题是“What’s Fair?”。这个是一个近期越来越收到关注的题目，那就是人工智能或者机器学习算法会不会因为从过去的数据中学习从而带有过去的偏见。典型的偏见有比如在预测犯罪的时候，对某一个种族或者族群会有高于常规的预测率。这个演讲就是讨论了包括如何定义是否“公平”，如何算是有偏见，到底是个人偏见还是群体偏见等等问题。从现场的反应来看，总体感觉，算法的公平性或者偏见性是一个非常新、而且可能会有争议性的话题。Cynthia在这个场合提出来也是需要一定勇气和远见的。&lt;/p&gt;

&lt;p&gt;第三个主题演讲来自Renée J. Miller，多伦多大学信息系统系主任、计算机系教授。Renée是加拿大皇家协会院士（Royal Society of Canada）、加拿大科学院院士（Canada’s National Academy）以及ACM院士。Renée是一个具有神秘色彩的学者。大会网站上并没有放她的照片，原因是她不愿意自己的相貌被搜索引擎给准确记住。Renée的演讲主题是“The Future of Data Integration”。应该说这个主题放在一个以数据科学为核心的会议上还是很应景的。毕竟，很多都说数据科学80%甚至更多的时间在处理数据而只有20%的时间在做真正的算法和模型革新。Renée从数据库领域出发，用非常浅显的语言讲解了这20年数据集成（Data Integration）领域的主要发现，以及如何利用这些核心算法来达到“发掘数据和整个数据格式”的作用。&lt;/p&gt;

&lt;h2 id=&quot;大会的几个趋势&quot;&gt;大会的几个趋势&lt;/h2&gt;
&lt;hr /&gt;

&lt;p&gt;这次会议有这么几个趋势和亮点：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;大家更加重视模型，特别是深度学习模型的可解释性。&lt;/li&gt;
  &lt;li&gt;Causal Inference和Machine Learning的结合成为新方向。&lt;/li&gt;
  &lt;li&gt;对算法和模型的去Bias成为一个新的课题。&lt;/li&gt;
  &lt;li&gt;各大公司的招聘力度非常大，在某一天内就有Amazon、Microsoft、Airbnb、Snapchat、Pinterest以及其它公司的Happy Hour，感觉人才就在那么几家公司赶场。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;总体最大的感觉是KDD已经成为了数据科学的盛宴。&lt;/p&gt;
</description>
        <pubDate>Wed, 30 Aug 2017 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E4%BC%9A%E8%AE%AE/2017/08/30/kdd2017/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E4%BC%9A%E8%AE%AE/2017/08/30/kdd2017/</guid>
        
        
        <category>会议</category>
        
      </item>
    
      <item>
        <title>ACL 2017文章精读（五）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://acl2017.org/&quot;&gt;ACL 2017&lt;/a&gt;文章From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.07926&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/kelvinguu/lang2program&quot;&gt;代码地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自斯坦福大学。主要的作者们来自Percy Liang的实验室。最近几年Percy Liang的实验室可以说收获颇丰，特别是在自然语言处理（NLP）和深度学习（Deep Learning）的结合上都有不错的显著成果。&lt;/p&gt;

&lt;p&gt;这篇文章里有好一些值得关注的内容。首先从总体上来说，这篇文章要解决的问题是怎么从一段文字翻译成为“程序”的问题。这可以说是一个很有价值的问题。如果这个问题能够可以容易解决，那么我们就可以教会计算机编写很多程序，而不一定需要知道程序语言的细微的很多东西。从细节上说，这个问题就是，给定一个输入的语句，一个模型需要把目前的状态转移到下一个目标状态上。这里面的难点是，对于同一个输入语句，从当前的状态到可能会到达多种目标状态。这些目标状态都有可能是对当前输入语句的一种描述。但是正确的描述其实是非常有限的，甚至是唯一的。那么，如何从所有的描述中，剥离开不正确的，找到唯一的或者少量的正确描述，就成为了这么一个问题的核心。&lt;/p&gt;

&lt;p&gt;文章中采用了一个Neural Encoder-Decoder的模型架构。这种模型主要是对序列信息能够有比较好的效果。具体说来，那就是对于现在的输入语句，首先把输入语句变换成为一个语句向量，然后根据之前已经产生的程序状态，以及当前的语句向量，产生现在的程序状态。在这个整个的过程中，对于Encoder作者们采用了LSTM的架构，而对于Decoder作者们采用了普通的Feed-forward Network（原因文章中是为了简化）。另外一个比较有创新的地方就是作者们把过于已经产生程序状态重新给Embedding化（作者们说是叫Stack）。这有一点模仿普通数据结构的意思。&lt;/p&gt;

&lt;p&gt;那么，这个模型架构应该说还是比较经典的。文章这时候就引出了另外一个本文的主要贡献，那就是对模型学习的流程进行了改进。为了引出模型学习的改进，作者们首先讨论了两种学习训练模式的形式，那就是强化学习（Reinforcement Learning）以及MML（Maximum Marginal Likelihood）的目标函数的异同。文章中提出两者非常类似，不过比较小的区别造成了MML可以更加容易避开错误程序这一结果。文章又比较了基于REINFORCE算法的强化学习以及基于Numerical Integration以及Beam Search的MML学习的优劣。总体说来，REINFORCE算法对于这个应用来说非常容易陷入初始状态就不太优并且也很难Explore出来的情况。MML稍微好一些，但依然有类似问题。文章这里提出了Randomized Beam Search来解决。也就是说在做Beam Search的时候加入一些Exploration的成分。另外一个情况则是在做Gradient Updates的时候，当前的状态会对Gradient有影响，也就是说，如果当前状态差强人意，Gradient也许就无法调整到应该的情况。这里，作者们提出了一种叫Beta-Meritocratic的Gradient更新法则，来解决当前状态过于影响Gradient的情况。&lt;/p&gt;

&lt;p&gt;实验的部分还是比较有说服里的，详细的模型参数也是一应俱全。对于提出的模型来说，在三个数据集上都有不错的表现。当然，从准确度上来说，这种从文字翻译到程序状态的任务离真正的实际应用还有一段距离。&lt;/p&gt;

&lt;p&gt;这篇文章适合对于最近所谓的Neural Programming有兴趣的读者泛读。对怎么改进强化学习或者MML有兴趣的读者精读。文章的“Related Work”部分也是非常详尽，有很多工作值得参考。&lt;/p&gt;
</description>
        <pubDate>Mon, 07 Aug 2017 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/08/07/acl2017-language-to-program/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/08/07/acl2017-language-to-program/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>ACL 2017文章精读（四）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://acl2017.org/&quot;&gt;ACL 2017&lt;/a&gt;文章Learning to Skim Text进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.06877&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自Google。这篇文章是第一作者来自卡内基梅隆大学的Adams Wei Yu在Google实习的时候做的工作。第三作者的Quoc V. Le曾是Alex Smola和Andrew Ng的高徒，在Google工作期间有很多著名的工作，比如Sequence to Sequence Model来做机器翻译（Machine Translation）等。&lt;/p&gt;

&lt;p&gt;这篇文章想要解决的的问题叫做“Skim Text”。简单说来，就是在文字处理的时候，略过不重要的部分，对重要的部分进行记忆和阅读。也就是说，要教会模型知道在哪里需要略过不读，哪里需要重新开始阅读的能力。略过阅读的另外一个好处则是对文字整体的处理速度明显提高，而且很有可能还会带来质量上的提升（因为处理的噪声信息少了、垃圾信息少了）。&lt;/p&gt;

&lt;p&gt;具体说来，这篇文章是希望在LSTM的基础上加入“跳转”功能，从而使得这个时序模型能够有能力判读是否要略过一部分的文字信息。简单说来，作者们是这么对LSTM进行改进的。首先，有一个参数R来确定要读多少文字。然后模型从一个0到K的基于Multinomial分布的这一个跳转机制中决定当前需要往后跳多少文字（可以是0，也就是说不跳转）。这个是否跳转的这一个步骤所需要的Multinomial分布，则也要基于当期那LSTM的隐参数信息（Hidden State）。跳转决定以后，根据这个跳转信息，模型会看一下是否已经达到最大的跳转限制N。，如果没有则往后跳转。当所有的这些步骤都走完，达到一个序列（往往是一个句子）的结尾的时候，最后的隐参数信息会用来对最终需要的目标（比如分类标签）进行预测。&lt;/p&gt;

&lt;p&gt;这篇文章的另外一个创新点，也就是引入了强化学习（Reinforcement Learning）到模型的训练中。最终从隐参数到目标标签（Label）的这一步往往采用的是Cross Entropy的优化目标函数。这一个选择很直观，也是一个标准的步骤。然而，如何训练跳转的Multinomial分布，因为其离散（Discrete）特质，则成为文章的难点。原因是Cross Entropy无法直接应用到离散数据上。那么，这篇文章采取的思路是把这个问题构造成为强化学习的例子，从而使用最近的一些强化学习思路来把这个离散信息转化为连续信息。具体说来，就是采用了Policy Gradient的办法，在每次跳转正确的时候，得到一个为+1的反馈，反之则是-1。这样就把问题抓换成为了学习跳转策略的强化学习模式。文章采用了REINFORCE的算法来对这里的离散信息做处理。从而把Policy Gradient的计算转换为了一个近似逼近。这样，最终的目标函数来自于三个部分，第一个部分是Cross Entropy，第二个部分是Policy Gradient的逼近，第三个部分则是一个Variance Reduction的控制项（为了优化更加有效）。整个目标函数就可以完整得被优化了。&lt;/p&gt;

&lt;p&gt;文章在好多种实验类型上做了实验，主要比较的就是没有跳转信息的标准的LSTM。其实总体上来说，很多任务（Task）依然比较机械和人工。比如最后的用一堆句子，来预测中间可能会出现的某个词的情况，这样的任务其实并不是很现实。但是，文章中提到了一个人工（Synthetic）的任务还蛮有意思，那就是从一个数组中，根据下标为0的数作为提示来跳转取得相应的数作为输出这么一个任务。这个任务可以说是充分的展示了LSTM这类模型，以及文章提出的模型的魅力：第一，可以非常好的处理这样的非线性时序信息，第二，文章提出的模型比普通的LSTM快不少，并且准确度也提升很多。&lt;/p&gt;

&lt;p&gt;总体说来，这篇文章非常值得对时序模型有兴趣的读者精读。文章的“Related Work”部分也很精彩，对相关研究有兴趣的朋友可以参考这部分看看最近都有哪些工作很类似。&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Aug 2017 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/08/06/acl2017-skim-text/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/08/06/acl2017-skim-text/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>ACL 2017文章精读（三）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://acl2017.org/&quot;&gt;ACL 2017&lt;/a&gt;文章Towards End-to-End Reinforcement Learning of Dialogue Agents for Information Access进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1609.00777&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/MiuLab/KB-InfoBot&quot;&gt;代码地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自于微软研究院、卡内基梅隆大学和台湾国立大学。文章中还有Lihong Li和Li Deng（邓力）这样的著名学者的影子。第一作者的Bhuwan Dhingra是在卡内基梅隆大学William W. Cohen和Ruslan Salakhutdinov的博士学生。两位导师都十分有名气。而这个学生这几年在NLP领域可以说是收获颇丰：在今年的ACL上已经发表2篇文章，之前在今天的ICLR和AAAI上都有论文发表。&lt;/p&gt;

&lt;p&gt;这篇文章的核心思想是如何训练一个多轮（Multi-turn）的基于知识库（Knowledge Base）的对话系统。这个对话系统的目的主要还是帮助用户从这个知识库中来获取一些信息。那么，传统的基于知识库的对话系统的主要弊病在于中间有一个步骤是对于“知识库的查询”。也就是说，系统必须根据用户提交的查询（Query），进行分析并且产生结果。这一步，作者们称为“硬查询”（Hard-Lookup）。虽然这一步非常自然，但是这一步阻断了（Block）了整个流程，使得整个系统没法“端到端”（End-to-End）进行训练。并且，这一步由于是“硬查询”，并没有携带更多的不确定信息，不利于系统的整体优化。&lt;/p&gt;

&lt;p&gt;这篇文章其实就是想提出一种“软查询”从而让整个系统可以得以“端到端”（End-to-End）得进行训练。这个新提出的“软查询”步骤，和强化学习（Reinforcement Learning）相结合，共同完成整个的回路，从而在这个对话系统上达到真正的“端到端”。这就是整个文章的核心思想。&lt;/p&gt;

&lt;p&gt;那么，这个所谓的“软查询”是怎么回事？其实就是整个系统保持一个对知识库中的所有本体（Entities）所可能产生的值的一个后验分布（Posterior Distribution）。也就是说，作者们构建了这么一组后验分布，然后可以通过对这些分布的更新（这个过程是一个自然获取新数据，并且更新后验分布的过程），来对现在所有本体的确信度有一个重新的估计。这一步的转换，让对话系统从和跟知识库直接打交道，变成了如何针对后验分布打交道。而显然，从机器学习的角度来说，和分布打交道往往容易简单很多。具体说来，系统的后验分布是一个关于用户在第T轮，针对某个值是否有兴趣的概率分布。&lt;/p&gt;

&lt;p&gt;整个对话系统是这样运行的。首先，用户通过输入的对话（Utterance）来触发系统进行不同的动作（Action）。动作空间（Action Space）包含向用户询问某个Slot的值，或者通知用户目前的结果。整个系统包含三个大模块：一个Belief Trackers、一个Soft-KB Lookup以及一个Policy Network。&lt;/p&gt;

&lt;p&gt;Belief Trackers的作用是对整个系统现在的状态有一个全局的掌握。这里，每一个Slot都有一个Tracker，一个是根据用户当前的输入需要保持一个对于所有值的Multinomial分布，另外的则是需要保持一个对于用户是否知道这个Slot的值的置信值。文章中奖了Hand-Crafted Tracker和Neural Belief Tracker（基于GRU）的细节，这里就不复述了。有了Tracker以后，Soft-KB Lookup的作用是保持一个整个对于本体的所有值得后验分布。最后，这些后验概率统统被总结到了一个总结向量（Summary Vector）里。这个向量可以认为是把所有的后验信息给压缩到了这个向量里。而Policy Network则根据这个总结向量，来选择整个对话系统的下一个动作。这里文章也是介绍了Hand-Crafted的Policy和Neural Policy两种情况。我们就不复述了。&lt;/p&gt;

&lt;p&gt;整个模型的训练过程还是有困难的。虽然作者用了REINFORCE的算法，但是，作者们发现根据随机初始化的算法没法得到想要的效果。于是作者们采用了所谓的Imitation Learning的方法，也就是说，最开始的时候去模拟Hand-Crafted Agents的效果。&lt;/p&gt;

&lt;p&gt;在这篇文章里，作者们采用了模拟器（Simulator）的衡量方式。具体说来，就是通过与一个模拟器进行对话从而训练基于强化学习的对话系统。作者们用了MovieKB来做数据集。总体说来整个实验部分都显得比较“弱”。没有充足的真正的实验结果。&lt;/p&gt;

&lt;p&gt;可以说整个文章真正值得借鉴主要还是那个“软查询”的思想。整个流程也值得参考。但是训练的困难可能使得这个系统作为一个可以更加扩展的系统的价值不高。本文值得对对话系统有研究的人泛读。&lt;/p&gt;
</description>
        <pubDate>Sat, 05 Aug 2017 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/08/05/acl2017-rl-dl/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/08/05/acl2017-rl-dl/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>ACL 2017文章精读（二）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://acl2017.org/&quot;&gt;ACL 2017&lt;/a&gt;文章Topically Driven Neural Language Model进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.08012&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/jhlau/topically-driven-language-model&quot;&gt;代码地址&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者都来自于澳大利亚的研究人员。第一作者Jey Han Lau目前在澳大利亚的IBM进行Topic Model以及NLP方面的研究，之前也在第二作者Timothy Baldwin的实验室做过研究。第二作者Timothy Baldwin和第三作者Trevor Cohn都是在墨尔本大学长期从事NLP的研究的教授。&lt;/p&gt;

&lt;p&gt;这篇文章的核心思想是想彻底用Neural的思想来做结合Topic Model和Language Model。当然，既然这两种模型都是文字处理方面的核心模型，自然之前就有人曾经想过要这么做。不过之前的不少尝试都是要么还想保留LDA的一些部件或者往传统的LDA模型上去靠，要么是并没有和Language Model结合起来。这篇文章的主要卖点是完全用深度学习的“语言”来构建了整个模型，并且模型中的Topic Model模型部分的结果会成为驱动Language Model部分的成分。&lt;/p&gt;

&lt;p&gt;概括说来，文章提出了一个有两个组成部分的模型的集合（文章管这个模型叫tdlm）。第一个部分就是所谓的Topic Model的部分。我们已经提过，这里的Topic Model和LDA已经相去甚远。这里的思路是这样的，首先，从一个文字表达的矩阵中（有可能就直接是传统的Word Embedding），通过Convolutional Filters转换成为一些文字的特征表达（Feature Vector）。文章里面选用的是线性的转换方式。这些Convolutional Filters都是作用在文字的一个Window上面，所以从概念上讲，这一个步骤很类似Word Embedding。得到这些Feature Vector以后，作者们又使用了一个Max-Over-Time的Pooling动作（也就是每一组文字的Feature Vector中最大值），从而产生了文档的表达。注意，这里依然学到的依然是比较直接的Embedding。然后，作者们定义了这么一组Topic的产生形式。首先，是有一个“输入Topic矩阵”。这个矩阵和已经得到的文档特征一起，产生一个叫做Attention的向量。这个Attention的向量再和“输出Topic矩阵”一起作用，产生最终的文档Topic向量。这也就是这部分模型的主要部分。最终，这个文档Topic向量通过用于预测文档中的每一个字来被学习到。有了这个文档Topic向量以后，作者们把这个信息用在了一个基于LSTM的Language Model上面。这一部分，其实就是用了一个类似于GRU的功能，把Topic的信息给附加在Language Model上。&lt;/p&gt;

&lt;p&gt;文章在训练的时候，采用了Joint训练的方式，并且使用了Google发布的Word2Vec已经Pre-trained的Word Embedding。所采用的种种参数也都在文章中已经有所介绍。
文章在好一些数据集上做了实验。对于Topic的部分来说，文章主要是和LDA做比较，用了Perplexity这个传统的测量，还比较了Topic Coherence等。总体说来，提出的模型和LDA不相上下。Language Model的部分来说，提出的模型也在APNews、IMDB和BNC上都有不错的Perplexity值。&lt;/p&gt;

&lt;p&gt;总体说来，这篇文章值得文字挖掘的研究者和NLP的研究者泛读。&lt;/p&gt;
</description>
        <pubDate>Fri, 04 Aug 2017 00:00:00 -0700</pubDate>
        <link>http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/08/04/acl2017-neural-lm/</link>
        <guid isPermaLink="true">http://column.hongliangjie.com/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/08/04/acl2017-neural-lm/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
  </channel>
</rss>
