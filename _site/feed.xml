<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>期望最大化（洪亮劼的专栏）</title>
    <description>Etsy数据科学主管、前雅虎研究院高级研发经理，长期从事机器学习、大数据分析、个性化系统架构的研究；这是一个分享技术、管理、团队和业界思考的专栏。</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 11 Jul 2017 21:42:46 -0400</pubDate>
    <lastBuildDate>Tue, 11 Jul 2017 21:42:46 -0400</lastBuildDate>
    <generator>Jekyll v3.4.3</generator>
    
      <item>
        <title>Google Scholar 2017学术指标之人工智能篇</title>
        <description>&lt;p&gt;近日，Google Scholar发布了一个&lt;a href=&quot;https://scholar.googleblog.com/2017/07/2017-scholar-metrics-released.html&quot;&gt;2017年的“学术指标”&lt;/a&gt;，主要是对各个学科的众多领域的学术刊物（包括期刊、会议论文集以及在线论文出版集）做出了排名。这个排名主要是依靠&lt;a href=&quot;https://en.wikipedia.org/wiki/H-index&quot;&gt;H5-Index&lt;/a&gt;这一指标。我们在这篇文章里，对人工智能相关的领域学术出版刊物的排名进行一个简单的分析和导读。&lt;/p&gt;

&lt;h2 id=&quot;人工智能主类&quot;&gt;人工智能主类&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/google_ai.png&quot; alt=&quot;&quot; /&gt;
因为收率了在线论文出版集（主要是ArXiv），借着深度学习（Deep Learning）的春风，ArXiv的Learning子类成为了目前最有影响力的出版集。当然，考虑到目前在深度学习以及更加广阔的机器学习领域已经有了把论文的某一个版本率先发表到ArXiv的习惯，Learning子类的实际影响力可能要打一些折扣。不过，不可否认的则是这样的发布学术结果的方式的确对计算机科学（Computer Science）原本的发表模式有了很深远的挑战和影响。
&lt;img src=&quot;/assets/google_ai_learning.png&quot; alt=&quot;&quot; /&gt;
有意思的是，尽管引用度排名靠前的大多数文章最终都在传统的会议或者期刊上面发表，排名第四的&lt;a href=&quot;https://arxiv.org/abs/1212.5701&quot;&gt;ADADELTA: An Adaptive Learning Rate Method&lt;/a&gt;（应用数超过900）则并没有在任何传统刊物上有出版。还有引用度超过500的&lt;a href=&quot;https://arxiv.org/abs/1312.5602&quot;&gt;Playing Atari with Deep Reinforcement Learning&lt;/a&gt;也没有在传统的刊物上发表出版。这些都显示了ArXiv作为当前出版渠道的重要补充的这一作用。我们再来看一下传统刊物中排名第一的NIPS的排名靠前的文章：
&lt;img src=&quot;/assets/google_ai_nips.png&quot; alt=&quot;&quot; /&gt;
首先我们发现的是，排名靠前的无一例外地都是和深度学习有密切联系的文章。排名第一的则是Hinton及其学生提出的&lt;a href=&quot;http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&quot;&gt;AlexNet&lt;/a&gt;的这一开创性的研究成果，一举奠定了深度学习在计算机视觉领域的主导地位的历史性文章。排名第二的则是提出目前在NLP等领域广泛使用的&lt;a href=&quot;http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality&quot;&gt;Word2Vec&lt;/a&gt;的论文，也可以说实至名归。总之，NIPS排名靠前的论文还是非常有含金量的标志性研究成果。和NIPS齐名的机器学习会议ICML也在排名上位列第4。
&lt;img src=&quot;/assets/google_ai_icml.png&quot; alt=&quot;&quot; /&gt;
和NIPS类似的也是排位靠前的文章基本上被深度学习相关的研究成果所把持。相比之下，排位稍微靠后的期刊&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385&quot;&gt;IEEE Transactions on Neural Networks and Learning Systems&lt;/a&gt;以及&lt;a href=&quot;http://www.jmlr.org/&quot;&gt;The Journal of Machine Learning Research&lt;/a&gt;则多了不少机器学习其他领域的研究成果。
&lt;img src=&quot;/assets/google_ai_jmlr.png&quot; alt=&quot;&quot; /&gt;
比如，最近几年又重新红火起来的大规模Bayesian Inference的代表作&lt;a href=&quot;http://www.jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf&quot;&gt;Stochastic variational inference&lt;/a&gt;以及开创了Moment Matching旧瓶装新酒的&lt;a href=&quot;http://www.jmlr.org/papers/volume15/anandkumar14b/anandkumar14b.pdf&quot;&gt;Tensor decompositions for learning latent variable models&lt;/a&gt;也都名列前茅。通过我们这里简单的分析和总结，不难发现最近五年AI界的成果还是集中在深度学习界，而且是传统刊物NIPS和ICML都成为了推动深度学习发展的重要领军会议。而ArXiv则在这个过程中发挥着不可替代的辅助性作用。&lt;/p&gt;

&lt;h2 id=&quot;计算机视觉&quot;&gt;计算机视觉&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/google_cv.png&quot; alt=&quot;&quot; /&gt;
我们看了人工智能主类之后，我们来关注一下几个人工智能的分类的动态。那么要说最近几年发展得最迅猛的人工智能分支，无疑要数计算机视觉技术。不过，相比于人工智能主类的好几大主流会刊的情况，在计算机视觉领域，目前的格局依然是&lt;a href=&quot;https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition&quot;&gt;CVPR&lt;/a&gt;和&lt;a href=&quot;http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34&quot;&gt;PAMI&lt;/a&gt;独秀的情况。而ArXiv的补充作用在这里也显示得很明显。
&lt;img src=&quot;/assets/google_cv_cvpr.png&quot; alt=&quot;&quot; /&gt;
我们来看看CVPR的这几年的有影响力的工作，无疑都和ImageNet的主要进步联系起来。比如排名第一的&lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf&quot;&gt;Going Deeper With Convolutions&lt;/a&gt;所代表的GoogleNet，以及排名第二的&lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf&quot;&gt;Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation&lt;/a&gt;所提出的R-CNN和排名第三的&lt;a href=&quot;http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf&quot;&gt;Deep Residual Learning for Image Recognition&lt;/a&gt;所提出的ResNet。这些都是最近几年借助大幅度提高ImageNet的效果而在CV领域获得重点关注的文章。&lt;/p&gt;

&lt;h2 id=&quot;计算语言学&quot;&gt;计算语言学&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/google_nlp.png&quot; alt=&quot;&quot; /&gt;
人工智能在计算语言学的应用主要体现在自然语言处理（NLP）等领域。借着深度学习在NLP领域的影响和发展，ArXiv成为一个主要的文章发表场所似乎也是顺利成长的事情了。和人工智能主类相似的情况是，在ArXiv上面发布的重要文章最后都在相应的会议或者期刊有所发表，唯一例外的是有3600多引用的&lt;a href=&quot;https://arxiv.org/abs/1301.3781&quot;&gt;Efficient Estimation of Word Representations in Vector Space&lt;/a&gt;。从分布的情况上看，过去几年的大多数影响力大的文章主要分为在Word2Vec方面做文章，以及在Machine Translation或者Sequence Model方面做文章。排名第二第三的依然是NLP领域传统的旗舰会议ACL和EMNLP。
&lt;img src=&quot;/assets/google_nlp_acl.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/assets/google_nlp_emnlp.png&quot; alt=&quot;&quot; /&gt;
我们可以看到深度学习，特别是学习文字的Embedding（包括字、文章段落等等）占据了很重要的一个研究方向。另外一个重要的研究方向就是机器翻译，特别是如何应用深度学习在这方面的成果。需要特别注意的是，斯坦福大学&lt;a href=&quot;https://nlp.stanford.edu/manning/&quot;&gt;Christopher Manning&lt;/a&gt;的研究组最近几年可以说是成果颇丰。高排名的好几篇ACL以及EMNLP都看得见他的身影。&lt;/p&gt;

&lt;h2 id=&quot;数据挖掘和信息系统&quot;&gt;数据挖掘和信息系统&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;img src=&quot;/assets/google_dm_1.png&quot; alt=&quot;&quot; /&gt;
&lt;img src=&quot;/assets/google_dm_2.png&quot; alt=&quot;&quot; /&gt;
Google把整个数据挖掘和信息系统分为了两类“Data Mining &amp;amp; Analysis”和“Database &amp;amp; Information Systems”。然而在实际中这两类的文章和成果经常交叉出现，于是我们这里就一起讨论这两个分类。一个比较有意思的情况就是，ArXiv还并没有成为这个领域的主要发布工具。传统的&lt;a href=&quot;http://www.kdd.org/&quot;&gt;KDD&lt;/a&gt;以及&lt;a href=&quot;https://en.wikipedia.org/wiki/International_World_Wide_Web_Conference&quot;&gt;WWW&lt;/a&gt;依然占据着重要的成果发布平台的地位。我们来看一下KDD的最新经典论文：
&lt;img src=&quot;/assets/google_dm_kdd.png&quot; alt=&quot;&quot; /&gt;
可以说是涉及范围十分广泛。从Social Network Analysis到Time Series Analysis再到一般性质的Data Mining的算法和工具，KDD还是展现了这个发布平台的包容性和多样性。其中排名第二的&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2623623&quot;&gt;Knowledge vault: a web-scale approach to probabilistic knowledge fusion&lt;/a&gt;，这一讲述Google的知识图谱的技术论文和在2016年才发表的&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2939785&quot;&gt;XGBoost: A Scalable Tree Boosting System&lt;/a&gt;在短时间内吸引了不少相关学者的关注。下面我们来看看WWW的情况：
&lt;img src=&quot;/assets/google_dm_www.png&quot; alt=&quot;&quot; /&gt;
可以看出过去5年来，关于Social Media（以Twitter为主）和关于Social Network Analysis的相关研究还是如火如荼。而纵观KDD和WWW都可以看到斯坦福大学的明星学者&lt;a href=&quot;https://cs.stanford.edu/people/jure/&quot;&gt;Jure Leskovec&lt;/a&gt;的强大存在。&lt;/p&gt;

&lt;h2 id=&quot;总结&quot;&gt;总结&lt;/h2&gt;
&lt;hr /&gt;
&lt;p&gt;我们仅仅是在这里总结了和人工智能有关的几个分类的趋势。总体说来有这么几个特点：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;人工智能和机器学习的核心领域目前基本上完全围绕着深度学习展开。&lt;/li&gt;
  &lt;li&gt;计算机视觉和自然语言处理目前也是和深度学习有很强的联系。&lt;/li&gt;
  &lt;li&gt;数据挖掘相关的研究依然非常多样化。&lt;/li&gt;
  &lt;li&gt;ArXiv已经成为了非常强有力的辅助性研究成果发布平台。然而有影响力的文章最终还是在核心刊物上发表。&lt;/li&gt;
  &lt;li&gt;传统的NIPS、ICML、CVPR、ACL、EMNLP、KDD和WWW依然是人工智能的核心研究成果发布刊物。&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 09 Jul 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/07/09/google-scholar/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/07/09/google-scholar/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>AIStats 2017文章精读（五）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://www.aistats.org/&quot;&gt;AIStats 2017&lt;/a&gt;文章Communication-Efficient Learning of Deep Networks from Decentralized Data进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/mcmahan17a/mcmahan17a-supp.pdf&quot;&gt;文章附加信息&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自Google。文章的核心内容讲的是一个非常有实际意义的问题，那就是在分布式网络的情况下，如何构建合理的机器学习框架。这里说的分布式网络，指的是类似于手机网络这样的系统，用户有不同的数据集合（按照统计意义来说，通常是非IID的），并且这里面主要的陈本是通信陈本，而非计算陈本。传统的设置是不同的分布的数据可能是均匀IID的，而作者们认为在现实情况下，这是很难达到的一种状态。这里面还需要考虑的一些情况就是，如果作为手机客户端的话，每天能够参与优化模型的时间和次数都是有限的（根据电量等因素），因此如何设计一套有效的优化方案就显得非常必要。&lt;/p&gt;

&lt;p&gt;这篇文章提出的方案其实非常简单直观。算法总共有三个基本的参数，C（0到1）控制相对有多少数量的客户端参与优化，E控制每一轮多少轮SGD需要在客户端运行，B是每一轮的Mini-Batch的数目大小。算法的思路是：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;每一轮都随机选择出C那么多的客户端&lt;/li&gt;
  &lt;li&gt;对于每个客户端进行Mini-Batch的大小为B，轮数为E的SGD更新&lt;/li&gt;
  &lt;li&gt;对于参数直接进行加权平均（这里的权重是每个客户端的数据相对大小）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;文章对这里的最后一步进行了说明。之前有其他研究表明，如何直接对参数空间进行加权平均，特别是Non-Convex的问题，会得到任意坏的结果。这篇文章里，作者们对于这样的问题的处理是，让每一轮各个客户端的起始参数值相同（也就是前一轮的全局参数值）。这一步使得算法效果大幅度提高。&lt;/p&gt;

&lt;p&gt;文章在一系列的数据集上做了大量的实验，基本上都是基于神经网络的模型，例如LSTM，CNN等。效果应该说是非常显著和惊人，绝大多数情况下，提出的算法能够在大幅度比较小的情况下，达到简单SGD很多轮才能达到的精读。&lt;/p&gt;

&lt;p&gt;虽然这篇文章提出的算法简单可行，并且也有不错的实验结果。但是比较令人遗憾的是，作者们并没有给出更多的分析，证明这样做的确可以让参数达到全局最优或者局部最优。
这篇文章对于大规模机器学习有兴趣的读者可以精读。&lt;/p&gt;
</description>
        <pubDate>Sun, 18 Jun 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/18/aistats2017-dist-sgd/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/18/aistats2017-dist-sgd/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>AIStats 2017文章精读（四）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://www.aistats.org/&quot;&gt;AIStats 2017&lt;/a&gt;文章Fast Bayesian Optimization of Machine Learning Hyper-parameters on Large Datasets进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/klein17a/klein17a.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/klein17a/klein17a-supp.pdf&quot;&gt;文章附加信息&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群是一队来自德国的学者，分别来自University of Freiburg和Max Planck Institute for Intelligent Systems。文章讨论了一个很实际的问题，那就是如何对一个机器学习算法进行自动调参数。文章针对这几年逐渐火热起来的Bayesian Optimization，开发了一个快速的、并且能够在大规模数据上运行的算法。&lt;/p&gt;

&lt;p&gt;传统的机器学习算法有很多所谓叫超参数（Hyper-parameter）需要设置。而这些超参数往往对最后的算法性能有至关重要的影响。在一般的情况下，如何寻找最佳的超参数组合则成为了很多专家的必要“技能”。而对于机器算法本身而言，取决于算法的复杂程度，有时候寻找一组合适的超参数意味着非常大的计算代价。&lt;/p&gt;

&lt;p&gt;这篇文章讨论了这么一个思路，那就是，既然在全局数据上对算法进行评估计算代价太大，可能对于直接调参过于困难，那能否在一个数据的子集上进行调参，然后把获得的结果看能否运用到更大一点的子集上，最终运用到全集上。&lt;/p&gt;

&lt;p&gt;这里，我们来回顾一下Bayesian Optimization的简单原理。首先，我们有一个“黑盒”的目标函数。我们的任务是找到这个目标函数最小值所对应的参数值（超参数）。这里，我们需要一个这个目标函数的先验分布，同时我们还需要一个所谓的Acquisition Function，用来衡量在某个点的参数值的Utility。有了这些设置，一个通常情况下的Bayesian Optimization的步骤是这样的：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;用数值优化的方法在Acquisition Function的帮助下，找到下一个Promising的点。&lt;/li&gt;
  &lt;li&gt;带入这个Promising的点到黑盒函数中，得到当前的值，并且更新现在的数据集。&lt;/li&gt;
  &lt;li&gt;更新目标函数的先验分布以及Acquisition Function。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;通常情况下，Bayesian Optimization的研究喜欢用Gaussian Processes（GP）来做目标函数的先验分布。这里就不复述具体的设置了。而对于Acquisition Function，这里有好几种可能性，比如文章举了Expected Improvement（EI）、Upper Confidence Bound（UCB）、Entropy Search（ES）等的例子。这篇文章使用了EI和ES。&lt;/p&gt;

&lt;p&gt;这篇文章提出的方法的思路的第一步，是把原来那个黑盒函数增加了一个参数，也就是除了原来的超参数以外，增加了一个数据集大小的参数。这个参数是按照比例（从0到1的一个值）来调整相对的数据集大小的。那么，如何应用这个参数呢？这里的技巧是，在GP里，需要有一个Kernel的设置。原本这个Kernel是定义在两组超参数之间的。那么，在这篇文章里，这个Kernel就定义在“超参数和数据集大小”这个Pair与另外一个Pair之间。于是，这里就能够通过已经经典的设置得到需要的效果。文章还提出了一个新的Acquisition Function用来平衡Information Gain和Cost。&lt;/p&gt;

&lt;p&gt;文章用SVM在MNIST做了实验，还用CNN在CIFAR-10以及SVHN上做了实验，以及还用ResNet在CIFAR-10上做了实验。总体上说，提出来的算法比之前的方法快10倍到100倍。并且，相比较的一些其他算法（比如一开始就在全集上进行计算的方法）都没法完成实验。&lt;/p&gt;

&lt;p&gt;这篇文章的基本思路和相关研究值得机器学习实践者学习。&lt;/p&gt;
</description>
        <pubDate>Sat, 17 Jun 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/17/aistats2017-fast-bayesian/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/17/aistats2017-fast-bayesian/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>AIStats 2017文章精读（三）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://www.aistats.org/&quot;&gt;AIStats 2017&lt;/a&gt;文章Decentralized Collaborative Learning of Personalized Models over Networks进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/vanhaesebrouck17a/vanhaesebrouck17a.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/vanhaesebrouck17a/vanhaesebrouck17a-supp.pdf&quot;&gt;文章附加信息&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者们来自法国的INRIA和里尔大学（Universite de Lille）。文章讨论了一个非常实用也有广泛应用的问题，那就是所谓的Decentralized Collaborative Learning的问题，或者是说如何学习有效的个人模型（Personalized Models）的问题。&lt;/p&gt;

&lt;p&gt;在移动网络的情况下，不同的用户可能在移动设备（比如手机上）已经对一些内容进行了交互。那么，传统的方式，就是把这些用户产生的数据给集中到一个中心服务器，然后由中心服务器进行一个全局的优化。可以看出，在这样的情况下，有相当多的代价都放到了网络通信上。同时，还有一个问题，那就是全局的最优可能并不是每个用户的最优情况，所以还需要考虑用户的个别情况。&lt;/p&gt;

&lt;p&gt;比较快捷的方式是每个用户有一个自己的模型（Personalized Models），这个模型产生于用户自己的数据，并且能够很快地在这个局部的数据上进行优化。然而这样的问题则是可能没法利用全局更多的数据，从而能够为用户提供服务。特别是用户还并没有产生很多交互的时候，这时候可能更需要依赖于全局信息为用户提供服务。&lt;/p&gt;

&lt;p&gt;这篇文章提出了这么几个解决方案。首先，作者们构建了一个用户之间的图（Graph）。这个图的目的是来衡量各个用户节点之间的距离。注意，这里的距离不是物理距离，而是可以通过其他信息来定义的一个图。每个节点之间有一个权重（Weight），也是可以通过其他信息定义的。在这个图的基础上，作者们借用了传统的Label Propagation，这里其实是Model Propagation的方式，让这个图上相近节点的模型参数相似。在这个传统的Label Propagation方式下，这个优化算法是有一个Closed-Form的结论。&lt;/p&gt;

&lt;p&gt;当然，并不是所有的情况下，都能够直接去解这个Closed-Form的结论，于是这篇文章后面就提出了异步（Asynchronous）的算法来解这个问题。异步算法的核心其实还是一样的思路，不过就是需要从相近的节点去更新现在的模型。&lt;/p&gt;

&lt;p&gt;第三步，作者们探讨了一个更加复杂的情况，那就是个人模型本身并不是事先更新好，而是一边更新，一边和周围节点同步。作者这里采用了ADMM的思路来对这样目标进行优化。这里就不复述了。&lt;/p&gt;

&lt;p&gt;比较意外的是，文章本身并没有在大规模的数据上做实验而是人为得构造了一些实验数据（从非分布式的情况下）。所以实验的结果本身并没有过多的价值。&lt;/p&gt;

&lt;p&gt;不过这篇文章提出的Model Propagation的算法应该说是直观可行，很适合对大规模机器学习有兴趣的学者和实验者精读。&lt;/p&gt;
</description>
        <pubDate>Mon, 12 Jun 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/12/aistats2017-personal-model1/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/12/aistats2017-personal-model1/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>AIStats 2017文章精读（二）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://www.aistats.org/&quot;&gt;AIStats 2017&lt;/a&gt;文章Less than a Single Pass: Stochastically Controlled Stochastic Gradient Method
进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/lei17a/lei17a.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者们来自加州大学伯克利分校。作者之一的Michael Jordan是机器学习的权威学者之一，曾经在概率图模型的时期有突出的贡献。&lt;/p&gt;

&lt;p&gt;这篇文章主要还是讨论的大规模Convex优化的场景。在这个方面，已经有了相当丰富的学术成果。那么，这篇文章的主要贡献在什么地方呢？这篇文章主要想在算法的准确性和算法的通讯成本上下文章。&lt;/p&gt;

&lt;p&gt;具体说来，这篇文章提出的算法是想在Stochastic Variance Reduced Gradient（SVRG）上进行更改。SVRG的主要特征就是利用全部数据的Gradient来对SGD的Variance进行控制。因此SVRG的计算成本（Computation Cost）是O((n+m)T)，这里n是数据的总数，m是Step-size，而T是论数。SVRG的通讯成本也是这么多。这里面的主要成本在于每一轮都需要对全局数据进行访问。&lt;/p&gt;

&lt;p&gt;作者们提出了一种叫Stochastically Controlled Stochastic Gradient（SCSG）的新算法。总的来说，就是对SVRG进行了两个改进：&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;每一轮并不用全局的数据进行Gradient的计算，而是从一个全局的子集Batch中估计Gradient。子集的大小是B。&lt;/li&gt;
  &lt;li&gt;每一轮的SGD的更新数目也不是一个定值，而是一个和之前那个子集大小有关系，基于Geometric Distribution的随机数。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;剩下的更新步骤和SVRG一模一样。&lt;/p&gt;

&lt;p&gt;然而，这样的改变之后，新算法的计算成本成为了O((B+N)T)。也就是说，这是一个不依赖全局数据量大小的数值。而通过分析，作者们也比较了SCSG的通讯成本和一些原本就为了通讯成本而设计的算法，在很多情况下，SCSG的通讯成本更优。&lt;/p&gt;

&lt;p&gt;作者们通过MNIST数据集的实验发现，SCSG达到相同的准确度，需要比SVRG更少的轮数，和每一轮更少的数据。可以说，这个算法可能会成为SVRG的简单替代。&lt;/p&gt;

&lt;p&gt;对于大规模机器学习有兴趣的读者可以泛读。&lt;/p&gt;
</description>
        <pubDate>Sun, 11 Jun 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/11/aistats2017-less-sgd/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/11/aistats2017-less-sgd/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>AIStats 2017文章精读（一）</title>
        <description>&lt;p&gt;我们在这里对&lt;a href=&quot;http://www.aistats.org/&quot;&gt;AIStats 2017&lt;/a&gt;文章Stochastic Rank-1 Bandits进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/katariya17a/katariya17a.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://proceedings.mlr.press/v54/katariya17a/katariya17a-supp.pdf&quot;&gt;文章附加信息&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自于几个大学和Adobe Research。作者群中的Branislav Kveton和Zheng Wen在过去几年中发表过多篇关于Bandits的文章，值得关注。&lt;/p&gt;

&lt;p&gt;这篇文章解决的问题是一个在应用中经常遇到的问题，那就是每一步Agent是从一对Row和Column的Arms中选择，并且得到他们的外积（Outer Product）作为Reward。这个设置从搜索中的Position-based Model以及从广告的推广中都有应用。&lt;/p&gt;

&lt;p&gt;具体的设置是这样的，先假设我们有K行，L列。在每一个时间T步骤中有一个行（Row）向量u，从一个分布中抽取（Draw）出来，同时有一个列（Column）向量v，从另外一个分布中抽取出来。这两个抽取的动作是完全独立的。在这样的情况下， Agent在时间T，需要选择一个综合的Arm，也就是一个两维的坐标，i和j，从而在u和v的外积（Outer Product）这个矩阵中得到坐标为i和j的回报（Reward）。&lt;/p&gt;

&lt;p&gt;文章指出，这个设置可以被当做是有K乘以L那么多个Arm的简单的Multi-armed Bandit。那么当然可以用UCB1或者是LinUCB去解。然而文章中分析了这样做的不现实性，最主要的难点在K和L都比较大的情况下，把这个场景的算法当做原始的Multi-armed Bandit就会有过大的Regret。&lt;/p&gt;

&lt;p&gt;这篇文章提出了一个叫做Rank1Elim的算法来有效的解决这个问题。我们这里不提这个算法的细节。总体说来，这个算法的核心思想，就是减少行和列的数量，使得需要Explore的数量大大减少。这也就是算法中所谓Elimination的来历。那么，怎么来减少行列的数量呢？虽然作者们没有直接指出，不过这里采用和核心思想就是Clustering。也就是说，有相似回报（Reward）的行与列都归并在一起，并且只留下一个。这样，就能大大减少整个搜索空间。&lt;/p&gt;

&lt;p&gt;文章主要的篇幅用在了证明上，这里就不去复述了。文章在MovenLens的数据集上做了一组实验，并且显示了比UCB1的Regret有非常大的提高。&lt;/p&gt;

&lt;p&gt;这篇文章适合对推荐系统的Exploitation和Exploration有研究的学者泛读。&lt;/p&gt;
</description>
        <pubDate>Sat, 10 Jun 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/10/aistats2017-rank1-bandits/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/06/10/aistats2017-rank1-bandits/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（七）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Monetary Discount Strategies for Real-Time Promotion Campaign进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://oak.cs.ucla.edu/~chucheng/publication/www17.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的来自于一批来自台湾国立成功大学的学者和一个叫Slice Technologies的公司。这篇文章要解决的是一个非常实际的在E-Commerce会遇到的问题，那就是如何进行实时的促销（Promotion Campaign）使得可以吸引用户而同时也可以达到利润最大化的目的。&lt;/p&gt;

&lt;p&gt;作者们在这篇文章提出了一个叫做Real-Time Promotion（RTP）的概念，类比于广告里面经常提到的Real-Time Bidding。同时，这个RTP是一个针对某一个特定用户的一次性Deal。也就是说，这里面有了个性化的成分，使得能够对用户有一定的吸引力。然而，这个问题的难点是，如果能够做到在做RTP的同时，不影响到或者尽可能小的影响到用户对于品牌的一个认知，不至于让用户有负面的感觉。&lt;/p&gt;

&lt;p&gt;这篇文章的数据来源于这个叫Slice的公司。具体说来，Slice就是对百万用户的Receipts进行分析，从而对用户进行建模。这里面有一个基本的假设就是，如果一个用户已经以一定的价格（Price）购买了某种商品，那么，比这个价格低的价格，用户也一般愿意接受。而相反，用户可能不会接受比当前这个价格更高的价格。&lt;/p&gt;

&lt;p&gt;首先，作者们定义了这个所谓Discount-Giving Strategy的问题。那就是在给定的Discount预算（Budget）的情况下，如何最大化利润。文章指出，这个问题很类似传统的背包问题（Knapsack）。当然，与背包问题的最大不同的就是在于，这个问题中的很多参数是未知的，比如顾客是否愿意购买，再比如当前的折扣价格。&lt;/p&gt;

&lt;p&gt;在假设知道当前客户购买一个商品的价格分布的情况下，我们是可以得到最大化利润的一个表达的。然而遗憾的是，我们并不知道这个价格分布。于是在这篇文章里，作者们就提出了使用Kernel Density Estimation（KDE）来对价格分布进行估计。而得知了这个分布以后，我们就能够对每一个商品的所谓Cut-off Price进行一个准确的估计。这里的细节建议大家看文章。有了这些组成部分以后，作者们在这篇文章中提出了一个基于Thompson Sampling的办法，这样做的好处是可以对实时变化的数据进行很好的估计，同时也可以让整个优化过程更加Robust。&lt;/p&gt;

&lt;p&gt;实验就是在Slice过去手机的Receipts来进行的Simulation。应该说，实验的结果还是证明了动态的实时优化对于曾家利润是有帮助的。&lt;/p&gt;

&lt;p&gt;这篇文章的具体技术比较繁复，很难看出能够直接在这个基础上再扩展算法。然而这篇文章提出的问题的确比较新颖，也是电商或者网络运营商（比如Uber、DiDi）等经常遇到的问题，所以，值得对相关技术有兴趣的读者泛读。&lt;/p&gt;
</description>
        <pubDate>Sun, 30 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/30/www2017-slice/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/30/www2017-slice/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（六）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Situational Context for Ranking in Personal Search进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ciir-publications.cs.umass.edu/pub/web/getpdf.php?id=1268&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自于University of Massachusetts Amherst（UMASS）以及Google。UMASS因为W. Bruce Croft（Information Retrieval领域的学术权威）的原因 ，一直以来是培养IR学者的重要学校。文章做这种的Michael Bendersky以及Xuanhua Wang都是Bruce Croft过去的学生。这篇文章想要讨论的是如何在个人搜索（Personal Search）这个领域根据用户的场景和情况（Situational Context）来训练有效的排序模型（Ranking Model）。&lt;/p&gt;

&lt;p&gt;这篇文章的核心思想其实非常直观：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;场景信息对于个人搜索来说很重要，比如时间，地点，Device，因此试图采用这些信息到排序算法中，是非常显而易见的。&lt;/li&gt;
  &lt;li&gt;作者们尝试采用Deep Neural Networks来学习Query以及Document之间的Matching。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;具体说来，作者们提出了两个排序模型来解决这两个设计问题。第一个模型应该说是第二个模型的简化版。&lt;/p&gt;

&lt;p&gt;第一个模型是把Query，Context，以及Document当做不同的模块元素，首先对于每一个模块分别学习一个Embedding向量。与之前的一些工作不同的是，这个Embedding不是事先学习好的（Pre-Trained）而是通过数据End-to-End学习出来的。有了各个模块的Embedding向量，作者们做了这么一个特殊的处理，那就是对于不同的Context（比如，时间、地点）学习到的Embedding，在最后进入Matching之前，不同Context的Embedding又组合成为一个统一的Context Embedding（这里的目的是学习到例如对时间、地点这组信息的统一规律），然后这个最终的Context Embedding和Query的，以及Document的Embedding，这三个模块进行Matching产生Relevance Score。&lt;/p&gt;

&lt;p&gt;那么，第二个模型是建立在第一个模型的基础上的。思路就是把最近的一个所谓叫Wide and Deep Neural Networks（Wide and Deep）的工作给延展到了这里。Wide and Deep的具体思想很简单。那就是说，一些Google的研究人员发现，单靠简单的DNN并不能很好的学习到过去的一些非常具体的经验。原因当然是DNN的主要优势和目的就是学习数据的抽象表达，而因为中间的Hidden Layer的原因，对于具体的一些Feature也好无法“记忆”。而在有一些应用中，能够完整记忆一些具体的Feature是非常有必要的。于是Wide and Deep其实就是把一个Logistic Regression和DNN硬拼凑在一起，用Logistic Regression的部分达到记忆具体数据，而用DNN的部分来进行抽象学习。这第二个模型也就采用了这个思路。在第一个模型之上，第二个模型直接把不同Context信息又和已经学到的各种Embedding放在一起，成为了最后产生Relevance Score的一部分。这样的话，在一些场景下出现的结果，就被这个线性模型部分给记忆住了。&lt;/p&gt;

&lt;p&gt;在实验的部分来说，文章当然是采用了Google的个人搜索实验数据，因此数据部分是没有公开的。从实验效果上来说，文章主要是比较了单纯的用CTR作为Feature，进行记忆的简单模型。总体说来，这篇文章提出的模型都能够对Baseline提出不小的提升，特别是第二个模型仍然能够对第一个模型有一个小部分但具有意义的提升。&lt;/p&gt;

&lt;p&gt;这篇文章对于研究如何用深度学习来做文档查询或者搜索的研究者和实践者而言，有不小的借鉴意义，值得精读。&lt;/p&gt;
</description>
        <pubDate>Fri, 28 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/28/www2017-personal-search/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/28/www2017-personal-search/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（五）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Streaming Recommender Systems进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.yichang-cs.com/yahoo/WWW17_StreamingRec.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自雅虎研究院和University of Illinois at Urbana-Champaign。第一作者&lt;a href=&quot;http://www.ifp.illinois.edu/~chang87&quot;&gt;Shiyu Chang&lt;/a&gt;，是今年来一位学术新星，目前在IBM华生研究院工作。这篇文章的核心思想是想提出一个完全基于流（Stream）信息的推荐系统框架。&lt;/p&gt;

&lt;p&gt;作者们认为，流信息和普通的静态数据有很大的区别：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;大量的数据流入系统，系统必须对这些数据进行实时的反应。比如用户和某一个物品进行了交互；比如有新的物品产生需要被系统识别到并且能够查询等等。&lt;/li&gt;
  &lt;li&gt;流入系统的数据的量是未知的。这部分信息无法在产生系统之前拿到。&lt;/li&gt;
  &lt;li&gt;随着时间的推移，数据会产生所谓的“概念漂移”（Concept Shift）的现象。用户的喜好也会随着时间的推移而发生变化。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;于是，这篇文章就是希望从根本上来解决这些问题，提出一个基于信息流的推荐系统框架。&lt;/p&gt;

&lt;p&gt;文章提出的模型是一个具有时间信息的概率图模型（Probabilistic Graphical Model）。核心思想就是所有的元素都有时间的概念。举例来说，用户对于某一个物品的喜爱也仅仅是一个时间点的信息，并不代表之后的时间点的信息。这一点来说，就给了用户喜好发生变化的可能性。模型的核心还是基于用户向量（User Vector）和物品向量（Item Vector）的点积。不过，这里的用户向量和物品向量都是某一个时间点的估计。这些向量都随着时间发生变化。具体说来，作者们定义了一个基于布朗随机运动（Brownian Motion）的变化过程来对用户向量随着时间变化的改变来建模。也就是说，下一个时间点的用户向量是一个基于上一个时间点的用户向量的高斯分布。同样的建模手段也用到了物品向量上。整个模型可以说还是比较直观的，从概念上来说，提出的这个框架其实非常类似用卡曼滤波（Kalman Filtering）来进行时间维度的建模。而用卡曼滤波建模也是过去在概率图模型里经常使用的技巧。&lt;/p&gt;

&lt;p&gt;这个模型的难点是做模型的在线预测（Online Prediction）和离线模型参数估计（Offline Parameter Estimation）。对于在线预测的部分，作者们提出了一个叫Recursive Mean-field Approximation的技术。对于离线模型参数估计来说，作者们使用了标准的EM算法。总体来说，整个学习流程其实是比较复杂的。这也和其他使用类似卡曼滤波的方法类似。这也是概率图模型对时间信息处理的通病。&lt;/p&gt;

&lt;p&gt;文章实验的部分还是非常详尽的。文章在MovieLens的比较小的以及比较大的数据集上都做了实验，并且还加上了经典的Netflix的数据集。从Baseline的比较上来说，文章比较了传统的Probabilistic Matrix Factorization，经典的Time-SVD++算法（赢得Netflix大赛的算法）以及比较先进的Gaussian Process Factorization Machines。从实验的效果上来看，文章提出的方法在三个数据集上都有不错的效果。&lt;/p&gt;

&lt;p&gt;这篇文章提出的方法因为其算法复杂性，很难应用在生产中。而且要想在这个模型上做进一步的扩展，只能使得算法的复杂性进一步提升。这篇文章适合对于推荐系统有研究的学者和实践者泛读。&lt;/p&gt;
</description>
        <pubDate>Thu, 27 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/27/www2017-stream/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/27/www2017-stream/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
      <item>
        <title>WWW 2017文章精读（四）</title>
        <description>&lt;p&gt;我们在这里对WWW 2017文章Modeling Consumer Preferences and Price Sensitivities from Large-Scale Grocery Shopping Transaction Logs进行一个简单的分析解读。&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://cseweb.ucsd.edu/~m5wan/paper/www17_mwan.pdf&quot;&gt;全文PDF&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;这篇文章的作者群来自加州大学圣地亚哥分校（University of California at San Diego）和微软研究院。最后一个作者Julian McAuley在加州大学圣地亚哥分校长期从事推荐系统以及用户模型的研究工作。建议对推荐系统有研究的朋友经常看看他又有什么新的研究成果这篇文章的特色在于希望把推荐系统的用户喜好建模和经济学里的对于价格的研究结合起来。作者们认为，在推荐系统领域，对于用户喜好建模已经是比较成熟的研究领域了，而对于价格，特别是价格的敏感度（Sensitivity）的研究还并不是很多。于是这篇文章就是要弥补这么一个研究缺失（Gap）。&lt;/p&gt;

&lt;p&gt;作者们首先提出了一个分三阶段（Three Stage）的概率模型，用来刻画用户选择购买商品时候的选择过程。具体来说，这篇文章把用户的行为分为了这么三个阶段：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;类别选择（Category Purchase），也就是说，用户首先选择要购买哪个类别的商品。&lt;/li&gt;
  &lt;li&gt;产品选择（Product Choice），这里面就是在已经选定了一个类别以后，用户如何在这个类别里面选择商品。&lt;/li&gt;
  &lt;li&gt;数量购买（Purchase Quantity），选择要购买多少商品。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有了这三个阶段以后，用户的购买需求就成为了这三种概率的联合分布。&lt;/p&gt;

&lt;p&gt;为了对这三种行为有效建模，作者们首先提出了一个所谓的Feature-Based Matrix Factorization（FMF）的框架。总的说来，这是之前的LinkedIn提出的所谓的Generalized Linear Mixed Model（GLMix）变种。读者可以仔细参考原论文看看FMF的细节。这个FMF结合了全局特征（Global Features），物品特征，用户特征，以及用户和物品的隐含特征（Latent Features）。可以说是一个比较完善的框架体系。&lt;/p&gt;

&lt;p&gt;有了FMF这个工具，我们再回到刚才的三个阶段的建模。作者们的思路就是用FMF的不同表达形式为三个阶段进行分别的建模。具体说来，类别选择的部分，采用了FMF的Logistic表达形式，也就是对每个类别进行简单的“是”还是“不是”的购买选择。产品选择的部分则采用了Multinomial Regression的形式，也就是在所有同类商品里面进行选择。第三部分数量购买则采用了Poisson Regression的形式。然而核心这三部分采用的是同样的一套思路。因为这三个部分的独立性，使得模型的学习可以把这三部分分来，有利于能够并行化。在整体的模型学习上，作者们还加上了AUC Optimization的“作料”。&lt;/p&gt;

&lt;p&gt;接下来，作者们介绍了这篇文章的一个重点，那就是把价格因素引入到了整体框架中。其实思路还是很简单，就是直接把价格（在模型中用了Log Transformation）当做一个Feature，进行参数学习。这样做的好处还有直接可以计算所谓的价格敏感度，也就是购买一个东西的可能性的变化和价格变化的比值。这个数量可以用来描述价格的变化敏感度，可以让我们对价格做进一步的分析。&lt;/p&gt;

&lt;p&gt;作者们在一个非公开的西雅图的商店数据集上，和公开的Dunnhumby数据集上做了实验。实验结果是三个阶段的模型都有不错的表现。并且作者们还利用价格敏感度进行了数据的进一步分析。这里就不复述了。&lt;/p&gt;

&lt;p&gt;这篇文章值得对推荐系统有研究的学者和实践者精读。&lt;/p&gt;
</description>
        <pubDate>Wed, 26 Apr 2017 00:00:00 -0400</pubDate>
        <link>http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/26/www2017-ec/</link>
        <guid isPermaLink="true">http://localhost:4000/%E8%AF%BB%E8%AE%BA%E6%96%87/2017/04/26/www2017-ec/</guid>
        
        
        <category>读论文</category>
        
      </item>
    
  </channel>
</rss>
